{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#spare-cores-crawler","title":"Spare Cores Crawler","text":"<p>SC Crawler is a Python package to pull and standardize data on cloud compute resources, with tooling to help organize and update the collected data into databases.</p>"},{"location":"#database-schemas","title":"Database schemas","text":"<p>The database schemas and relationships are visualized and documented at https://dbdocs.io/spare-cores/sc-crawler.</p>"},{"location":"#usage","title":"Usage","text":"<p>The package provides a CLI tool:</p> <pre><code>sc-crawler --help\n</code></pre>"},{"location":"#collect-data","title":"Collect data","text":"<p>Note that you need specific IAM permissions to be able to run <code>sc-crawler</code> at the below vendors:</p> Amazon Web Services (AWS) <p>AWS supports different options for Authentication and access for interacting with their APIs. This is usually an AWS access key stored in <code>~/.aws/credentials</code> or in environment variables, or an attached IAM role.</p> <p>The related user or role requires the below minimum IAM policy:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AllowCrawler\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"pricing:ListPriceLists\",\n                \"pricing:GetPriceListFileUrl\",\n                \"pricing:GetProducts\",\n                \"ec2:DescribeRegions\",\n                \"ec2:DescribeAvailabilityZones\",\n                \"ec2:DescribeInstanceTypes\",\n                \"ec2:DescribeSpotPriceHistory\",\n                \"ec2:DescribeInstanceTypeOfferings\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre> Google Cloud Platform (GCP) <p>Using the Application Default Credentials for interacting with GCP APIs. This is usually the path to a credential configuration file (created at https://developers.google.com/workspace/guides/create-credentials#service-account) stored in the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable, but could be an attached service account, Workload Identity Federation etc.</p> <p>The related user or service account requires the below minimum roles:</p> <ul> <li>Commerce Price Management Viewer</li> <li>Compute Viewer</li> </ul> <p>List of APIs required to be enabled in the project:</p> <ul> <li>Cloud Billing API</li> <li>Compute Engine API</li> </ul> Hetzner Cloud <p>Generate token at your Hetzner Cloud project and store it in the <code>HCLOUD_TOKEN</code> environment variable.</p> Microsoft Azure <p>Authentication is handled via the <code>DefaultAzureCredential</code>, so you can use either secrets or certificates.</p> <p>The following environment variables are required:</p> <ul> <li><code>AZURE_CLIENT_ID</code> (application client ID)</li> <li><code>AZURE_TENANT_ID</code></li> </ul> <p>To authenticate with secret:</p> <ul> <li><code>AZURE_CLIENT_SECRET</code> (secret value)</li> </ul> <p>To authenticate with certificate:</p> <ul> <li><code>AZURE_CLIENT_CERTIFICATE_PATH</code></li> <li><code>AZURE_CLIENT_CERTIFICATE_PASSWORD</code> (optional)</li> </ul> <p>For further options, consult the <code>EnvironmentCredential</code> docs.</p> <p>Optionally, you can also specify the Subscription (otherwise the first one found in the account will be used):</p> <ul> <li><code>AZURE_SUBSCRIPTION_ID</code></li> </ul> <p>The related Service Principal requires either the global \"Reader\" role, or the following list of (more restrictive) permissions:</p> <ul> <li><code>Microsoft.Resources/subscriptions/locations/read</code></li> </ul> <p>To create the Service Principal, go to App registrations, and then assign the role at the Subscription's Access control page.</p> UpCloud <p>Create a user (subaccount) in the UpCloud control panel with \"API connections\" permission enabled. Then configure the following environment variables:</p> <ul> <li><code>UPCLOUD_USERNAME</code></li> <li><code>UPCLOUD_PASSWORD</code></li> </ul> OVHcloud <p>You need to create a cloud project, optionally enable all regions, then create and configure a service account as described in the Managing OVHcloud service accounts via the API document. In short:</p> <ol> <li>Create a service account via a <code>POST</code> API query to <code>/me/api/oauth2/client</code>.</li> <li>Get its <code>arn</code> via a <code>GET</code> to <code>/me/api/oauth2/client/{client_id}</code> (using the <code>client_id</code> from above).</li> <li>Set minimum permissions for the <code>arn</code> via a <code>POST</code> to <code>/iam/policy</code>, e.g.:</li> </ol> <pre><code>{\n  \"description\": \"Minimum permissions for sc-data\",\n  \"identities\": [\"{your_urn}\"],\n  \"name\": \"sc-data\",\n  \"permissions\": {\n    \"allow\": [\n      {\n        \"action\": \"account:apiovh:me/get\"\n      },\n      {\n        \"action\": \"publicCloudProject:apiovh:get\"\n      },\n      {\n        \"action\": \"publicCloudProject:apiovh:region/get\"\n      },\n      {\n        \"action\": \"publicCloudProject:apiovh:flavor/get\"\n      }\n    ]\n  },\n  \"resources\": [\n    {\n        \"urn\": \"urn:v1:eu:resource:account:{your_account_id}-ovh\"\n    }\n  ]\n}\n</code></pre> <p>Then configure the following environment variables:</p> <ul> <li><code>OVH_ENDPOINT</code> (e.g. \"ovh-eu\")</li> <li><code>OVH_CLIENT_ID</code></li> <li><code>OVH_CLIENT_SECRET</code></li> </ul> <p>By default, the first project found in the account will be used. Optionally, you can also specify the project ID to override that behavior via the <code>OVH_PROJECT_ID</code> environment variable.</p> <p>For the price catalog, we default to using the <code>IE</code> (Ireland) OVH subsidiary, which can be overridden via the <code>OVH_SUBSIDIARY</code> environment variable. This choice affects the currency used for prices.</p> Alibaba Cloud <p>Create a RAM user with the <code>AliyunBSSReadOnlyAccess</code> and <code>AliyunECSReadOnlyAccess</code> system policies (or a custom policy with at least the <code>bss:DescribeProduct</code> and <code>ecs:DescribePrice</code> permissions), then configure the following environment variables:</p> <ul> <li><code>ALIBABA_CLOUD_ACCESS_KEY_ID</code></li> <li><code>ALIBABA_CLOUD_ACCESS_KEY_SECRET</code></li> </ul> <p>Optionally, you can also specify the default region to use via the <code>ALIBABA_CLOUD_REGION_ID</code> environment variable, otherwise the default region (<code>eu-central-1</code>) will be used.</p> <p>Fetch and standardize datacenter, zone, servers, traffic, storage etc data from AWS into a single SQLite file:</p> <pre><code>sc-crawler pull --connection-string sqlite:///sc-data-all.db --include-vendor aws\n</code></pre> <p>If you need to run this many times, set the <code>SC_CRAWLER_INSPECTOR_DATA_PATH</code> environment variable to a directory for caching the inspector data, so that it won't be downloaded multiple times.</p> <p>Such an up-to-date SQLite database is managed by the Spare Cores team in the SC Data repository, or you can also find it at https://sc-data-public-40e9d310.s3.amazonaws.com/sc-data-all.db.bz2.</p> <p>Example run:</p>"},{"location":"#hash-data","title":"Hash data","text":"<p>Database content can be hashed via the <code>sc-crawler hash</code> command. It will provide a single SHA1 hash value based on all records of all SC Crawler tables, which is useful to track if database content has changed.</p> <pre><code>$ sc-crawler hash --connection-string sqlite:///sc-data-all.db\nb13b9b06cfb917b591851d18c824037914564418\n</code></pre> <p>For advanced usage, check sc_crawler.utils.hash_database to hash tables or rows.</p>"},{"location":"#copy-and-sync-data","title":"Copy and sync data","text":"<p>To copy data from a database to another one or sync data between two databases, you can use the <code>copy</code> and <code>sync</code> subcommands, which also support feeding SCD tables.</p>"},{"location":"#database-migrations","title":"Database migrations","text":"<p>To generate <code>CREATE TABLE</code> statements using the current version of the Crawler schemas, e.g. for a MySQL database:</p> <pre><code>sc-crawler schemas create --dialect mysql\n</code></pre> <p>See <code>sc-crawler schemas create --help</code> for all supported database engines (mainly thanks to SQLAlchemy), and other options.</p> <p><code>sc-crawler schemas</code> also supports many other subcommands based on Alembic, e.g. <code>upgrade</code> or <code>downgrade</code> schemas in a database (either just printing the related SQL commands via the <code>--sql</code> flag), printing the current version, setting a database version to a specific revision, or auto-generating migration scripts (for SC Crawler developers).</p>"},{"location":"#orm","title":"ORM","text":"<p>SC Crawler is using SQLModel / SQLAlchemy as the ORM to interact with the underlying database, and you can also use the defined schemas and models to actually read/filter a previously pulled DB. Quick examples:</p> <pre><code>from sc_crawler.tables import Server\nfrom sqlmodel import create_engine, Session, select\n\nengine = create_engine(\"sqlite:///sc-data-all.db\") # (1)!\nsession = Session(engine) # (2)!\nserver = session.exec(select(Server).where(Server.server_id == 'trn1.32xlarge')).one() # (3)!\n\nfrom rich import print as pp # (4)!\npp(server)\npp(server.vendor) # (5)!\n</code></pre> <ol> <li>Creating a connection (pool) to the SQLite database.</li> <li>Define an in-memory representation of the database for the ORM objects.</li> <li>Query the database for the Server with the <code>trn1.32xlarge</code> id.</li> <li>Use <code>rich</code> to pretty-print the objects.</li> <li>The <code>vendor</code> is a Vendor relationship of the Server, in this case being aws.</li> </ol>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#v036-feb-26-2026","title":"v0.3.6 (Feb 26, 2026)","text":"<p>New feature(s):</p> <ul> <li>Add <code>__version__</code> and <code>__version_info__</code> variables to the package.</li> </ul>"},{"location":"CHANGELOG/#v035-feb-26-2026","title":"v0.3.5 (Feb 26, 2026)","text":"<p>Fix(es):</p> <ul> <li>Add support for Azure Denmark East region (Copenhagen).</li> <li>Fix SCD table schema generation in CLI <code>create</code> command.</li> <li>Replace deprecated <code>datetime.utcnow()</code> calls with <code>datetime.now(UTC)</code>.</li> <li>Add field deserializers and reconstructors to <code>cpus</code>, <code>gpus</code>, <code>storages</code>, and <code>price_tiered</code> columns to prevent   Pydantic serialization   warnings and to preserve the original data types when loading from the database.</li> <li>Fix and extend test cases for field serializers and OVH vendor module.</li> <li>Add Provisioned IOPS (io1, io2) storage types and update gp3 volume limits (IOPS, throughput, size) for AWS.</li> <li>Fix <code>DynamicDocstrings</code> griffe extension to accept the new <code>agent</code> keyword argument introduced in griffe 0.49.0.</li> <li>Pin <code>mkdocs&lt;2.0</code> as MkDocs 2.0 is incompatible with Material for MkDocs.</li> <li>Fix <code>mkdocs</code> build warnings and version incompatibilities.</li> </ul> <p>New feature(s):</p> <ul> <li>Record the monthly cap for ondemand prices.</li> </ul> <p>\u203c Breaking changes:</p> <ul> <li>Minimum required Python version upgraded from 3.9 to 3.11.</li> </ul>"},{"location":"CHANGELOG/#v034-feb-05-2026","title":"v0.3.4 (Feb 05, 2026)","text":"<p>Fix(es):</p> <ul> <li>Add storage infos from lshw outputs to GCP servers.</li> <li>Check region availability for Alibaba Cloud servers before adding their prices.</li> <li>Determine CPU allocation type for Alibaba Cloud servers.</li> <li>Preserve vendor API data by default, only overriding when necessary for known API data issues.</li> <li>Verify Alibaba Cloud instance type retirement status.</li> <li>Prevent duplicate records from being inserted into the database.</li> </ul> <p>New feature(s):</p> <ul> <li>CLI tool to dump database tables to JSON files.</li> <li>Implement Alibaba Cloud's spot instance price sampling.</li> <li>Support for fractional GPU counts in server instances with partial GPU allocation.</li> </ul> <p>Housekeeping:</p> <ul> <li>Delay method validation to avoid CLI startup slowdown.</li> <li>Avoid name conflict in vendor modules via private modules.</li> <li>Convert all prices to float and round to 4 digits.</li> <li>Change gpu_count field type from integer to float for fractional GPU support.</li> <li>Remove foreign key constraints from SCD table definitions.</li> <li>Reset Alembic revision history and rewrite initial migration script.</li> </ul>"},{"location":"CHANGELOG/#v033-jan-02-2026","title":"v0.3.3 (Jan 02, 2026)","text":"<p>New vendor(s):</p> <ul> <li>Alibaba Cloud</li> </ul> <p>Fix(es):</p> <ul> <li>Don't include instruction cache in L1 cache size.</li> <li>Manufacturer of Ampere Altra.</li> </ul>"},{"location":"CHANGELOG/#v032-dec-04-2025","title":"v0.3.2 (Dec 04, 2025)","text":"<p>New vendor(s):</p> <ul> <li>UpCloud</li> <li>OVHcloud</li> </ul> <p>New benchmark(s):</p> <ul> <li>PassMark</li> <li>LLM inference speed</li> </ul> <p>Fix(es):</p> <ul> <li>Minor region and server detail overrides.</li> </ul>"},{"location":"CHANGELOG/#v031-oct-25-2024","title":"v0.3.1 (Oct 25, 2024)","text":"<p>New benchmark(s):</p> <ul> <li>Static HTTP server</li> <li>Redis</li> <li>stress-ng's div16 run on all vCPUs</li> </ul> <p>New feature(s):</p> <ul> <li>Optional list of tables to be synced in the CLI tool.</li> <li>Standardized CPU and GPU manufacturer, family, and model name.</li> <li>Optional description for Disks.</li> </ul> <p>Fix(es):</p> <ul> <li>Better support for long-running DB syncs.</li> <li>Exlude dummy \"2 Ghz\" CPU speed reported by GCP.</li> <li>Improved physical CPU cores lookup.</li> <li>Improved performance for interactive bulk inserts.</li> <li>Review how vendors reports on storage size using base 2 or 10.</li> <li>Update from Azure's deprecated API endpoint, fix ingesting NVMe drives.</li> <li>Better support for Azure API rate limits.</li> </ul>"},{"location":"CHANGELOG/#v030-aug-20-2024","title":"v0.3.0 (Aug 20, 2024)","text":"<p>New vendor(s):</p> <ul> <li>Microsoft Azure</li> </ul> <p>New feature(s):</p> <ul> <li>Support for new <code>hcloud</code> CX server types.</li> <li>Support for new <code>hcloud</code> region (Singapore).</li> <li>Improved caching.</li> </ul> <p>Fix(es):</p> <ul> <li>Join references pointing to the right tables.</li> <li>Count CPU cores in all physical CPUs.</li> <li>Improve the standardization and cleanup of the CPU manufacturer, family, and model.</li> <li>Extract speed from CPU description when available instead of unreliable <code>dmidecode</code> data.</li> <li>Update included outbound network extractor at <code>hcloud</code> due to API change.</li> <li>Check if a server is available in a <code>gcp</code> zone even though a related price is known.</li> <li>Silence <code>SAWarning</code> on multiple relationships using overlapping compound foreign keys.</li> <li>Fix manually collected geolocation of 3 <code>gcp</code> regions.</li> <li>Fix spelling issues in benchmark and table column descriptions.</li> </ul> <p>\u203c Breaking changes:</p> <ul> <li>Complex queries with joins relying on the foreign keys of the table   definitions are now using the right references. This might result in   different (but correct) results than before.</li> </ul>"},{"location":"CHANGELOG/#v021-june-4-2024","title":"v0.2.1 (June 4, 2024)","text":"<p>Fix(es):</p> <ul> <li>Sort <code>dict</code> by its keys before passing as JSON to the database engine.</li> </ul>"},{"location":"CHANGELOG/#v020-june-4-2024","title":"v0.2.0 (June 4, 2024)","text":"<p>Database migrations:</p> <ul> <li>Name all constraints for easier management in the future.</li> <li>Rename the <code>datacenter</code> table to <code>region</code>, and the <code>datacenter_id</code>   column to <code>region_id</code> in the <code>zone</code>, <code>server_price</code>,   <code>storage_price</code>, <code>traffic_price</code> and <code>ipv4_price</code> tables.</li> </ul> <p>\u203c Breaking changes:</p> <ul> <li>Renamed Datacenter to Region in all tables and across the codebase.</li> </ul>"},{"location":"CHANGELOG/#v014-june-2-2024","title":"v0.1.4 (June 2, 2024)","text":"<p>New feature(s):</p> <ul> <li>Documented <code>benchmark</code> workloads and actual <code>benchmark_score</code> records loaded from <code>sparecores-inspector-data</code>.</li> <li>Enriched <code>server</code> details loaded from <code>sparecores-inspector-data</code>.</li> </ul> <p>Database migrations:</p> <ul> <li>Add <code>benchmark</code> and <code>benchmark_score</code> tables.</li> <li>Add 8 new columns to the <code>server</code> table.</li> </ul> <p>\u203c Breaking changes:</p> <ul> <li>Renamed the <code>memory</code> column to <code>memory_amount</code> in the <code>server</code> table.</li> </ul>"},{"location":"CHANGELOG/#v013-may-7-2024","title":"v0.1.3 (May 7, 2024)","text":"<p>New feature(s):</p> <ul> <li>Add <code>api_reference</code> and <code>display_name</code> to <code>Datacenter</code>, <code>Zone</code>, and <code>Server</code>.</li> <li>Add latitude and longitude coordinates to <code>Datacenter</code>.</li> <li>Add <code>family</code> to <code>Server</code>.</li> </ul>"},{"location":"CHANGELOG/#v012-apr-24-2024","title":"v0.1.2 (Apr 24, 2024)","text":"<p>New vendor(s):</p> <ul> <li>Google Cloud Platform (GCP)</li> </ul> <p>New feature(s):</p> <ul> <li>SVG logo for all supported vendors.</li> </ul> <p>Fix(es):</p> <ul> <li>Amazon Web Services' missed outbound traffic prices</li> <li>Hetzner Cloud's outbound traffic price per GB instead of TB</li> <li>Hetzner Cloud's <code>datacenter_id</code> reference in the server prices table</li> </ul>"},{"location":"CHANGELOG/#v011-apr-12-2024","title":"v0.1.1 (Apr 12, 2024)","text":"<p>New vendors:</p> <ul> <li>Hetzner Cloud</li> </ul> <p>Infrastructure:</p> <ul> <li>Use Alembic for database migrations.</li> </ul> <p>CLI tools:</p> <ul> <li>Database migration helpers.</li> <li>Moved CREATE TABLE generator subcommand under <code>schemas create</code>.</li> </ul> <p>Database migrations:</p> <ul> <li>Add <code>description</code> field to <code>Server</code>.</li> <li>Update <code>Server.cpu_cores</code> to be optional.</li> </ul> <p>\u203c Breaking changes:</p> <p>As the database migration tool was just introduced, if you have been already using SC Crawler to initialize a database and collect data (e.g. in SCD tables), you will need to let Alembic know that you are already on v0.1.0 via the below command:</p> <pre><code>sc-crawler schemas stamp --revision 98894dffd37c\n</code></pre>"},{"location":"CHANGELOG/#v010-apr-05-2024","title":"v0.1.0 (Apr 05, 2024)","text":"<p>Initial PyPI release of <code>sparecores-crawler</code>.</p> <p>CLI tools:</p> <ul> <li>Generate database schema for standard and SCD tables of the   supported records in various SQL dialects.</li> <li>Pull records from vendor APIs and update a database with the fetched   records.</li> <li>Copy all supported tables from a database into another one.</li> <li>Sync records of a database into another database's standard or SCD   tables, with optional logging of the changes.</li> <li>Hash database content.</li> </ul> <p>Supported vendors:</p> <ul> <li>Amazon Web Services (AWS)</li> </ul> <p>Supported records:</p> <ul> <li>country</li> <li>compliance_framework</li> <li>vendor</li> <li>vendor_compliance_link</li> <li>datacenter</li> <li>zone</li> <li>server</li> <li>server_price</li> <li>storage</li> <li>storage_price</li> <li>traffic_price</li> <li>ipv4_price</li> </ul> <p>Infrastructure:</p> <ul> <li>Package documentation via MkDocs, Material for MkDocs,   <code>mkdocstrings</code>, and bunch of other MkDocs plugins.</li> <li>Database documentation on table schemas, relations and column   comments via DBML and dbdocs.</li> <li>Unit tests via <code>pytest</code>.</li> <li>Linting via <code>ruff</code>.</li> </ul>"},{"location":"add_vendor/","title":"Vendor support","text":"<p>Each file in the <code>src/sc_crawler/vendors</code> folder provides the required helpers for a given Vendor, named as the <code>id</code> of the vendor prefixed with an underscore. For example, <code>_aws.py</code> provides functions to be used by its Vendor instance, called <code>aws</code>.</p>"},{"location":"add_vendor/#first-steps","title":"First steps","text":"<ol> <li>Define the new Vendor instance in <code>src/sc_crawler/vendors/vendors.py</code>.</li> <li>Copy the below template file as a starting point to <code>src/sc_crawler/vendors/_&lt;vendor_id&gt;.py</code>.</li> <li>Update <code>src/sc_crawler/vendors/__init__.py</code> to include the new vendor.</li> <li>Update <code>docs/add_vendor.md</code> with the credential requirements for the new vendor.</li> <li>Implement the <code>inventory</code> methods.</li> </ol>"},{"location":"add_vendor/#inventory-methods","title":"Inventory methods","text":"<p>Each vendor module should provide the below functions:</p> <ul> <li><code>inventory_compliance_frameworks</code>: Define <code>VendorComplianceLink</code> instances to describe which frameworks the vendor complies with. Optionally include references in the <code>comment</code> field. To avoid duplicating <code>ComplianceFramework</code> instances, easiest is to use the <code>compliance_framework_id</code> field instead of the <code>compliance_framework</code> relationship, preferably via sc_crawler.lookup.map_compliance_frameworks_to_vendor.</li> <li><code>inventory_regions</code>: Define <code>Region</code> instances with location, energy source etc for each region the vendor has.</li> <li><code>inventory_zones</code>: Define a <code>Zone</code> instance for each availability zone of the vendor in each region.</li> <li><code>inventory_servers</code>: Define <code>Server</code> instances for the vendor's server/instance types.</li> <li><code>inventory_server_prices</code>: Define the <code>ServerPrice</code> instances for the standard/ondemand (or optionally also for the reserved) pricing of the instance types per region and zone. When applicable, include the monthly cap for tiered pricing in the <code>price_tiered</code> field.</li> <li><code>inventory_server_prices_spot</code>: Similar to the above, define <code>ServerPrice</code> instances but the <code>allocation</code> field set to <code>Allocation.SPOT</code>. Very likely to see different spot prices per region/zone.</li> <li><code>inventory_storage_prices</code>: Define <code>StoragePrice</code> instances to describe the available storage options that can be attached to the servers.</li> <li><code>inventory_traffic_prices</code>: Define <code>TrafficPrice</code> instances to describe the pricing of ingress/egress traffic.</li> <li><code>inventory_ipv4_prices</code>: Define <code>Ipv4Price</code> instances on the price of an IPv4 address.</li> </ul> <p>Each function will be picked up as the related Vendor instance's instance methods, so each function should take a single argument, that is the Vendor instance. E.g. sc_crawler.vendors._aws.inventory_regions is called by sc_crawler.tables.Vendor.inventory_regions.</p> <p>The functions should return an array of dict representing the related objects. The vendor's <code>inventory</code> method will pass the array to sc_crawler.insert.insert_items along with the table object.</p> <p>Other functions and variables must be prefixed with an underscore to suggest those are internal tools.</p>"},{"location":"add_vendor/#progress-bars","title":"Progress bars","text":"<p>To create progress bars, you can use the Vendor's progress_tracker attribute with the below methods:</p> <ul> <li>start_task</li> <li>advance_task</li> <li>hide_task</li> </ul> <p>The start_task will register a task in the \"Current tasks\" progress bar list with the provided name automatically prefixed by the vendor name, and the provided number of expected steps. You should call advance_task after each step finished, which will by default update the most recently created task's progress bar. If making updates in parallel, store the <code>TaskID</code> returned by start_task and pass to advance_task and hide_task explicitly. Make sure to call <code>hide_task</code> when the progress bar is not to be shown anymore. It's a good practice to log the number of fetched/synced objects afterwards with <code>logger.info</code>. See the manual of <code>VendorProgressTracker</code> for more details.</p> <p>Basic example:</p> <pre><code>def inventory_zones(vendor):\n    zones = range(5)\n    vendor.progress_tracker.start_task(name=\"Searching zones\", total=len(zones))\n    for zone in zones:\n        # do something\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return zones\n</code></pre>"},{"location":"add_vendor/#template-file-for-new-vendors","title":"Template file for new vendors","text":"<pre><code>def inventory_compliance_frameworks(vendor):\n    return map_compliance_frameworks_to_vendor(vendor.vendor_id, [\n    #    \"hipaa\",\n    #    \"soc2t2\",\n    #    \"iso27001\",\n    ])\n\n\ndef inventory_regions(vendor):\n    items = []\n    # for region in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": \"\",\n    #             \"name\": \"\",\n    #             \"api_reference\": \"\",\n    #             \"display_name\": \"\",\n    #             \"aliases\": [],\n    #             \"country_id\": \"\",\n    #             \"state\": None,\n    #             \"city\": None,\n    #             \"address_line\": None,\n    #             \"zip_code\": None,\n    #             \"lon\": None,\n    #             \"lat\": None,\n    #             \"founding_year\": None,\n    #             \"green_energy\": None,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_zones(vendor):\n    items =[]\n    # for zone in []:\n    #     items.append({\n    #         \"vendor_id\": vendor.vendor_id,\n    #         \"region_id\": \"\",\n    #         \"zone_id\": \"\",\n    #         \"name\": \"\",\n    #         \"api_reference\": \"\",\n    #         \"display_name\": \"\",\n    #     })\n    return items\n\n\ndef inventory_servers(vendor):\n    items = []\n    # for server in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"server_id\": ,\n    #             \"name\": ,\n    #             \"api_reference\": ,\n    #             \"display_name\": ,\n    #             \"description\": None,\n    #             \"family\": None,\n    #             \"vcpus\": ,\n    #             \"hypervisor\": None,\n    #             \"cpu_allocation\": CpuAllocation....,\n    #             \"cpu_cores\": None,\n    #             \"cpu_speed\": None,\n    #             \"cpu_architecture\": CpuArchitecture....,\n    #             \"cpu_manufacturer\": None,\n    #             \"cpu_family\": None,\n    #             \"cpu_model\": None,\n    #             \"cpu_l1_cache\": None,\n    #             \"cpu_l2_cache\": None,\n    #             \"cpu_l3_cache\": None,\n    #             \"cpu_flags\": [],\n    #             \"cpus\": [],\n    #             \"memory_amount\": ,\n    #             \"memory_generation\": None,\n    #             \"memory_speed\": None,\n    #             \"memory_ecc\": None,\n    #             \"gpu_count\": 0,\n    #             \"gpu_memory_min\": None,\n    #             \"gpu_memory_total\": None,\n    #             \"gpu_manufacturer\": None,\n    #             \"gpu_family\": None,\n    #             \"gpu_model\": None,\n    #             \"gpus\": [],\n    #             \"storage_size\": 0,\n    #             \"storage_type\": None,\n    #             \"storages\": [],\n    #             \"network_speed\": None,\n    #             \"inbound_traffic\": 0,\n    #             \"outbound_traffic\": 0,\n    #             \"ipv4\": 0,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_server_prices(vendor):\n    items = []\n    # for server in []:\n    #     items.append({\n    #         \"vendor_id\": ,\n    #         \"region_id\": ,\n    #         \"zone_id\": ,\n    #         \"server_id\": ,\n    #         \"operating_system\": ,\n    #         \"allocation\": Allocation....,\n    #         \"unit\": PriceUnit.HOUR,\n    #         \"price\": ,\n    #         \"price_upfront\": 0,\n    #         \"price_tiered\": [\n    #             {\"lower\": 0, \"upper\": monthly_cap, \"price\": hourly_price},\n    #             {\"lower\": monthly_cap + 1, \"upper\": \"Infinity\", \"price\": 0},\n    #         ],\n    #         \"currency\": \"USD\",\n    #     })\n    return items\n\n\ndef inventory_server_prices_spot(vendor):\n    return []\n\n\ndef inventory_storages(vendor):\n    items = []\n    # for storage in []:\n    #     items.append(\n    #         {\n    #             \"storage_id\": ,\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"name\": ,\n    #             \"description\": None,\n    #             \"storage_type\": StorageType....,\n    #             \"max_iops\": None,\n    #             \"max_throughput\": None,\n    #             \"min_size\": None,\n    #             \"max_size\": None,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_storage_prices(vendor):\n    items = []\n    # for price in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": ,\n    #             \"storage_id\": ,\n    #             \"unit\": PriceUnit.GB_MONTH,\n    #             \"price\": ,\n    #             \"currency\": \"USD\",\n    #         }\n    #     )\n    return items\n\n\ndef inventory_traffic_prices(vendor):\n    items = []\n    # for price in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": ,\n    #             \"price\": ,\n    #             \"price_tiered\": [],\n    #             \"currency\": \"USD\",\n    #             \"unit\": PriceUnit.GB_MONTH,\n    #             \"direction\": TrafficDirection....,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_ipv4_prices(vendor):\n    items = []\n    # for price in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": ,\n    #             \"price\": ,\n    #             \"currency\": \"USD\",\n    #             \"unit\": PriceUnit.MONTH,\n    #         }\n    #     )\n    return items\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>sc_crawler<ul> <li>alembic_helpers</li> <li>cli</li> <li>insert</li> <li>inspector</li> <li>logger</li> <li>lookup</li> <li>str_utils</li> <li>table_bases</li> <li>table_fields</li> <li>tables</li> <li>tables_scd</li> <li>utils</li> <li>vendor_helpers</li> <li>vendors<ul> <li>_alicloud</li> <li>_aws</li> <li>_azure</li> <li>_gcp</li> <li>_hcloud</li> <li>_ovh</li> <li>_upcloud</li> <li>vendors</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/sc_crawler/","title":"sc_crawler","text":""},{"location":"reference/sc_crawler/#sc_crawler","title":"sc_crawler","text":"<p>Spare Cores crawler: collect and standardize cloud server offerings data.</p> <p>Modules:</p> Name Description <code>alembic_helpers</code> <code>cli</code> <p>The Spare Cores (SC) Crawler CLI functions.</p> <code>insert</code> <code>inspector</code> <code>logger</code> <code>lookup</code> <code>str_utils</code> <code>table_bases</code> <p>Tiny helper classes for the most commonly used fields to be inherited by sc_crawler.tables.</p> <code>table_fields</code> <p>Enumerations, JSON nested data objects &amp; other helper classes used in sc_crawler.tables.</p> <code>tables</code> <p>Table definitions for vendors, regions, zones, and other cloud resources.</p> <code>tables_scd</code> <p>SCD version of the table definitions in sc_crawler.tables.</p> <code>utils</code> <code>vendor_helpers</code> <code>vendors</code> <p>Helper methods for each cloud compute resource provider.</p>"},{"location":"reference/sc_crawler/alembic_helpers/","title":"alembic_helpers","text":""},{"location":"reference/sc_crawler/alembic_helpers/#sc_crawler.alembic_helpers","title":"sc_crawler.alembic_helpers","text":"<p>Functions:</p> Name Description <code>alembic_cfg</code> <p>Loads the Alembic config and sets some dynamic attributes.</p> <code>get_revision</code> <p>Get current revision of alembic in a database connection.</p>"},{"location":"reference/sc_crawler/alembic_helpers/#sc_crawler.alembic_helpers.alembic_cfg","title":"alembic_cfg","text":"<pre><code>alembic_cfg(connection, scd=None, force_logging=True)\n</code></pre> <p>Loads the Alembic config and sets some dynamic attributes.</p> Source code in <code>sc_crawler/alembic_helpers.py</code> <pre><code>def alembic_cfg(\n    connection, scd: Optional[bool] = None, force_logging: bool = True\n) -&gt; Config:\n    \"\"\"Loads the Alembic config and sets some dynamic attributes.\"\"\"\n    alembic_cfg = Config(join(pkg_folder, \"alembic.ini\"))\n    alembic_cfg.attributes[\"force_logging\"] = force_logging\n    if scd is not None:\n        alembic_cfg.attributes[\"scd\"] = scd\n    alembic_cfg.attributes[\"connection\"] = connection\n    alembic_cfg.set_main_option(\"script_location\", join(pkg_folder, \"alembic\"))\n    return alembic_cfg\n</code></pre>"},{"location":"reference/sc_crawler/alembic_helpers/#sc_crawler.alembic_helpers.get_revision","title":"get_revision","text":"<pre><code>get_revision(connection, version_table='zzz_alembic_version')\n</code></pre> <p>Get current revision of alembic in a database connection.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>SQLAlchemy connection to look up revision in <code>version_table</code></p> required <code>version_table</code> <code>str</code> <p>name of the table storing revision</p> <code>'zzz_alembic_version'</code> Source code in <code>sc_crawler/alembic_helpers.py</code> <pre><code>def get_revision(\n    connection: Connection, version_table: str = \"zzz_alembic_version\"\n) -&gt; str:\n    \"\"\"Get current revision of alembic in a database connection.\n\n    Args:\n        connection: SQLAlchemy connection to look up revision in `version_table`\n        version_table: name of the table storing revision\"\"\"\n    return MigrationContext.configure(\n        connection, opts={\"version_table\": version_table}\n    ).get_current_revision()\n</code></pre>"},{"location":"reference/sc_crawler/cli/","title":"cli","text":""},{"location":"reference/sc_crawler/cli/#sc_crawler.cli","title":"sc_crawler.cli","text":"<p>The Spare Cores (SC) Crawler CLI functions.</p> <p>Check <code>sc-crawler --help</code> for more details.</p> <p>Functions:</p> Name Description <code>create</code> <p>Print the database schema in a SQL dialect.</p> <code>current</code> <p>Show current database revision.</p> <code>upgrade</code> <p>Upgrade the database schema to a given (default: most recent) revision.</p> <code>downgrade</code> <p>Downgrade the database schema to a given (default: previous) revision.</p> <code>stamp</code> <p>Set the migration revision mark in the database to a specified revision. Set to \"heads\" if the database schema is up-to-date.</p> <code>autogenerate</code> <p>Autogenerate a migrations script based on the current state of a database.</p> <code>hash_command</code> <p>Print the hash of the content of a database.</p> <code>copy</code> <p>Copy the standard SC Crawler tables of a database into a blank database.</p> <code>sync</code> <p>Sync a database to another one.</p> <code>dump</code> <p>Export database records to JSON files organized by primary keys.</p> <code>pull</code> <p>Pull data from available vendor APIs and store in a database.</p>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.create","title":"create","text":"<pre><code>create(connection_string=None, dialect=None, scd=False)\n</code></pre> <p>Print the database schema in a SQL dialect.</p> <p>Either <code>connection_string</code> or <code>dialect</code> is to be provided to decide what SQL dialect to use to generate the CREATE TABLE (and related) SQL statements.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef create(\n    connection_string: Annotated[\n        Optional[str], typer.Option(help=\"Database URL with SQLAlchemy dialect.\")\n    ] = None,\n    dialect: Annotated[\n        Optional[Engines],\n        typer.Option(\n            help=\"SQLAlchemy dialect to use for generating CREATE TABLE statements.\"\n        ),\n    ] = None,\n    scd: Annotated[\n        bool, typer.Option(help=\"If SCD Type 2 tables should be also created.\")\n    ] = False,\n):\n    \"\"\"\n    Print the database schema in a SQL dialect.\n\n    Either `connection_string` or `dialect` is to be provided to decide\n    what SQL dialect to use to generate the CREATE TABLE (and related)\n    SQL statements.\n    \"\"\"\n    if connection_string is None and dialect is None:\n        print(\"Either connection_string or dialect parameters needs to be provided!\")\n        raise typer.Exit(code=1)\n    if dialect:\n        url = engine_to_dialect[dialect.value]\n    else:\n        url = connection_string\n\n    def metadata_dump(sql, *_args, **_kwargs):\n        typer.echo(str(sql.compile(dialect=engine.dialect)) + \";\")\n\n    engine = create_mock_engine(url, metadata_dump)\n    if scd:\n        for table in tables_scd:\n            table.__table__.create(engine)\n    else:\n        for table in tables:\n            table.__table__.create(engine)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.current","title":"current","text":"<pre><code>current(connection_string='sqlite:///sc-data-all.db', scd=False)\n</code></pre> <p>Show current database revision.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef current(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    scd: options.scd = False,\n):\n    \"\"\"\n    Show current database revision.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.current(alembic_cfg(connection, scd))\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.upgrade","title":"upgrade","text":"<pre><code>upgrade(connection_string='sqlite:///sc-data-all.db', revision='heads', scd=False, sql=False)\n</code></pre> <p>Upgrade the database schema to a given (default: most recent) revision.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef upgrade(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    revision: options.revision = \"heads\",\n    scd: options.scd = False,\n    sql: options.sql = False,\n):\n    \"\"\"\n    Upgrade the database schema to a given (default: most recent) revision.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.upgrade(alembic_cfg(connection, scd), revision, sql)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.downgrade","title":"downgrade","text":"<pre><code>downgrade(connection_string='sqlite:///sc-data-all.db', revision='-1', scd=False, sql=False)\n</code></pre> <p>Downgrade the database schema to a given (default: previous) revision.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef downgrade(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    revision: options.revision = \"-1\",\n    scd: options.scd = False,\n    sql: options.sql = False,\n):\n    \"\"\"\n    Downgrade the database schema to a given (default: previous) revision.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.downgrade(alembic_cfg(connection, scd), revision, sql)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.stamp","title":"stamp","text":"<pre><code>stamp(connection_string='sqlite:///sc-data-all.db', revision='heads', scd=False, sql=False)\n</code></pre> <p>Set the migration revision mark in the database to a specified revision. Set to \"heads\" if the database schema is up-to-date.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef stamp(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    revision: options.revision = \"heads\",\n    scd: options.scd = False,\n    sql: options.sql = False,\n):\n    \"\"\"\n    Set the migration revision mark in the database to a specified revision. Set to \"heads\" if the database schema is up-to-date.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.stamp(alembic_cfg(connection, scd), revision, sql)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.autogenerate","title":"autogenerate","text":"<pre><code>autogenerate(connection_string='sqlite:///sc-data-all.db', message='empty message')\n</code></pre> <p>Autogenerate a migrations script based on the current state of a database.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef autogenerate(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    message: Annotated[\n        str,\n        typer.Option(help=\"Revision message, e.g. SC Crawler version number.\"),\n    ] = \"empty message\",\n):\n    \"\"\"\n    Autogenerate a migrations script based on the current state of a database.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.revision(\n            alembic_cfg(connection=connection), autogenerate=True, message=message\n        )\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.hash_command","title":"hash_command","text":"<pre><code>hash_command(connection_string='sqlite:///sc-data-all.db')\n</code></pre> <p>Print the hash of the content of a database.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command(name=\"hash\")\ndef hash_command(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n):\n    \"\"\"Print the hash of the content of a database.\"\"\"\n    print(hash_database(connection_string))\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.copy","title":"copy","text":"<pre><code>copy(source, target)\n</code></pre> <p>Copy the standard SC Crawler tables of a database into a blank database.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command()\ndef copy(\n    source: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) that is to be copied to `target`.\"\n        ),\n    ],\n    target: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) that is to be populated with the content of `source`.\"\n        ),\n    ],\n):\n    \"\"\"Copy the standard SC Crawler tables of a database into a blank database.\"\"\"\n\n    source_engine = create_engine(source, pool_pre_ping=True)\n    target_engine = create_engine(target, pool_pre_ping=True)\n\n    for table in tables:\n        table.__table__.create(target_engine)\n\n    progress = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    panel = Panel(progress, title=\"Copying tables\", expand=False)\n\n    with Live(panel):\n        for table in tables:\n            with Session(source_engine) as source_session:\n                rows = source_session.exec(statement=select(table))\n                items = [row.model_dump() for row in rows]\n            with Session(target_engine) as target_session:\n                insert_items(table, items, session=target_session, progress=progress)\n                target_session.commit()\n    with target_engine.begin() as connection:\n        command.stamp(alembic_cfg(connection), \"heads\")\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.sync","title":"sync","text":"<pre><code>sync(source, target, dry_run=False, scd=False, sync_tables=table_names, log_changes_path=None, log_changes_tables=table_names)\n</code></pre> <p>Sync a database to another one.</p> <p>Hashing both the <code>source</code> and the <code>target</code> databases, then comparing hashes and marking for syncing the following records:</p> <ul> <li> <p>new (rows with primary keys found in <code>source</code>, but not found in <code>target</code>)</p> </li> <li> <p>update (rows with different values in <code>source</code> and in <code>target</code>).</p> </li> <li> <p>inactive (rows with primary keys found in <code>target</code>, but not found in <code>source</code>).</p> </li> </ul> <p>The records marked for syncing are written to the <code>target</code> database's standard or SCD tables. When updating the SCD tables, the hashing still happens on the standard tables/views, which are probably based on the most recent records of the SCD tables.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command()\ndef sync(\n    source: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) to sync to `update` based on `target`.\"\n        ),\n    ],\n    target: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) to compare with `source`.\"\n        ),\n    ],\n    dry_run: Annotated[\n        bool,\n        typer.Option(help=\"Stop after comparing the databases, do NOT insert rows.\"),\n    ] = False,\n    scd: Annotated[\n        bool,\n        typer.Option(help=\"Sync the changes to the SCD tables.\"),\n    ] = False,\n    sync_tables: Annotated[\n        List[Tables],\n        typer.Option(help=\"Tables to be synced. Can be specified multiple times.\"),\n    ] = table_names,\n    log_changes_path: Annotated[\n        Path,\n        typer.Option(\n            help=\"Optional file path to log the list of new/updated/deleted records.\"\n        ),\n    ] = None,\n    log_changes_tables: Annotated[\n        List[Tables],\n        typer.Option(\n            help=\"New/updated/deleted rows of a table to be logged. Can be specified multiple times.\"\n        ),\n    ] = table_names,\n):\n    \"\"\"Sync a database to another one.\n\n    Hashing both the `source` and the `target` databases, then\n    comparing hashes and marking for syncing the following records:\n\n    - new (rows with primary keys found in `source`, but not found in `target`)\n\n    - update (rows with different values in `source` and in `target`).\n\n    - inactive (rows with primary keys found in `target`, but not found in `source`).\n\n    The records marked for syncing are written to the `target` database's\n    standard or SCD tables. When updating the SCD tables, the hashing still\n    happens on the standard tables/views, which are probably based on the\n    most recent records of the SCD tables.\n    \"\"\"\n\n    source_engine = create_engine(source, pool_pre_ping=True)\n    target_engine = create_engine(target, pool_pre_ping=True)\n\n    # compare source and target database revisions, halt if not matching\n    with source_engine.connect() as connection:\n        current_rev = get_revision(connection)\n    with target_engine.begin() as connection:\n        target_rev = get_revision(connection)\n    if current_rev != target_rev:\n        print(\n            \"Database revisions do NOT match, so not risking the sync. \"\n            \"Upgrade the database(s) before trying again!\"\n        )\n        raise typer.Exit(code=1)\n\n    ps = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    pt = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    g = Table.grid(padding=1)\n    g.add_row(\n        Panel(ps, title=\"Hashing source database\"),\n        Panel(pt, title=\"Hashing target database\"),\n    )\n\n    exclude_tables = [\n        t for t in tables if t.get_table_name() not in [t.value for t in sync_tables]\n    ]\n    with Live(g):\n        source_hash = hash_database(\n            source, level=HashLevels.ROW, progress=ps, exclude_tables=exclude_tables\n        )\n        target_hash = hash_database(\n            target, level=HashLevels.ROW, progress=pt, exclude_tables=exclude_tables\n        )\n    actions = {\n        k: {table: [] for table in source_hash.keys()}\n        for k in [\"update\", \"new\", \"deleted\"]\n    }\n\n    # enable logging\n    channel = ScRichHandler()\n    formatter = logging.Formatter(\"%(message)s\")\n    channel.setFormatter(formatter)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(channel)\n\n    ps = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    pt = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    g = Table.grid(padding=1)\n    g.add_row(\n        Panel(ps, title=\"Comparing source database with target\"),\n        Panel(pt, title=\"Comparing target database with source\"),\n    )\n    with Live(g):\n        # compare new records with old\n        with Session(source_engine) as session:\n            tables_task_id = ps.add_task(\"Comparing tables\", total=len(source_hash))\n            for table_name, items in source_hash.items():\n                table_task_id = ps.add_task(table_name, total=len(items))\n                model = table_name_to_model(table_name)\n                for pks_json, item in items.items():\n                    action = None\n                    try:\n                        if item != target_hash[table_name][pks_json]:\n                            action = \"update\"\n                    except KeyError:\n                        action = \"new\"\n                    if action:\n                        # get the new version of the record from the\n                        # source database and store as JSON for future update\n                        obj = get_row_by_pk(session, model, loads(pks_json))\n                        actions[action][table_name].append(obj.model_dump())\n                    ps.update(table_task_id, advance=1)\n                ps.update(tables_task_id, advance=1)\n\n        # compare old records with new\n        with Session(target_engine) as session:\n            tables_task_id = pt.add_task(\"Comparing tables\", total=len(target_hash))\n            for table_name, items in target_hash.items():\n                table_task_id = pt.add_task(table_name, total=len(items))\n                model = table_name_to_model(table_name)\n                for key, _ in items.items():\n                    if key not in source_hash[table_name]:\n                        # check if the row was already set to INACTIVE\n                        obj = get_row_by_pk(session, model, loads(key)).model_dump()\n                        if obj[\"status\"] != Status.INACTIVE:\n                            obj[\"status\"] = Status.INACTIVE\n                            obj[\"observed_at\"] = datetime.now(UTC)\n                            actions[\"deleted\"][table_name].append(obj)\n                    pt.update(table_task_id, advance=1)\n                pt.update(tables_task_id, advance=1)\n\n    stats = {ka: {ki: len(vi) for ki, vi in va.items()} for ka, va in actions.items()}\n    table = Table(title=\"Sync results\")\n    table.add_column(\"Table\", no_wrap=True)\n    table.add_column(\"New rows\", justify=\"right\")\n    table.add_column(\"Updated rows\", justify=\"right\")\n    table.add_column(\"Deleted rows\", justify=\"right\")\n    for table_name in source_hash.keys():\n        table.add_row(\n            table_name,\n            str(stats[\"new\"][table_name]),\n            str(stats[\"update\"][table_name]),\n            str(stats[\"deleted\"][table_name]),\n        )\n    console = Console()\n    console.print(table)\n\n    # log changes\n    if log_changes_path:\n        with open(log_changes_path, \"w\") as log_file:\n            for table_name, _ in source_hash.items():\n                if table_name in [t.value for t in log_changes_tables]:\n                    if (\n                        actions[\"new\"][table_name]\n                        or actions[\"update\"][table_name]\n                        or actions[\"deleted\"][table_name]\n                    ):\n                        model = table_name_to_model(table_name)\n                        pks = model.get_columns()[\"primary_keys\"]\n                        log_file.write(f\"\\n### {table_name}\\n\\n\")\n                        for action_types in [\"new\", \"update\", \"deleted\"]:\n                            for item in actions[action_types][table_name]:\n                                identifier = \"/\".join([item[key] for key in pks])\n                                log_file.write(\n                                    f\"- {action_types.title()}: {identifier}\\n\"\n                                )\n\n    if not dry_run:\n        progress = Progress(\n            TimeElapsedColumn(),\n            TextColumn(\"{task.description}\"),\n            BarColumn(),\n            MofNCompleteColumn(),\n        )\n        panel = Panel(progress, title=\"Updating target\", expand=False)\n        with Live(panel), Session(target_engine) as session:\n            for table_name, _ in source_hash.items():\n                model = table_name_to_model(table_name)\n                if scd:\n                    model = model.get_scd()\n                items = (\n                    actions[\"new\"][table_name]\n                    + actions[\"update\"][table_name]\n                    + actions[\"deleted\"][table_name]\n                )\n                if len(items):\n                    insert_items(model, items, session=session, progress=progress)\n                    logger.info(\"Updated %d %s(s) rows\" % (len(items), table_name))\n            session.commit()\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.dump","title":"dump","text":"<pre><code>dump(connection_string, output_directory=Path('.'), dump_tables=None, ignored=['observed_at'])\n</code></pre> <p>Export database records to JSON files organized by primary keys.</p> <p>Each record is written as a pretty-printed JSON file in a folder hierarchy based on the primary key values. For example, a server record with vendor_id='aws' and server_id='t3.small' would be written to: <code>output_directory/server/aws/t3.small.json</code></p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command()\ndef dump(\n    connection_string: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) to export from.\"\n        ),\n    ],\n    output_directory: Annotated[\n        Path,\n        typer.Option(help=\"Directory path where JSON files will be written.\"),\n    ] = Path(\".\"),\n    dump_tables: Annotated[\n        Optional[List[str]],\n        typer.Option(\n            help=\"Tables to be dumped. Can be specified multiple times. Defaults to all tables.\"\n        ),\n    ] = None,\n    ignored: Annotated[\n        List[str],\n        typer.Option(\n            help=\"Column names to exclude from JSON output. Can be specified multiple times.\"\n        ),\n    ] = [\"observed_at\"],\n):\n    \"\"\"\n    Export database records to JSON files organized by primary keys.\n\n    Each record is written as a pretty-printed JSON file in a folder\n    hierarchy based on the primary key values. For example, a server\n    record with vendor_id='aws' and server_id='t3.small' would be\n    written to: `output_directory/server/aws/t3.small.json`\n    \"\"\"\n    channel = ScRichHandler()\n    formatter = logging.Formatter(\"%(message)s\")\n    channel.setFormatter(formatter)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(channel)\n\n    engine = create_engine(connection_string, pool_pre_ping=True)\n    inspector = Inspector.from_engine(engine)\n    available_tables = inspector.get_table_names()\n    if dump_tables is None:\n        tables_to_dump = available_tables\n    else:\n        tables_to_dump = [t for t in dump_tables if t in available_tables]\n    if not tables_to_dump:\n        logger.warning(\"No tables to dump.\")\n        raise typer.Exit()\n\n    progress = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    panel = Panel(progress, title=\"Dumping tables\", expand=False)\n    with Live(panel), engine.connect() as connection:\n        tables_task = progress.add_task(\"Overall progress\", total=len(tables_to_dump))\n        for table_name in tables_to_dump:\n            pk_constraint = inspector.get_pk_constraint(table_name)\n            pk_columns = pk_constraint.get(\"constrained_columns\", [])\n\n            # record table schema\n            table_dir = output_directory / table_name\n            table_dir.mkdir(parents=True, exist_ok=True)\n            schema_file = table_dir / \"_schema.json\"\n            columns_info = inspector.get_columns(table_name)\n            schema = {\n                \"table_name\": table_name,\n                \"columns\": [\n                    {\n                        \"name\": col[\"name\"],\n                        \"type\": str(col[\"type\"]),\n                        \"nullable\": col.get(\"nullable\", True),\n                        \"default\": (\n                            str(col[\"default\"])\n                            if col.get(\"default\") is not None\n                            else None\n                        ),\n                        # no support for this in SQLite, though\n                        \"comment\": col.get(\"comment\"),\n                    }\n                    for col in columns_info\n                ],\n                \"primary_key\": pk_columns,\n                \"foreign_keys\": [\n                    {\n                        \"constrained_columns\": fk[\"constrained_columns\"],\n                        \"referred_table\": fk[\"referred_table\"],\n                        \"referred_columns\": fk[\"referred_columns\"],\n                    }\n                    for fk in inspector.get_foreign_keys(table_name)\n                ],\n                \"unique_constraints\": [\n                    {\"name\": uc.get(\"name\"), \"columns\": uc[\"column_names\"]}\n                    for uc in inspector.get_unique_constraints(table_name)\n                ],\n                \"indexes\": [\n                    {\n                        \"name\": idx[\"name\"],\n                        \"columns\": idx[\"column_names\"],\n                        \"unique\": idx.get(\"unique\", False),\n                    }\n                    for idx in inspector.get_indexes(table_name)\n                ],\n            }\n            with open(schema_file, \"w\") as f:\n                json_dump(schema, f, indent=2)\n\n            if not pk_columns:\n                logger.warning(f\"Table '{table_name}' has no primary key, skipping.\")\n                progress.update(tables_task, advance=1)\n                continue\n\n            count_result = connection.execute(\n                text(f\"SELECT COUNT(*) FROM {quoted_name(table_name, quote=True)}\")\n            )\n            row_count = count_result.scalar()\n            if row_count == 0:\n                logger.warning(f\"Table '{table_name}' is empty, skipping.\")\n                progress.update(tables_task, advance=1)\n                continue\n\n            table_task = progress.add_task(f\"{table_name}\", total=row_count)\n            result = connection.execute(\n                text(f\"SELECT * FROM {quoted_name(table_name, quote=True)}\")\n            )\n            column_names = list(result.keys())\n            # SQLite stores all nested objects as JSON strings that we need to parse back to objects\n            json_columns = {\n                col[\"name\"] for col in columns_info if \"JSON\" in str(col[\"type\"])\n            }\n\n            for row in result:\n                row_dict = dict(zip(column_names, row))\n                # try to parse JSON strings back to nested objects\n                for col_name in json_columns:\n                    if col_name in row_dict and row_dict[col_name] is not None:\n                        if isinstance(row_dict[col_name], str):\n                            with suppress(Exception):\n                                row_dict[col_name] = loads(row_dict[col_name])\n                for ignored_col in ignored:\n                    row_dict.pop(ignored_col, None)\n                # sanitize PK values for safe file paths (replace non-word chars)\n                pk_values = [sub(r\"[^\\w]\", \"_\", str(row_dict[pk])) for pk in pk_columns]\n                file_path = output_directory / table_name\n                if len(pk_values) &gt; 1:\n                    file_path = file_path / Path(*pk_values[:-1])\n                file_path = file_path / f\"{pk_values[-1]}.json\"\n                file_path.parent.mkdir(parents=True, exist_ok=True)\n                with open(file_path, \"w\") as f:\n                    json_dump(row_dict, f, indent=2)\n                progress.update(table_task, advance=1)\n            progress.update(tables_task, advance=1)\n\n    logger.info(f\"Dumped {len(tables_to_dump)} table(s) to '{output_directory}'\")\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.pull","title":"pull","text":"<pre><code>pull(connection_string='sqlite:///sc-data-all.db', include_vendor=[(vendor_id) for v in supported_vendors], exclude_vendor=[], include_records=supported_records, exclude_records=[], log_level=value, cache=False, cache_ttl=60 * 24)\n</code></pre> <p>Pull data from available vendor APIs and store in a database.</p> <p>Vendor API calls are optionally cached as Pickle objects in <code>~/.cachier</code>.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command()\ndef pull(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    include_vendor: Annotated[\n        List[Vendors],\n        typer.Option(help=\"Enabled data sources. Can be specified multiple times.\"),\n    ] = [v.vendor_id for v in supported_vendors],\n    exclude_vendor: Annotated[\n        List[Vendors],\n        typer.Option(help=\"Disabled data sources. Can be specified multiple times.\"),\n    ] = [],\n    include_records: Annotated[\n        List[Records],\n        typer.Option(\n            help=\"Database records to be updated. Can be specified multiple times.\"\n        ),\n    ] = supported_records,\n    exclude_records: Annotated[\n        List[Records],\n        typer.Option(\n            help=\"Database records NOT to be updated. Can be specified multiple times.\"\n        ),\n    ] = [],\n    log_level: Annotated[\n        LogLevels, typer.Option(help=\"Log level threshold.\")\n    ] = LogLevels.INFO.value,  # TODO drop .value after updating Enum to StrEnum in Python3.11\n    cache: Annotated[\n        bool,\n        typer.Option(help=\"Enable or disable caching of all vendor API calls on disk.\"),\n    ] = False,\n    cache_ttl: Annotated[\n        int,\n        typer.Option(help=\"Cache Time-to-live in minutes. Defaults to one day.\"),\n    ] = 60 * 24,  # 1 day\n):\n    \"\"\"\n    Pull data from available vendor APIs and store in a database.\n\n    Vendor API calls are optionally cached as Pickle objects in `~/.cachier`.\n    \"\"\"\n\n    def custom_serializer(x):\n        \"\"\"Use JSON serializer defined in custom objects.\"\"\"\n        return dumps(x, default=lambda x: x.__json__(), allow_nan=False)\n\n    # enable caching\n    if cache:\n        set_global_params(\n            caching_enabled=True,\n            stale_after=timedelta(minutes=cache_ttl),\n        )\n\n    # enable logging\n    channel = ScRichHandler()\n    formatter = logging.Formatter(\"%(message)s\")\n    channel.setFormatter(formatter)\n    logger.setLevel(log_level.value)\n    logger.addHandler(channel)\n\n    # filter vendors\n    vendors = [\n        vendor\n        for vendor in supported_vendors\n        if (\n            vendor.vendor_id in [iv.value for iv in include_vendor]\n            and vendor.vendor_id not in [ev.value for ev in exclude_vendor]\n        )\n    ]\n\n    # filter reocrds\n    records = [r for r in include_records if r not in exclude_records]\n\n    pbars = ProgressPanel()\n    with Live(pbars.panels):\n        # show CLI arguments in the Metadata panel\n        pbars.metadata.append(Text(\"Data sources: \", style=\"bold\"))\n        pbars.metadata.append(Text(\", \".join([x.vendor_id for x in vendors]) + \" \"))\n        pbars.metadata.append(Text(\"Updating records: \", style=\"bold\"))\n        pbars.metadata.append(Text(\", \".join([x.value for x in records]) + \"\\n\"))\n        pbars.metadata.append(Text(\"Connection type: \", style=\"bold\"))\n        pbars.metadata.append(Text(connection_string.split(\":\")[0]))\n        pbars.metadata.append(Text(\" Cache: \", style=\"bold\"))\n        if cache:\n            pbars.metadata.append(Text(\"Enabled (\" + str(cache_ttl) + \"m)\"))\n        else:\n            pbars.metadata.append(Text(\"Disabled\"))\n        pbars.metadata.append(Text(\" Time: \", style=\"bold\"))\n        pbars.metadata.append(Text(str(datetime.now())))\n\n        # alembic upgrade to ensure using the most recent version of the schemas\n        engine = create_engine(\n            connection_string,\n            json_serializer=custom_serializer,\n            pool_pre_ping=True,\n        )\n        with engine.begin() as connection:\n            command.upgrade(alembic_cfg(connection, force_logging=False), \"heads\")\n\n        with Session(engine) as session:\n            # add/merge static objects to database\n            for compliance_framework in compliance_frameworks.values():\n                session.merge(compliance_framework)\n            logger.info(\"%d Compliance Frameworks synced.\" % len(compliance_frameworks))\n            for country in countries.values():\n                session.merge(country)\n            logger.info(\"%d Countries synced.\" % len(countries))\n            for benchmark in benchmarks:\n                session.merge(benchmark)\n            logger.info(\"%d Benchmarks synced.\" % len(benchmarks))\n            # get data for each vendor and then add/merge to database\n            # TODO each vendor should open its own session and run in parallel\n            for vendor in vendors:\n                logger.info(\"Starting to collect data from vendor: \" + vendor.vendor_id)\n                vendor = session.merge(vendor)\n                # register session to the Vendor so that dependen objects can auto-merge\n                vendor.session = session\n                # register progress bars so that helpers can update\n                vendor.progress_tracker = VendorProgressTracker(\n                    vendor=vendor, progress_panel=pbars\n                )\n                vendor.progress_tracker.start_vendor(total=len(records))\n                if Records.compliance_frameworks in records:\n                    vendor.inventory_compliance_frameworks()\n                if Records.regions in records:\n                    vendor.inventory_regions()\n                if Records.zones in records:\n                    vendor.inventory_zones()\n                if Records.servers in records:\n                    vendor.inventory_servers()\n                if Records.server_prices in records:\n                    vendor.inventory_server_prices()\n                if Records.server_prices_spot in records:\n                    vendor.inventory_server_prices_spot()\n                if Records.storages in records:\n                    vendor.inventory_storages()\n                if Records.storage_prices in records:\n                    vendor.inventory_storage_prices()\n                if Records.traffic_prices in records:\n                    vendor.inventory_traffic_prices()\n                if Records.ipv4_prices in records:\n                    vendor.inventory_ipv4_prices()\n                # reset current step name\n                vendor.progress_tracker.update_vendor(step=\"\u2714\")\n                session.merge(vendor)\n                session.commit()\n\n        pbars.metadata.append(Text(\" - \" + str(datetime.now())))\n</code></pre>"},{"location":"reference/sc_crawler/insert/","title":"insert","text":""},{"location":"reference/sc_crawler/insert/#sc_crawler.insert","title":"sc_crawler.insert","text":"<p>Functions:</p> Name Description <code>can_bulk_insert</code> <p>Checks if bulk insert is supported for the engine dialect of a SQLModel session.</p> <code>validate_items</code> <p>Validates a list of items against a pydantic.BaseModel definition.</p> <code>bulk_insert_items</code> <p>Bulk inserts items into a SQLModel table with <code>ON CONFLICT</code> update.</p> <code>insert_items</code> <p>Insert items into the related database table using bulk or merge.</p>"},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.can_bulk_insert","title":"can_bulk_insert","text":"<pre><code>can_bulk_insert(session)\n</code></pre> <p>Checks if bulk insert is supported for the engine dialect of a SQLModel session.</p> Source code in <code>sc_crawler/insert.py</code> <pre><code>def can_bulk_insert(session: Session) -&gt; bool:\n    \"\"\"Checks if bulk insert is supported for the engine dialect of a SQLModel session.\"\"\"\n    return is_sqlite(session) or is_postgresql(session)\n</code></pre>"},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.validate_items","title":"validate_items","text":"<pre><code>validate_items(model, items, vendor=None, prefix='')\n</code></pre> <p>Validates a list of items against a pydantic.BaseModel definition.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>An SQLModel model to be used for validation.</p> required <code>items</code> <code>List[dict]</code> <p>List of dictionaries to be checked against <code>model</code>.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional Vendor instance used for logging and progress bar updates.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional extra description for the model added in front of the model name in logs and progress bar updates.</p> <code>''</code> <p>Returns:</p> Type Description <code>List[dict]</code> <p>List of validated dicts in the same order. Note that missing fields has been filled in with default values (needed for bulk inserts).</p> Source code in <code>sc_crawler/insert.py</code> <pre><code>def validate_items(\n    model: BaseModel,\n    items: List[dict],\n    vendor: Optional[\"Vendor\"] = None,\n    prefix: str = \"\",\n) -&gt; List[dict]:\n    \"\"\"Validates a list of items against a [pydantic.BaseModel][] definition.\n\n    Args:\n        model: An SQLModel model to be used for validation.\n        items: List of dictionaries to be checked against `model`.\n        vendor: Optional Vendor instance used for logging and progress bar updates.\n        prefix: Optional extra description for the model added in front of\n            the model name in logs and progress bar updates.\n\n    Returns:\n        List of validated dicts in the same order. Note that missing fields\n            has been filled in with default values (needed for bulk inserts).\n    \"\"\"\n    model_name = model.get_table_name()\n    # use the Pydantic data model for validation instead of the table definition\n    schema = model.__validator__\n    if vendor:\n        vendor.progress_tracker.start_task(\n            name=f\"Validating {space_after(prefix)}{model_name}(s)\", total=len(items)\n        )\n    for i, item in enumerate(items):\n        items[i] = schema.model_validate(item).model_dump()\n        if vendor:\n            vendor.progress_tracker.advance_task()\n    if vendor:\n        vendor.progress_tracker.hide_task()\n        vendor.log(\n            \"%d %s%s(s) objects validated\"\n            % (len(items), space_after(prefix), model_name),\n            DEBUG,\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.bulk_insert_items","title":"bulk_insert_items","text":"<pre><code>bulk_insert_items(model, items, vendor=None, session=None, progress=None, prefix='')\n</code></pre> <p>Bulk inserts items into a SQLModel table with <code>ON CONFLICT</code> update.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>SQLModel</code> <p>An SQLModel table definition with primary key(s).</p> required <code>items</code> <code>List[dict]</code> <p>List of dicts with all columns of the model.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional related Vendor instance used for logging and progress bar updates.</p> <code>None</code> <code>session</code> <code>Optional[Session]</code> <p>Optional database connections. When not provided, defaults to the <code>vendor</code>'s session.</p> <code>None</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to use instead of <code>vendor</code>'s progress bar.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional extra description for the model added in front of the model name in logs and progress bar updates.</p> <code>''</code> Source code in <code>sc_crawler/insert.py</code> <pre><code>def bulk_insert_items(\n    model: SQLModel,\n    items: List[dict],\n    vendor: Optional[\"Vendor\"] = None,\n    session: Optional[Session] = None,\n    progress: Optional[Progress] = None,\n    prefix: str = \"\",\n):\n    \"\"\"Bulk inserts items into a SQLModel table with `ON CONFLICT` update.\n\n    Args:\n        model: An SQLModel table definition with primary key(s).\n        items: List of dicts with all columns of the model.\n        vendor: Optional related Vendor instance used for logging and progress bar updates.\n        session: Optional database connections. When not provided, defaults to the `vendor`'s session.\n        progress: Optional progress bar to use instead of `vendor`'s progress bar.\n        prefix: Optional extra description for the model added in front of\n            the model name in logs and progress bar updates.\n    \"\"\"\n    if session is None:\n        if vendor is None:\n            raise TypeError(\"At least one of `session` or `vendor` is required.\")\n        session = vendor.session\n    model_name = model.get_table_name()\n    columns = model.get_columns()\n    if progress:\n        pid = progress.add_task(\n            f\"Inserting {space_after(prefix)}{model_name}(s)\", total=len(items)\n        )\n    elif vendor:\n        pid = vendor.progress_tracker.start_task(\n            name=f\"Inserting {space_after(prefix)}{model_name}(s)\", total=len(items)\n        )\n        progress = vendor.progress_tracker.tasks\n    # need to split list into smaller chunks to avoid \"too many SQL variables\"\n    for chunk in chunk_list(items, 100):\n        if is_sqlite(session):\n            query = insert_sqlite(model).values(chunk)\n        elif is_postgresql(session):\n            query = insert_postgresql(model).values(chunk)\n        else:\n            raise NotImplementedError(\n                \"Unsupported database engine dialect for bulk inserts.\"\n            )\n        query = query.on_conflict_do_update(\n            index_elements=[getattr(model, c) for c in columns[\"primary_keys\"]],\n            set_={c: query.excluded[c] for c in columns[\"attributes\"]},\n        )\n        session.execute(query)\n        if progress:\n            progress.update(pid, advance=len(chunk))\n\n    if vendor:\n        vendor.progress_tracker.hide_task()\n        vendor.log(f\"{len(items)} {space_after(prefix)}{model_name}(s) synced.\")\n</code></pre>"},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.insert_items","title":"insert_items","text":"<pre><code>insert_items(model, items, vendor=None, session=None, progress=None, prefix='')\n</code></pre> <p>Insert items into the related database table using bulk or merge.</p> <p>Bulk insert is only supported with SQLite, other databases fall back to the default session.merge (slower) approach.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>SQLModel</code> <p>An SQLModel table definition with primary key(s).</p> required <code>items</code> <code>List[dict]</code> <p>List of dicts with all columns of the model.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional related Vendor instance used for database connection, logging and progress bar updates.</p> <code>None</code> <code>session</code> <code>Optional[Session]</code> <p>Optional database connections. When not provided, defaults to the <code>vendor</code>'s session.</p> <code>None</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to use instead of <code>vendor</code>'s progress bar.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional extra description for the model added in front of the model name in logs and progress bar updates.</p> <code>''</code> Source code in <code>sc_crawler/insert.py</code> <pre><code>def insert_items(\n    model: SQLModel,\n    items: List[dict],\n    vendor: Optional[\"Vendor\"] = None,\n    session: Optional[Session] = None,\n    progress: Optional[Progress] = None,\n    prefix: str = \"\",\n):\n    \"\"\"Insert items into the related database table using bulk or merge.\n\n    Bulk insert is only supported with SQLite, other databases fall back to\n    the default session.merge (slower) approach.\n\n    Args:\n        model: An SQLModel table definition with primary key(s).\n        items: List of dicts with all columns of the model.\n        vendor: Optional related Vendor instance used for database connection, logging and progress bar updates.\n        session: Optional database connections. When not provided, defaults to the `vendor`'s session.\n        progress: Optional progress bar to use instead of `vendor`'s progress bar.\n        prefix: Optional extra description for the model added in front of\n            the model name in logs and progress bar updates.\n    \"\"\"\n    if session is None:\n        if vendor is None:\n            raise TypeError(\"At least one of `session` or `vendor` is required.\")\n        session = vendor.session\n    model_name = model.get_table_name()\n\n    # Deduplicate items based on primary keys to avoid ON CONFLICT errors in PostgreSQL\n    columns = model.get_columns()\n    primary_keys = columns[\"primary_keys\"]\n\n    seen = defaultdict(list)\n    item_keys = []\n    for item in items:\n        # all primary keys are nullable=False, so can safely convert to string for hashing\n        key = tuple(str(item.get(pk)) for pk in primary_keys)\n        item_keys.append(key)\n        seen[key].append(item)\n\n    duplicates_found = False\n    for occurrences in seen.values():\n        if len(occurrences) &gt; 1:\n            if not duplicates_found:\n                if vendor:\n                    duplicates_count = sum(\n                        len(v) - 1 for v in seen.values() if len(v) &gt; 1\n                    )\n                    vendor.log(\n                        f\"Found {duplicates_count} duplicate(s) in {space_after(prefix)}{model_name} items\",\n                    )\n                duplicates_found = True\n\n    unique_items = []\n    seen_keys = set()\n    for key, item in reversed(list(zip(item_keys, items))):\n        if key not in seen_keys:\n            seen_keys.add(key)\n            unique_items.append(item)\n\n    unique_items.reverse()\n    items = unique_items\n\n    if can_bulk_insert(session):\n        items = validate_items(model, items, vendor, prefix)\n        bulk_insert_items(model, items, vendor, session, progress, prefix)\n    else:\n        if vendor:\n            vendor.progress_tracker.start_task(\n                name=f\"Syncing {space_after(prefix)}{model_name}(s)\", total=len(items)\n            )\n        if progress:\n            pid = progress.add_task(\n                f\"Inserting {space_after(prefix)}{model_name}(s)\", total=len(items)\n            )\n        for item in items:\n            # vendor's auto session.merge doesn't work due to SQLmodel bug:\n            # - https://github.com/tiangolo/sqlmodel/issues/6\n            # - https://github.com/tiangolo/sqlmodel/issues/342\n            # so need to trigger the merge manually\n            session.merge(model.model_validate(item))\n            if vendor:\n                vendor.progress_tracker.advance_task()\n            if progress:\n                progress.update(pid, advance=1)\n        if vendor:\n            vendor.progress_tracker.hide_task()\n            vendor.log(f\"{len(items)} {space_after(prefix)}{model_name}(s) synced.\")\n</code></pre>"},{"location":"reference/sc_crawler/inspector/","title":"inspector","text":""},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector","title":"sc_crawler.inspector","text":"<p>Functions:</p> Name Description <code>inspector_data_path</code> <p>Download current inspector data into a temp folder.</p> <code>inspect_server_benchmarks</code> <p>Generate a list of BenchmarkScore-like dicts for the Server.</p> <code>inspect_update_server_dict</code> <p>Update a Server-like dict based on inspector data.</p>"},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector.inspector_data_path","title":"inspector_data_path  <code>cached</code>","text":"<pre><code>inspector_data_path()\n</code></pre> <p>Download current inspector data into a temp folder.</p> <p>Setting the <code>SC_CRAWLER_INSPECTOR_DATA_PATH</code> environment variable will override the default path for persistent/cached inspector data access.</p> Source code in <code>sc_crawler/inspector.py</code> <pre><code>@cache\ndef inspector_data_path() -&gt; str | PathLike:\n    \"\"\"Download current inspector data into a temp folder.\n\n    Setting the `SC_CRAWLER_INSPECTOR_DATA_PATH` environment variable will\n    override the default path for persistent/cached inspector data access.\n    \"\"\"\n    if getenv(\"SC_CRAWLER_INSPECTOR_DATA_PATH\"):\n        temp_dir = getenv(\"SC_CRAWLER_INSPECTOR_DATA_PATH\")\n        makedirs(temp_dir, exist_ok=True)\n    else:\n        temp_dir = mkdtemp()\n        register(rmtree, temp_dir)\n    zip_path = path.join(temp_dir, \"downloaded.zip\")\n    if not path.exists(zip_path):\n        response = get(\n            \"https://github.com/SpareCores/sc-inspector-data/archive/refs/heads/main.zip\"\n        )\n        with open(zip_path, \"wb\") as f:\n            f.write(response.content)\n        with ZipFile(zip_path, \"r\") as zip_ref:\n            zip_ref.extractall(temp_dir)\n    return path.join(temp_dir, \"sc-inspector-data-main\", \"data\")\n</code></pre>"},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector.inspect_server_benchmarks","title":"inspect_server_benchmarks","text":"<pre><code>inspect_server_benchmarks(server)\n</code></pre> <p>Generate a list of BenchmarkScore-like dicts for the Server.</p> Source code in <code>sc_crawler/inspector.py</code> <pre><code>def inspect_server_benchmarks(server: \"Server\") -&gt; List[dict]:\n    \"\"\"Generate a list of BenchmarkScore-like dicts for the Server.\"\"\"\n    benchmarks = []\n\n    framework = \"bogomips\"\n    try:\n        benchmarks.append(\n            {\n                **_benchmark_metafields(\n                    server, framework=\"lscpu\", benchmark_id=framework\n                ),\n                \"score\": round(float(_server_lscpu_field(server, \"BogoMIPS:\"))),\n            }\n        )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e)\n\n    framework = \"bw_mem\"\n    try:\n        with open(_server_framework_stdout_path(server, framework), \"r\") as lines:\n            for line in lines:\n                # filter out error messages\n                if match(r\"^(rd|wr|rdwr) \\d+(\\.\\d+) \\d+(\\.\\d+)$\", line):\n                    row = line.strip().split()\n                    benchmarks.append(\n                        {\n                            **_benchmark_metafields(server, framework=framework),\n                            \"config\": {\"operation\": row[0], \"size\": float(row[1])},\n                            \"score\": float(row[2]),\n                        }\n                    )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e)\n\n    framework = \"compression_text\"\n    try:\n        algos = _server_framework_stdout_from_json(server, framework)\n        for algo, levels in algos.items():\n            for level, datas in levels.items():\n                for data in datas:\n                    config = {\n                        \"algo\": algo,\n                        \"compression_level\": None if level == \"null\" else int(level),\n                        \"threads\": data[\"threads\"],\n                    }\n                    if data.get(\"extra_args\", {}).get(\"block_size\"):\n                        config[\"block_size\"] = data[\"extra_args\"][\"block_size\"]\n                    for measurement in [\"ratio\", \"compress\", \"decompress\"]:\n                        if data[measurement]:\n                            benchmarks.append(\n                                {\n                                    **_benchmark_metafields(\n                                        server,\n                                        benchmark_id=\":\".join([framework, measurement]),\n                                    ),\n                                    \"config\": config,\n                                    \"score\": float(data[measurement]),\n                                }\n                            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"geekbench\"\n    try:\n        with open(_server_framework_path(server, framework, \"results.json\"), \"r\") as fp:\n            scores = json.load(fp)\n        geekbench_version = _server_framework_meta(server, framework)[\"version\"]\n        for cores, workloads in scores.items():\n            for workload, values in workloads.items():\n                workload_fields = {\n                    \"config\": {\"cores\": cores, \"framework_version\": geekbench_version},\n                    \"score\": float(values[\"score\"]),\n                }\n                if values.get(\"description\"):\n                    workload_fields[\"note\"] = values[\"description\"]\n                benchmarks.append(\n                    {\n                        **_benchmark_metafields(\n                            server,\n                            benchmark_id=\":\".join(\n                                [framework, sub(r\"\\W+\", \"_\", workload.lower())]\n                            ),\n                        ),\n                        **workload_fields,\n                    }\n                )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"passmark\"\n    try:\n        with open(_server_framework_stdout_path(server, framework), \"r\") as fp:\n            scores = yaml_safe_load(fp)\n        passmark_version = \".\".join(\n            [str(scores[\"Version\"][i]) for i in [\"Major\", \"Minor\", \"Build\"]]\n        )\n        for key, name in PASSMARK_MAPS.items():\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        benchmark_id=\":\".join(\n                            [framework, sub(r\"\\W+\", \"_\", name.lower())]\n                        ),\n                    ),\n                    \"config\": {\"framework_version\": passmark_version},\n                    \"score\": float(scores[\"Results\"][key]),\n                }\n            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"openssl\"\n    try:\n        with open(_server_framework_path(server, framework, \"parsed.json\"), \"r\") as fp:\n            workloads = json.load(fp)\n        openssl_version = _server_framework_meta(server, framework)[\"version\"]\n        for workload in workloads:\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(server, framework=framework),\n                    \"config\": {\n                        \"algo\": workload[\"algo\"],\n                        \"block_size\": workload[\"block_size\"],\n                        \"framework_version\": openssl_version,\n                    },\n                    \"score\": float(workload[\"speed\"]),\n                }\n            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"stress_ng\"\n    # TODO deprecate\n    try:\n        cores_per_path = {\"stressng\": server.vcpus, \"stressngsinglecore\": 1}\n        for cores_path in cores_per_path.keys():\n            stressng_version = _server_framework_meta(server, cores_path)[\"version\"]\n            line = _extract_line_from_file(\n                _server_framework_stderr_path(server, cores_path),\n                \"bogo-ops-per-second-real-time\",\n            )\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        framework=cores_path,\n                        benchmark_id=\":\".join([framework, \"cpu_all\"]),\n                    ),\n                    \"config\": {\n                        \"cores\": cores_per_path[cores_path],\n                        \"framework_version\": stressng_version,\n                    },\n                    \"score\": float(line.split(\": \")[1]),\n                }\n            )\n    except Exception:\n        # backfill with newer method - can be dropped once we deprecate stress_ng:cpu_all\n        try:\n            records = []\n            with open(\n                _server_framework_stdout_path(server, \"stressngfull\"), newline=\"\"\n            ) as f:\n                rows = csv.reader(f, quoting=csv.QUOTE_NONNUMERIC)\n                for row in rows:\n                    records.append(row)\n            for i in [0, len(records) - 1]:\n                stressng_version = _server_framework_meta(server, \"stressngfull\")[\n                    \"version\"\n                ]\n                benchmarks.append(\n                    {\n                        **_benchmark_metafields(\n                            server,\n                            framework=\"stressngfull\",\n                            benchmark_id=\":\".join([framework, \"cpu_all\"]),\n                        ),\n                        \"config\": {\n                            \"cores\": records[i][0],\n                            \"framework_version\": stressng_version,\n                        },\n                        \"score\": records[i][1],\n                    }\n                )\n        except Exception as e:\n            _log_cannot_load_benchmarks(server, framework, e, True)\n\n    workload = \"div16\"\n    try:\n        records = []\n        with open(\n            _server_framework_stdout_path(server, \"stressngfull\"), newline=\"\"\n        ) as f:\n            rows = csv.reader(f, quoting=csv.QUOTE_NONNUMERIC)\n            for row in rows:\n                records.append(row)\n        for record in records:\n            stressng_version = _server_framework_meta(server, \"stressngfull\")[\"version\"]\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        framework=\"stressngfull\",\n                        benchmark_id=\":\".join([framework, workload]),\n                    ),\n                    \"config\": {\n                        \"cores\": record[0],\n                        \"framework_version\": stressng_version,\n                    },\n                    \"score\": record[1],\n                }\n            )\n        # best single and multi core performance\n        bests = {\"best1\": records[0][1], \"bestn\": max([r[1] for r in records])}\n        for k, v in bests.items():\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        framework=\"stressngfull\",\n                        benchmark_id=\":\".join([framework, k]),\n                    ),\n                    \"config\": {\n                        \"framework_version\": stressng_version,\n                    },\n                    \"score\": v,\n                }\n            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    for framework in SERVER_CLIENT_FRAMEWORK_MAPS.keys():\n        try:\n            versions = _server_framework_meta(server, framework)[\"version\"]\n            # drop the build number at the end of the redis server version\n            if framework == \"redis\":\n                versions = sub(r\" build=[a-zA-Z0-9]+\", \"\", versions)\n\n            records = []\n            with open(\n                _server_framework_stdout_path(server, framework), newline=\"\"\n            ) as f:\n                rows = csv.DictReader(f, quoting=csv.QUOTE_NONNUMERIC)\n                for row in rows:\n                    if \"connections\" in row.keys():\n                        row[\"connections_per_vcpus\"] = row[\"connections\"] / server.vcpus\n                    records.append(row)\n\n            framework_config = SERVER_CLIENT_FRAMEWORK_MAPS[framework]\n            keys = framework_config[\"keys\"]\n            measurements = framework_config[\"measurements\"]\n\n            # don't care about threads, keep the records with the highest rps\n            records = sorted(records, key=lambda x: (*[x[k] for k in keys], -x[\"rps\"]))\n            records = groupby(records, key=itemgetter(*keys))\n            records = [next(group) for _, group in records]\n\n            for record in records:\n                for measurement in measurements:\n                    score_field = measurement.split(\"-\")[0]\n                    if score_field == \"throughput\":\n                        score_field = \"rps\"\n                    score = record[score_field]\n                    server_usrsys = record[\"server_usr\"] + record[\"server_sys\"]\n                    client_usrsys = record[\"client_usr\"] + record[\"client_sys\"]\n                    note = (\n                        \"CPU usage (server/client usr+sys): \"\n                        f\"{round(server_usrsys, 4)}/{round(client_usrsys, 4)}.\"\n                    )\n                    if measurement.endswith(\"-extrapolated\"):\n                        note += f\" Original RPS: {score}.\"\n                        score = round(\n                            score / server_usrsys * (server_usrsys + client_usrsys), 2\n                        )\n                    if measurement.startswith(\"throughput\"):\n                        # drop the \"k\" suffix and multiply by 1024\n                        size = int(record[\"size\"][:-1]) * 1024\n                        score = score * size\n                    benchmarks.append(\n                        {\n                            **_benchmark_metafields(\n                                server,\n                                framework=framework,\n                                benchmark_id=\":\".join([framework, measurement]),\n                            ),\n                            \"config\": {\n                                **{k: record[k] for k in keys},\n                                \"framework_version\": versions,\n                            },\n                            \"score\": score,\n                            \"note\": note,\n                        }\n                    )\n        except Exception as e:\n            _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"llm_speed\"\n    try:\n        assert _server_framework_meta(server, \"llm\")[\"exit_code\"] == 0\n        llm_speed_version = _server_framework_meta(server, \"llm\")[\"version\"]\n        with open(_server_framework_stdout_path(server, \"llm\"), \"r\") as fp:\n            for line in fp:\n                record = json.loads(line)\n                model_name = path.basename(record.get(\"model_filename\", \"unknown\"))\n                measurement = \"text_generation\"\n                if record.get(\"n_prompt\") != 0:\n                    measurement = \"prompt_processing\"\n                tokens = record.get(\"n_prompt\") + record.get(\"n_gen\")\n                config = {\n                    \"model\": model_name,\n                    \"tokens\": tokens,\n                    \"framework_version\": llm_speed_version,\n                }\n                benchmarks.append(\n                    {\n                        **_benchmark_metafields(\n                            server,\n                            framework=\"llm\",\n                            benchmark_id=\":\".join([framework, measurement]),\n                        ),\n                        \"config\": config,\n                        \"score\": float(record[\"avg_ts\"]),\n                    }\n                )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    return benchmarks\n</code></pre>"},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector.inspect_update_server_dict","title":"inspect_update_server_dict","text":"<pre><code>inspect_update_server_dict(server)\n</code></pre> <p>Update a Server-like dict based on inspector data.</p> Source code in <code>sc_crawler/inspector.py</code> <pre><code>def inspect_update_server_dict(server: dict) -&gt; dict:\n    \"\"\"Update a Server-like dict based on inspector data.\"\"\"\n    server_obj = ServerBase.validate(server)\n\n    lookups = {\n        \"dmidecode_cpu\": lambda: _server_dmidecode_section(\n            server_obj, \"Processor Information\"\n        ),\n        \"dmidecode_cpus\": lambda: _server_dmidecode_sections(\n            server_obj, \"Processor Information\"\n        ),\n        \"dmidecode_memory\": lambda: _server_dmidecode_section(\n            server_obj, \"Memory Device\"\n        ),\n        \"lscpu\": lambda: _server_lscpu(server_obj),\n        \"lshw\": lambda: _server_lshw(server_obj),\n        \"nvidiasmi\": lambda: _server_nvidiasmi(server_obj),\n        \"gpu\": lambda: lookups[\"nvidiasmi\"].find(\"gpu\"),\n        \"gpus\": lambda: lookups[\"nvidiasmi\"].findall(\"gpu\"),\n    }\n    for k, f in lookups.items():\n        try:\n            lookups[k] = f()\n        except Exception as e:\n            lookups[k] = Exception(str(e))\n\n    def lscpu_lookup(field: str):\n        return _listsearch(lookups[\"lscpu\"], \"field\", field)[\"data\"]\n\n    # Parse lshw storage info once (empty dict if lshw lookup failed)\n    lshw_storage_info = (\n        {}\n        if isinstance(lookups[\"lshw\"], Exception)\n        else _parse_lshw_storage_info(lookups[\"lshw\"], server_obj)\n    )\n\n    def get_cpu_speed():\n        \"\"\"Extract CPU speed from lscpu or dmidecode.\"\"\"\n        # lscpu is more reliable, extracting from \"Model name: ... @ X.XGHz\"\n        speed = None\n        with suppress(Exception):\n            cpu_model = lscpu_lookup(\"Model name:\")\n            match = search(r\" @ ([0-9\\.]*)GHz$\", cpu_model)\n            if match:\n                speed = float(match.group(1))\n        # fall back to dmidecode\n        if not speed:\n            with suppress(Exception):\n                # use 1st CPU's speed, convert to Ghz\n                speed = lookups[\"dmidecode_cpu\"][\"Max Speed\"] / 1e9\n        # 2 GHz CPU speed is a lie at GCP\n        if server_obj.vendor_id == \"gcp\" and speed == 2:\n            speed = None\n        return speed\n\n    def get_cpu_manufacturer():\n        \"\"\"Extract CPU manufacturer from lscpu or dmidecode.\"\"\"\n        with suppress(Exception):\n            cpu_model = lscpu_lookup(\"Model name:\")\n            for manufacturer in [\"Intel\", \"AMD\", \"Ampere\"]:\n                if manufacturer.lower() in cpu_model.lower():\n                    return manufacturer\n        # fall back to dmidecode\n        with suppress(Exception):\n            return _standardize_manufacturer(lookups[\"dmidecode_cpu\"][\"Manufacturer\"])\n        # no CPU manufacturer data available\n        return None\n\n    def get_cpu_family():\n        \"\"\"Extract CPU family from lscpu or dmidecode.\"\"\"\n        with suppress(Exception):\n            cpu_model = lscpu_lookup(\"Model name:\")\n            for family in [\"Xeon\", \"EPYC\", \"Altra\"]:\n                if family.lower() in cpu_model.lower():\n                    return family\n        # fall back to dmidecode\n        with suppress(Exception):\n            return _standardize_cpu_family(lookups[\"dmidecode_cpu\"][\"Family\"])\n        # no CPU family data available\n        return None\n\n    def get_cpu_model():\n        \"\"\"Extract CPU model from lscpu or dmidecode.\"\"\"\n        with suppress(Exception):\n            return _standardize_cpu_model(lscpu_lookup(\"Model name:\"))\n        with suppress(Exception):\n            return _standardize_cpu_model(lookups[\"dmidecode_cpu\"][\"Version\"])\n        return None\n\n    mappings = {\n        \"vcpus\": lambda: lscpu_lookup(\"CPU(s):\"),\n        \"cpu_cores\": lambda: (\n            int(lscpu_lookup(\"Core(s) per socket:\")) * int(lscpu_lookup(\"Socket(s):\"))\n        ),\n        \"cpu_speed\": lambda: get_cpu_speed(),\n        \"cpu_manufacturer\": lambda: get_cpu_manufacturer(),\n        \"cpu_family\": lambda: get_cpu_family(),\n        \"cpu_model\": lambda: get_cpu_model(),\n        \"cpu_l1_cache\": lambda: _l123_cache(lookups[\"lscpu\"], 1),\n        \"cpu_l2_cache\": lambda: _l123_cache(lookups[\"lscpu\"], 2),\n        \"cpu_l3_cache\": lambda: _l123_cache(lookups[\"lscpu\"], 3),\n        \"cpu_flags\": lambda: lscpu_lookup(\"Flags:\").split(\" \"),\n        \"memory_generation\": lambda: DdrGeneration[lookups[\"dmidecode_memory\"][\"Type\"]],\n        # convert to Mhz\n        \"memory_speed\": lambda: int(lookups[\"dmidecode_memory\"][\"Speed\"]) / 1e6,\n        \"gpus\": lambda: _gpus_details(lookups[\"gpus\"]),\n        \"gpu_manufacturer\": lambda: _gpu_most_common(server[\"gpus\"], \"manufacturer\"),\n        \"gpu_family\": lambda: _gpu_most_common(server[\"gpus\"], \"family\"),\n        \"gpu_model\": lambda: _gpu_most_common(server[\"gpus\"], \"model\"),\n        # skip update if there is no HW-inspected GPU info\n        \"gpu_count\": lambda: len(server[\"gpus\"]) if len(server[\"gpus\"]) else None,\n        \"gpu_memory_min\": lambda: min([gpu[\"memory\"] for gpu in server[\"gpus\"]]),\n        \"gpu_memory_total\": lambda: sum([gpu[\"memory\"] for gpu in server[\"gpus\"]]),\n        # skip storage update if lshw parsing failed or API data is present\n        \"storage_type\": lambda: lshw_storage_info.get(\"storage_type\"),\n        \"storage_size\": lambda: lshw_storage_info.get(\"storage_size\"),\n        \"storages\": lambda: lshw_storage_info.get(\"storages\"),\n    }\n\n    def override_mapping(server, field, inspector_data):\n        \"\"\"Decide whether to override vendor-provided server data with inspector data.\n\n        Args:\n            server: Server-like dict with vendor-provided data.\n            field: Server table column name.\n            inspector_data: New data provided by inspector.\n\n        Returns:\n            The data provided by inspector, or the vendor.\n        \"\"\"\n        vendor_id = server.get(\"vendor_id\")\n        vendor_data = server.get(field)\n\n        # TODO drop once we have full lsblk coverage\n        # always override GCP fields where vendor data is known to be missing\n        storage_fields = [\"storage_type\", \"storage_size\", \"storages\"]\n        if vendor_id == \"gcp\" and field in [\"gpu_model\", *storage_fields]:\n            return inspector_data\n        # don't trust HDD/SSD inspection data at other vendors yet\n        if vendor_id != \"gcp\" and field in storage_fields:\n            return vendor_data\n\n        # keep inspector data for detailed fields that's not available from vendor API\n        if (\n            field == \"gpus\"\n            and inspector_data\n            and isinstance(inspector_data, list)\n            and len(inspector_data) &gt; 0\n            and inspector_data[0].get(\"bios_version\")\n        ):\n            return inspector_data\n        # never override vendor data with None\n        if inspector_data is None:\n            return vendor_data\n        # return inspector data if vendor data is missing\n        if not vendor_data:\n            return inspector_data\n        # last resort: keep vendor data\n        return vendor_data\n\n    for k, f in mappings.items():\n        try:\n            newval = f()\n            if newval:\n                server[k] = override_mapping(server, k, newval)\n        except Exception as e:\n            _log_cannot_update_server(server_obj, k, e)\n\n    # standardize GPU model\n    if server.get(\"gpu_model\"):\n        server[\"gpu_model\"] = _standardize_gpu_model(server[\"gpu_model\"], server)\n        server[\"gpu_family\"] = _standardize_gpu_family(server)\n        if not server.get(\"gpu_manufacturer\") and server[\"gpu_model\"] == \"A100\":\n            server[\"gpu_manufacturer\"] = \"NVIDIA\"\n\n    return server\n</code></pre>"},{"location":"reference/sc_crawler/logger/","title":"logger","text":""},{"location":"reference/sc_crawler/logger/#sc_crawler.logger","title":"sc_crawler.logger","text":"<p>Classes:</p> Name Description <code>ScRichHandler</code> <p>Extend RichHandler with function name logged in the right column.</p> <code>VendorProgressTracker</code> <p>Tracking the progress of the vendor's inventory updates.</p> <code>VoidProgressTracker</code> <p>Progress tracker reference not doing antyhing.</p> <p>Functions:</p> Name Description <code>log_start_end</code> <p>Log the start and end of the decorated function.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.log_start_end","title":"log_start_end","text":"<pre><code>log_start_end(func)\n</code></pre> <p>Log the start and end of the decorated function.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def log_start_end(func):\n    \"\"\"Log the start and end of the decorated function.\"\"\"\n\n    def wrap(*args, **kwargs):\n        # log start of the step\n        try:\n            self = args[0]\n            fname = f\"{self.vendor_id}/{func.__name__}\"\n        except Exception:\n            fname = func.__name__\n        logger.debug(\"Starting %s\", fname)\n\n        # update Vendor's progress bar with the step name\n        try:\n            self.progress_tracker.update_vendor(\n                # drop `inventory_` prefix and prettify\n                step=func.__name__[10:].replace(\"_\", \" \")\n            )\n        except Exception:\n            logger.error(\"Cannot update step name in the Vendor's progress bar.\")\n\n        # actually run step\n        result = func(*args, **kwargs)\n\n        # increment Vendor's progress bar\n        self.progress_tracker.advance_vendor()\n\n        # log end of the step and return\n        logger.debug(\"Finished %s\", fname)\n        return result\n\n    return wrap\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.ScRichHandler","title":"ScRichHandler","text":"<p>               Bases: <code>RichHandler</code></p> <p>Extend RichHandler with function name logged in the right column.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>class ScRichHandler(RichHandler):\n    \"\"\"Extend RichHandler with function name logged in the right column.\"\"\"\n\n    def render(\n        self,\n        *,\n        record: logging.LogRecord,\n        traceback: Optional[Traceback],\n        message_renderable: \"ConsoleRenderable\",\n    ):\n        path = Path(record.pathname).name + \":\" + record.funcName\n        level = self.get_level_text(record)\n        time_format = None if self.formatter is None else self.formatter.datefmt\n        log_time = datetime.fromtimestamp(record.created)\n\n        log_renderable = self._log_render(\n            self.console,\n            [message_renderable] if not traceback else [message_renderable, traceback],\n            log_time=log_time,\n            time_format=time_format,\n            level=level,\n            path=path,\n            line_no=record.lineno,\n            link_path=record.pathname if self.enable_link_path else None,\n        )\n        return log_renderable\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker","title":"VendorProgressTracker","text":"<p>Tracking the progress of the vendor's inventory updates.</p> <p>Methods:</p> Name Description <code>start_vendor</code> <p>Starts a progress bar for the Vendor's steps.</p> <code>advance_vendor</code> <p>Increment the number of finished steps.</p> <code>update_vendor</code> <p>Update the vendor's progress bar.</p> <code>start_task</code> <p>Starts a progress bar in the list of current jobs.</p> <code>last_task</code> <p>Returh the last registered TaskID.</p> <code>advance_task</code> <p>Increment the number of finished steps.</p> <code>update_task</code> <p>Update the task's progress bar.</p> <code>hide_task</code> <p>Hide a task from the list of progress bars.</p> <p>Attributes:</p> Name Type Description <code>task_ids</code> <code>List[TaskID]</code> <p>List of active task ids for the current <code>vendor</code>.</p> <code>vendor</code> <code>Vendor</code> <p>A sc_crawler.tables.Vendor instance for which tracking progress.</p> <code>progress_panel</code> <code>ProgressPanel</code> <p>A <code>rich</code> panel including progress bars.</p> <code>vendors</code> <code>Progress</code> <p>rich.progress.Progress for tracking the inventory steps of the vendor.</p> <code>tasks</code> <code>Progress</code> <p>rich.progress.Progress for tracking the lower-level tasks within each step.</p> <code>metadata</code> <code>Text</code> <p>rich.text.Text metadata, e.g. data sources and records to be udpated.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>class VendorProgressTracker:\n    \"\"\"Tracking the progress of the vendor's inventory updates.\"\"\"\n\n    vendor: Vendor\n    \"\"\"A [sc_crawler.tables.Vendor][] instance for which tracking progress.\"\"\"\n    progress_panel: ProgressPanel\n    \"\"\"\n    A `rich` panel including progress bars.\n    Should not be used directly, see the `vendors`, `tasks` and `metadata` attributes.\n    \"\"\"\n    # reexport Progress attributes of the ProgressPanel\n    vendors: Progress\n    \"\"\"[rich.progress.Progress][] for tracking the inventory steps of the vendor.\"\"\"\n    tasks: Progress\n    \"\"\"[rich.progress.Progress][] for tracking the lower-level tasks within each step.\"\"\"\n    metadata: Text\n    \"\"\"[rich.text.Text][] metadata, e.g. data sources and records to be udpated.\"\"\"\n    task_ids: List[TaskID] = []\n    \"\"\"List of active task ids for the current `vendor`.\"\"\"\n\n    def __init__(self, vendor: Vendor, progress_panel: ProgressPanel):\n        self.vendor = vendor\n        self.progress_panel = progress_panel\n        self.vendors = progress_panel.vendors\n        self.tasks = progress_panel.tasks\n        self.metadata = progress_panel.metadata\n\n    def start_vendor(self, total: int) -&gt; TaskID:\n        \"\"\"Starts a progress bar for the Vendor's steps.\n\n        Args:\n            total: Overall number of steps to show in the progress bar.\n\n        Returns:\n            TaskId: The progress bar's identifier to be referenced in future updates.\n        \"\"\"\n        return self.vendors.add_task(self.vendor.name, total=total, step=\"\")\n\n    def advance_vendor(self, advance: int = 1) -&gt; None:\n        \"\"\"Increment the number of finished steps.\n\n        Args:\n            advance: Number of steps to advance.\n        \"\"\"\n        self.vendors.update(self.vendors.task_ids[-1], advance=advance)\n\n    def update_vendor(self, **kwargs) -&gt; None:\n        \"\"\"Update the vendor's progress bar.\n\n        Useful fields:\n        - `step`: Name of the currently running step to be shown on the progress bar.\n        \"\"\"\n        self.vendors.update(self.vendors.task_ids[-1], **kwargs)\n\n    def start_task(self, name: str, total: int) -&gt; TaskID:\n        \"\"\"Starts a progress bar in the list of current jobs.\n\n        Besides returning the `TaskID`, it will also register in `self.tasks.task_ids`\n        as the last task, which will be the default value for future `advance_task`,\n        `hide_task` etc calls. The latter will remove the `TaskID` from the `task_ids`.\n\n        Args:\n            name: Name to show in front of the progress bar. Will be prefixed by Vendor's name.\n            total: Overall number of steps to show in the progress bar.\n\n        Returns:\n            TaskId: The progress bar's identifier to be referenced in future updates.\n        \"\"\"\n        self.task_ids.append(\n            self.tasks.add_task(self.vendor.name + \": \" + name, total=total)\n        )\n        return self.last_task()\n\n    def last_task(self) -&gt; TaskID:\n        \"\"\"Returh the last registered TaskID.\"\"\"\n        return self.task_ids[-1]\n\n    def advance_task(self, task_id: Optional[TaskID] = None, advance: int = 1):\n        \"\"\"Increment the number of finished steps.\n\n        Args:\n            task_id: The progress bar's identifier returned by `start_task`.\n                Defaults to the most recently created task.\n            advance: Number of steps to advance.\n        \"\"\"\n\n        self.tasks.update(task_id or self.last_task(), advance=advance)\n\n    def update_task(self, task_id: Optional[TaskID] = None, **kwargs) -&gt; None:\n        \"\"\"Update the task's progress bar.\n\n        Args:\n            task_id: The progress bar's identifier returned by `start_task`.\n                Defaults to the most recently created task.\n\n        Keyword Args:\n            step (str): Name of the currently running step to be shown on the progress bar.\n\n        See [`rich.progress.Progress.update`][] for further keyword arguments.\n        \"\"\"\n        self.tasks.update(task_id or self.last_task(), **kwargs)\n\n    def hide_task(self, task_id: Optional[TaskID] = None):\n        \"\"\"Hide a task from the list of progress bars.\n\n        Args:\n            task_id: The progress bar's identifier returned by `start_task`.\n                Defaults to the most recently created task.\n        \"\"\"\n        self.tasks.update(task_id or self.last_task(), visible=False)\n        self.task_ids.pop()\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.task_ids","title":"task_ids  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>task_ids = []\n</code></pre> <p>List of active task ids for the current <code>vendor</code>.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.vendor","title":"vendor  <code>instance-attribute</code>","text":"<pre><code>vendor = vendor\n</code></pre> <p>A sc_crawler.tables.Vendor instance for which tracking progress.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.progress_panel","title":"progress_panel  <code>instance-attribute</code>","text":"<pre><code>progress_panel = progress_panel\n</code></pre> <p>A <code>rich</code> panel including progress bars. Should not be used directly, see the <code>vendors</code>, <code>tasks</code> and <code>metadata</code> attributes.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.vendors","title":"vendors  <code>instance-attribute</code>","text":"<pre><code>vendors = vendors\n</code></pre> <p>rich.progress.Progress for tracking the inventory steps of the vendor.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.tasks","title":"tasks  <code>instance-attribute</code>","text":"<pre><code>tasks = tasks\n</code></pre> <p>rich.progress.Progress for tracking the lower-level tasks within each step.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata = metadata\n</code></pre> <p>rich.text.Text metadata, e.g. data sources and records to be udpated.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.start_vendor","title":"start_vendor","text":"<pre><code>start_vendor(total)\n</code></pre> <p>Starts a progress bar for the Vendor's steps.</p> <p>Parameters:</p> Name Type Description Default <code>total</code> <code>int</code> <p>Overall number of steps to show in the progress bar.</p> required <p>Returns:</p> Name Type Description <code>TaskId</code> <code>TaskID</code> <p>The progress bar's identifier to be referenced in future updates.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def start_vendor(self, total: int) -&gt; TaskID:\n    \"\"\"Starts a progress bar for the Vendor's steps.\n\n    Args:\n        total: Overall number of steps to show in the progress bar.\n\n    Returns:\n        TaskId: The progress bar's identifier to be referenced in future updates.\n    \"\"\"\n    return self.vendors.add_task(self.vendor.name, total=total, step=\"\")\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.advance_vendor","title":"advance_vendor","text":"<pre><code>advance_vendor(advance=1)\n</code></pre> <p>Increment the number of finished steps.</p> <p>Parameters:</p> Name Type Description Default <code>advance</code> <code>int</code> <p>Number of steps to advance.</p> <code>1</code> Source code in <code>sc_crawler/logger.py</code> <pre><code>def advance_vendor(self, advance: int = 1) -&gt; None:\n    \"\"\"Increment the number of finished steps.\n\n    Args:\n        advance: Number of steps to advance.\n    \"\"\"\n    self.vendors.update(self.vendors.task_ids[-1], advance=advance)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.update_vendor","title":"update_vendor","text":"<pre><code>update_vendor(**kwargs)\n</code></pre> <p>Update the vendor's progress bar.</p> <p>Useful fields: - <code>step</code>: Name of the currently running step to be shown on the progress bar.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def update_vendor(self, **kwargs) -&gt; None:\n    \"\"\"Update the vendor's progress bar.\n\n    Useful fields:\n    - `step`: Name of the currently running step to be shown on the progress bar.\n    \"\"\"\n    self.vendors.update(self.vendors.task_ids[-1], **kwargs)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.start_task","title":"start_task","text":"<pre><code>start_task(name, total)\n</code></pre> <p>Starts a progress bar in the list of current jobs.</p> <p>Besides returning the <code>TaskID</code>, it will also register in <code>self.tasks.task_ids</code> as the last task, which will be the default value for future <code>advance_task</code>, <code>hide_task</code> etc calls. The latter will remove the <code>TaskID</code> from the <code>task_ids</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to show in front of the progress bar. Will be prefixed by Vendor's name.</p> required <code>total</code> <code>int</code> <p>Overall number of steps to show in the progress bar.</p> required <p>Returns:</p> Name Type Description <code>TaskId</code> <code>TaskID</code> <p>The progress bar's identifier to be referenced in future updates.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def start_task(self, name: str, total: int) -&gt; TaskID:\n    \"\"\"Starts a progress bar in the list of current jobs.\n\n    Besides returning the `TaskID`, it will also register in `self.tasks.task_ids`\n    as the last task, which will be the default value for future `advance_task`,\n    `hide_task` etc calls. The latter will remove the `TaskID` from the `task_ids`.\n\n    Args:\n        name: Name to show in front of the progress bar. Will be prefixed by Vendor's name.\n        total: Overall number of steps to show in the progress bar.\n\n    Returns:\n        TaskId: The progress bar's identifier to be referenced in future updates.\n    \"\"\"\n    self.task_ids.append(\n        self.tasks.add_task(self.vendor.name + \": \" + name, total=total)\n    )\n    return self.last_task()\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.last_task","title":"last_task","text":"<pre><code>last_task()\n</code></pre> <p>Returh the last registered TaskID.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def last_task(self) -&gt; TaskID:\n    \"\"\"Returh the last registered TaskID.\"\"\"\n    return self.task_ids[-1]\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.advance_task","title":"advance_task","text":"<pre><code>advance_task(task_id=None, advance=1)\n</code></pre> <p>Increment the number of finished steps.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>Optional[TaskID]</code> <p>The progress bar's identifier returned by <code>start_task</code>. Defaults to the most recently created task.</p> <code>None</code> <code>advance</code> <code>int</code> <p>Number of steps to advance.</p> <code>1</code> Source code in <code>sc_crawler/logger.py</code> <pre><code>def advance_task(self, task_id: Optional[TaskID] = None, advance: int = 1):\n    \"\"\"Increment the number of finished steps.\n\n    Args:\n        task_id: The progress bar's identifier returned by `start_task`.\n            Defaults to the most recently created task.\n        advance: Number of steps to advance.\n    \"\"\"\n\n    self.tasks.update(task_id or self.last_task(), advance=advance)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.update_task","title":"update_task","text":"<pre><code>update_task(task_id=None, **kwargs)\n</code></pre> <p>Update the task's progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>Optional[TaskID]</code> <p>The progress bar's identifier returned by <code>start_task</code>. Defaults to the most recently created task.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>step</code> <code>str</code> <p>Name of the currently running step to be shown on the progress bar.</p> <p>See <code>rich.progress.Progress.update</code> for further keyword arguments.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def update_task(self, task_id: Optional[TaskID] = None, **kwargs) -&gt; None:\n    \"\"\"Update the task's progress bar.\n\n    Args:\n        task_id: The progress bar's identifier returned by `start_task`.\n            Defaults to the most recently created task.\n\n    Keyword Args:\n        step (str): Name of the currently running step to be shown on the progress bar.\n\n    See [`rich.progress.Progress.update`][] for further keyword arguments.\n    \"\"\"\n    self.tasks.update(task_id or self.last_task(), **kwargs)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.hide_task","title":"hide_task","text":"<pre><code>hide_task(task_id=None)\n</code></pre> <p>Hide a task from the list of progress bars.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>Optional[TaskID]</code> <p>The progress bar's identifier returned by <code>start_task</code>. Defaults to the most recently created task.</p> <code>None</code> Source code in <code>sc_crawler/logger.py</code> <pre><code>def hide_task(self, task_id: Optional[TaskID] = None):\n    \"\"\"Hide a task from the list of progress bars.\n\n    Args:\n        task_id: The progress bar's identifier returned by `start_task`.\n            Defaults to the most recently created task.\n    \"\"\"\n    self.tasks.update(task_id or self.last_task(), visible=False)\n    self.task_ids.pop()\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VoidProgressTracker","title":"VoidProgressTracker","text":"<p>               Bases: <code>VendorProgressTracker</code></p> <p>Progress tracker reference not doing antyhing.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>class VoidProgressTracker(VendorProgressTracker):\n    \"\"\"Progress tracker reference not doing antyhing.\"\"\"\n\n    def __init__(*args, **kwargs):\n        pass\n\n    def start_vendor(self, *args, **kwargs):\n        pass\n\n    def advance_vendor(self, *args, **kwargs):\n        pass\n\n    def update_vendor(self, *args, **kwargs):\n        pass\n\n    def start_task(self, *args, **kwargs):\n        pass\n\n    def last_task(self, *args, **kwargs):\n        pass\n\n    def advance_task(self, *args, **kwargs):\n        pass\n\n    def update_task(self, *args, **kwargs):\n        pass\n\n    def hide_task(self, *args, **kwargs):\n        pass\n</code></pre>"},{"location":"reference/sc_crawler/lookup/","title":"lookup","text":""},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup","title":"sc_crawler.lookup","text":"<p>Functions:</p> Name Description <code>map_compliance_frameworks_to_vendor</code> <p>Map compliance frameworks to vendors in a dict.</p> <p>Attributes:</p> Name Type Description <code>countries</code> <code>dict</code> <p>Dictionary of sc_crawler.tables.Country instances keyed by the <code>country_id</code>.</p> <code>compliance_frameworks</code> <code>dict</code> <p>Dictionary of sc_crawler.tables.ComplianceFramework instances keyed by the <code>compliance_framework_id</code>.</p>"},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup.countries","title":"countries  <code>module-attribute</code>","text":"<pre><code>countries = {k: (Country(country_id=k, continent=v)) for k, v in (items())}\n</code></pre> <p>Dictionary of sc_crawler.tables.Country instances keyed by the <code>country_id</code>.</p>"},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup.compliance_frameworks","title":"compliance_frameworks  <code>module-attribute</code>","text":"<pre><code>compliance_frameworks = {'hipaa': ComplianceFramework(compliance_framework_id='hipaa', name='The Health Insurance Portability and Accountability Act', abbreviation='HIPAA', description=\"HIPAA (Health Insurance Portability and Accountability Act) is a U.S. federal law designed to safeguard the privacy and security of individuals' health information, establishing standards for its protection and regulating its use in the healthcare industry.\", homepage='https://www.cdc.gov/phlp/publications/topic/hipaa.html'), 'soc2t2': ComplianceFramework(compliance_framework_id='soc2t2', name='System and Organization Controls Level 2 Type 2', abbreviation='SOC 2 Type 2', description=\"SOC 2 Type 2 is a framework for assessing and certifying the effectiveness of a service organization's information security policies and procedures over time, emphasizing the operational aspects and ongoing monitoring of controls.\", homepage='https://www.aicpa-cima.com/topic/audit-assurance/audit-and-assurance-greater-than-soc-2'), 'iso27001': ComplianceFramework(compliance_framework_id='iso27001', name='ISO/IEC 27001', abbreviation='ISO 27001', description='ISO 27001 is standard for information security management systems.', homepage='https://www.iso.org/standard/27001')}\n</code></pre> <p>Dictionary of sc_crawler.tables.ComplianceFramework instances keyed by the <code>compliance_framework_id</code>.</p>"},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup.map_compliance_frameworks_to_vendor","title":"map_compliance_frameworks_to_vendor","text":"<pre><code>map_compliance_frameworks_to_vendor(vendor_id, compliance_framework_ids)\n</code></pre> <p>Map compliance frameworks to vendors in a dict.</p> <p>Parameters:</p> Name Type Description Default <code>vendor_id</code> <code>str</code> <p>identifier of a Vendor</p> required <code>compliance_framework_ids</code> <code>List[str]</code> <p>identifier(s) of <code>ComplianceFramework</code></p> required <p>Returns:</p> Type Description <code>dict</code> <p>Array of dictionaroes that can be passed to sc_crawler.insert.insert_items.</p> Source code in <code>sc_crawler/lookup.py</code> <pre><code>def map_compliance_frameworks_to_vendor(\n    vendor_id: str, compliance_framework_ids: List[str]\n) -&gt; dict:\n    \"\"\"Map compliance frameworks to vendors in a dict.\n\n    Args:\n        vendor_id: identifier of a [Vendor][sc_crawler.tables.Vendor]\n        compliance_framework_ids: identifier(s) of [`ComplianceFramework`][sc_crawler.tables.ComplianceFramework]\n\n    Returns:\n        Array of dictionaroes that can be passed to [sc_crawler.insert.insert_items][].\n    \"\"\"\n    items = []\n    for compliance_framework_id in compliance_framework_ids:\n        items.append(\n            {\n                \"vendor_id\": vendor_id,\n                \"compliance_framework_id\": compliance_framework_id,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/","title":"str_utils","text":""},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils","title":"sc_crawler.str_utils","text":"<p>Functions:</p> Name Description <code>wrap</code> <p>Wrap string between before/after strings (default to spaces) if not empty.</p> <code>space_after</code> <p>Add space after string if not empty.</p> <code>snake_case</code> <p>Convert CamelCase to snake_case.</p> <code>plural</code> <p>Super basic implementation of pluralizing an English word.</p> <code>extract_last_number</code> <p>Extract the last non-negative number from a string.</p>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.wrap","title":"wrap","text":"<pre><code>wrap(text, before=' ', after=' ')\n</code></pre> <p>Wrap string between before/after strings (default to spaces) if not empty.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>A string.</p> required <code>before</code> <code>str</code> <p>Characters to be added before the <code>text</code>.</p> <code>' '</code> <code>after</code> <code>str</code> <p>Characters to be added after the <code>text</code>.</p> <code>' '</code> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def wrap(text: str, before: str = \" \", after: str = \" \") -&gt; str:\n    \"\"\"Wrap string between before/after strings (default to spaces) if not empty.\n\n    Args:\n        text: A string.\n        before: Characters to be added before the `text`.\n        after: Characters to be added after the `text`.\n    \"\"\"\n    return text if text == \"\" else before + text + after\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.space_after","title":"space_after","text":"<pre><code>space_after(text)\n</code></pre> <p>Add space after string if not empty.</p> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def space_after(text: str) -&gt; str:\n    \"\"\"Add space after string if not empty.\"\"\"\n    return wrap(text, before=\"\")\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.snake_case","title":"snake_case","text":"<pre><code>snake_case(text)\n</code></pre> <p>Convert CamelCase to snake_case.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>A CamelCase text.</p> required <p>Returns:</p> Type Description <code>str</code> <p>snake_case version of the text.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; snake_case('DescriptionToComment')\n'description_to_comment'\n</code></pre> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def snake_case(text: str) -&gt; str:\n    \"\"\"Convert CamelCase to snake_case.\n\n    Args:\n        text: A CamelCase text.\n\n    Returns:\n        snake_case version of the text.\n\n    Examples:\n        &gt;&gt;&gt; snake_case('DescriptionToComment')\n        'description_to_comment'\n    \"\"\"\n    return \"_\".join(sub(\"([A-Z][a-z]+)\", r\" \\1\", text).split()).lower()\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.plural","title":"plural","text":"<pre><code>plural(text)\n</code></pre> <p>Super basic implementation of pluralizing an English word.</p> <p>Note that grammar exceptions are not handled, so better to use a proper NLP method for real use-cases.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>A singular noun.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plural form of the noun.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; plural('dog')\n'dogs'\n&gt;&gt;&gt; plural('boy') # :facepalm:\n'boies'\n</code></pre> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def plural(text: str) -&gt; str:\n    \"\"\"Super basic implementation of pluralizing an English word.\n\n    Note that grammar exceptions are not handled, so better to use a\n    proper NLP method for real use-cases.\n\n    Args:\n        text: A singular noun.\n\n    Returns:\n        Plural form of the noun.\n\n    Examples:\n        &gt;&gt;&gt; plural('dog')\n        'dogs'\n        &gt;&gt;&gt; plural('boy') # :facepalm:\n        'boies'\n    \"\"\"\n    if search(\"[sxz]$\", text) or search(\"[^aeioudgkprt]h$\", text):\n        return sub(\"$\", \"es\", text)\n    if search(\"[aeiou]y$\", text):\n        return sub(\"y$\", \"ies\", text)\n    return text + \"s\"\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.extract_last_number","title":"extract_last_number","text":"<pre><code>extract_last_number(text)\n</code></pre> <p>Extract the last non-negative number from a string.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The input string from which to extract the number.</p> required <p>Returns:</p> Type Description <code>Union[float, None]</code> <p>The last non-negative number found in the string, or None if no number is found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; extract_last_number(\"foo42\")\n42.0\n&gt;&gt;&gt; extract_last_number(\"foo24.42bar\")\n24.42\n</code></pre> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def extract_last_number(text: str) -&gt; Union[float, None]:\n    \"\"\"Extract the last non-negative number from a string.\n\n    Args:\n        text: The input string from which to extract the number.\n\n    Returns:\n        The last non-negative number found in the string, or None if no number is found.\n\n    Examples:\n        &gt;&gt;&gt; extract_last_number(\"foo42\")\n        42.0\n        &gt;&gt;&gt; extract_last_number(\"foo24.42bar\")\n        24.42\n    \"\"\"\n    match = search(r\"([\\d\\.]+)[^0-9]*$\", text)\n    return float(match.group(1)) if match else None\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/","title":"table_bases","text":""},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases","title":"sc_crawler.table_bases","text":"<p>Tiny helper classes for the most commonly used fields to be inherited by sc_crawler.tables.</p> <p>Classes:</p> Name Description <code>ScMetaModel</code> <p>Custom class factory to auto-update table models.</p> <code>ScModel</code> <p>Custom extensions to SQLModel objects and tables.</p> <code>MetaColumns</code> <p>Helper class to add the <code>status</code> and <code>observed_at</code> columns.</p> <code>HasPriceFieldsBase</code> <code>ServerFields</code> <code>BenchmarkScoreFields</code>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScMetaModel","title":"ScMetaModel","text":"<p>               Bases: <code>__class__</code></p> <p>Custom class factory to auto-update table models.</p> <ul> <li> <p>Reuse description of the table and its fields as SQL comment.</p> <p>Checking if the table and its fields have explicit comment set to be shown in the <code>CREATE TABLE</code> statements, and if not, reuse the optional table and field descriptions. Table docstrings are truncated to first line.</p> </li> <li> <p>Reuse description of the fields to dynamically append to the     docstring in the Attributes section.</p> </li> <li> <p>Set <code>__validator__</code> to the parent Pydantic model without     <code>table=True</code>, which is useful for running validations.     The Pydantic model is found by the parent class' name ending in \"Base\".</p> </li> <li> <p>Auto-generate SCD table docs from the non-SCD table docs.</p> </li> </ul> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class ScMetaModel(SQLModel.__class__):\n    \"\"\"Custom class factory to auto-update table models.\n\n    - Reuse description of the table and its fields as SQL comment.\n\n        Checking if the table and its fields have explicit comment set\n        to be shown in the `CREATE TABLE` statements, and if not,\n        reuse the optional table and field descriptions. Table\n        docstrings are truncated to first line.\n\n    - Reuse description of the fields to dynamically append to the\n        docstring in the Attributes section.\n\n    - Set `__validator__` to the parent Pydantic model without\n        `table=True`, which is useful for running validations.\n        The Pydantic model is found by the parent class' name ending in \"Base\".\n\n    - Auto-generate SCD table docs from the non-SCD table docs.\n    \"\"\"\n\n    def __init__(subclass, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # early return for non-tables\n        if subclass.model_config.get(\"table\") is None:\n            return\n        satable = subclass.metadata.tables[subclass.__tablename__]\n\n        # enforce auto-naming constrains as per\n        # https://alembic.sqlalchemy.org/en/latest/naming.html\n        subclass.metadata.naming_convention = {\n            \"ix\": \"ix_%(column_0_label)s\",\n            \"uq\": \"uq_%(table_name)s_%(column_0_name)s\",\n            \"ck\": \"ck_%(table_name)s_%(constraint_name)s\",\n            \"fk\": \"fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s\",\n            \"pk\": \"pk_%(table_name)s\",\n        }\n\n        # table comment\n        if subclass.__doc__ and satable.comment is None:\n            satable.comment = subclass.__doc__.splitlines()[0]\n\n        # column comments\n        for k, v in subclass.model_fields.items():\n            comment = satable.columns[k].comment\n            if v.description and comment is None:\n                satable.columns[k].comment = v.description\n\n        # generate docstring for SCD tables\n        if subclass.__name__.endswith(\"Scd\"):\n            from .tables import tables\n\n            nonscd = [t for t in tables if t.__name__ == subclass.__name__[:-3]][0]\n            doclines = nonscd.__doc__.splitlines()\n            # drop trailing dot and append SCD\n            doclines[0] = doclines[0][:-1] + \" (SCD Type 2).\"\n            subclass.__doc__ = \"\\n\".join(doclines)\n        else:\n            # describe table columns as attributes in docstring\n            subclass.__doc__ = subclass.__doc__ + \"\\n\\nAttributes:\\n\"\n            for k, v in subclass.model_fields.items():\n                if not hasattr(v.annotation, \"__args__\"):\n                    typehint = v.annotation.__name__\n                else:\n                    typehint = str(v.annotation)\n                description = satable.columns[k].comment\n                subclass.__doc__ = (\n                    subclass.__doc__ + f\"    {k} ({typehint}): {description}\\n\"\n                )\n\n        # find Pydantic model parent to be used for validating\n        subclass.__validator__ = [\n            m for m in subclass.__bases__ if m.__name__.endswith(\"Base\")\n        ][0]\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel","title":"ScModel","text":"<p>               Bases: <code>SQLModel</code></p> <p>Custom extensions to SQLModel objects and tables.</p> <p>Extra features:</p> <ul> <li>auto-generated table names using snake_case,</li> <li>support for hashing table rows,</li> <li>reuse description field of tables/columns as SQL comment,</li> <li>reuse description field of columns to extend the <code>Attributes</code> section of the docstring.</li> </ul> <p>Methods:</p> Name Description <code>__tablename__</code> <p>Override tables names using all-lowercase snake_case.</p> <code>get_columns</code> <p>Return the table's column names in a dict for all, primary keys, and attributes.</p> <code>get_table_name</code> <p>Return the SQLModel object's table name.</p> <code>get_validator</code> <p>Return the parent Base Pydantic model (without a table definition).</p> <code>get_scd</code> <p>Return the SCD version of the SQLModel table.</p> <code>hash</code> <p>Hash the content of the rows.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class ScModel(SQLModel, metaclass=ScMetaModel):\n    \"\"\"Custom extensions to SQLModel objects and tables.\n\n    Extra features:\n\n    - auto-generated table names using [snake_case][sc_crawler.str_utils.snake_case],\n    - support for hashing table rows,\n    - reuse description field of tables/columns as SQL comment,\n    - reuse description field of columns to extend the `Attributes` section of the docstring.\n    \"\"\"\n\n    @declared_attr  # type: ignore\n    def __tablename__(cls) -&gt; str:\n        \"\"\"Override tables names using all-lowercase [snake_case][sc_crawler.str_utils.snake_case].\"\"\"\n        return snake_case(cls.__name__)\n\n    @classmethod\n    def get_columns(cls) -&gt; List[str]:\n        \"\"\"Return the table's column names in a dict for all, primary keys, and attributes.\"\"\"\n        columns = cls.__table__.columns.keys()\n        pks = [pk.name for pk in inspect(cls).primary_key]\n        attributes = [a for a in columns if a not in set(pks)]\n        return {\"all\": columns, \"primary_keys\": pks, \"attributes\": attributes}\n\n    @classmethod\n    def get_table_name(cls) -&gt; str:\n        \"\"\"Return the SQLModel object's table name.\"\"\"\n        return str(cls.__tablename__)\n\n    @classmethod\n    def get_validator(cls) -&gt; Union[\"ScModel\", None]:\n        \"\"\"Return the parent Base Pydantic model (without a table definition).\"\"\"\n        if cls.model_config.get(\"table\") is None:\n            return None\n        return cls.__validator__\n\n    @classmethod\n    def get_scd(cls) -&gt; Union[\"ScModel\", None]:\n        \"\"\"Return the SCD version of the SQLModel table.\"\"\"\n        if cls.model_config.get(\"table\") is None:\n            return None\n        from .tables_scd import tables_scd\n\n        validator = cls.get_validator()\n        scds = [t for t in tables_scd if t.get_validator() == validator]\n        if len(scds) != 1:\n            raise ValueError(\"Not found SCD definition.\")\n        return scds[0]\n\n    @classmethod\n    def hash(\n        cls,\n        session: Session,\n        ignored: List[str] = [\"observed_at\"],\n        progress: Optional[Progress] = None,\n    ) -&gt; dict:\n        \"\"\"Hash the content of the rows.\n\n        Args:\n            session: Database connection to use for object lookups.\n            ignored: List of column names to exclude from hashing.\n            progress: Optional progress bar to track the status of the hashing.\n\n        Returns:\n            Dictionary of the row hashes keyed by the JSON dump of primary keys.\n        \"\"\"\n        pks = sorted(cls.get_columns()[\"primary_keys\"])\n        rows = session.exec(statement=select(cls))\n        row_count = session.query(cls).count()\n        if progress:\n            table_task_id = progress.add_task(\n                cls.get_table_name(),\n                total=row_count,\n            )\n        # no use of a generator as will need to serialize to JSON anyway\n        hashes = {}\n        for i, row in enumerate(rows):\n            # NOTE Pydantic is warning when read Gpu/Storage as dict\n            # https://github.com/tiangolo/sqlmodel/issues/63#issuecomment-1081555082\n            rowdict = row.model_dump(warnings=False)\n            keys = {pk: rowdict.get(pk) for pk in pks}\n            keys_id = dumps(keys, sort_keys=True)\n            for dropkey in [*ignored, *pks]:\n                rowdict.pop(dropkey, None)\n            rowhash = sha1(dumps(rowdict, sort_keys=True).encode()).hexdigest()\n            hashes[keys_id] = rowhash\n            if progress:\n                # updating the progress bar is expensive, so limit with manu iterations\n                if row_count &gt; 1e3:\n                    if (i + 1) % 1000 == 0:\n                        progress.update(table_task_id, advance=1000)\n                    if i == row_count - 1:\n                        progress.update(table_task_id, advance=row_count % 1000)\n                else:\n                    progress.update(table_task_id, advance=1)\n\n        return hashes\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.__tablename__","title":"__tablename__","text":"<pre><code>__tablename__()\n</code></pre> <p>Override tables names using all-lowercase snake_case.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@declared_attr  # type: ignore\ndef __tablename__(cls) -&gt; str:\n    \"\"\"Override tables names using all-lowercase [snake_case][sc_crawler.str_utils.snake_case].\"\"\"\n    return snake_case(cls.__name__)\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_columns","title":"get_columns  <code>classmethod</code>","text":"<pre><code>get_columns()\n</code></pre> <p>Return the table's column names in a dict for all, primary keys, and attributes.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_columns(cls) -&gt; List[str]:\n    \"\"\"Return the table's column names in a dict for all, primary keys, and attributes.\"\"\"\n    columns = cls.__table__.columns.keys()\n    pks = [pk.name for pk in inspect(cls).primary_key]\n    attributes = [a for a in columns if a not in set(pks)]\n    return {\"all\": columns, \"primary_keys\": pks, \"attributes\": attributes}\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_table_name","title":"get_table_name  <code>classmethod</code>","text":"<pre><code>get_table_name()\n</code></pre> <p>Return the SQLModel object's table name.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_table_name(cls) -&gt; str:\n    \"\"\"Return the SQLModel object's table name.\"\"\"\n    return str(cls.__tablename__)\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_validator","title":"get_validator  <code>classmethod</code>","text":"<pre><code>get_validator()\n</code></pre> <p>Return the parent Base Pydantic model (without a table definition).</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_validator(cls) -&gt; Union[\"ScModel\", None]:\n    \"\"\"Return the parent Base Pydantic model (without a table definition).\"\"\"\n    if cls.model_config.get(\"table\") is None:\n        return None\n    return cls.__validator__\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_scd","title":"get_scd  <code>classmethod</code>","text":"<pre><code>get_scd()\n</code></pre> <p>Return the SCD version of the SQLModel table.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_scd(cls) -&gt; Union[\"ScModel\", None]:\n    \"\"\"Return the SCD version of the SQLModel table.\"\"\"\n    if cls.model_config.get(\"table\") is None:\n        return None\n    from .tables_scd import tables_scd\n\n    validator = cls.get_validator()\n    scds = [t for t in tables_scd if t.get_validator() == validator]\n    if len(scds) != 1:\n        raise ValueError(\"Not found SCD definition.\")\n    return scds[0]\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.hash","title":"hash  <code>classmethod</code>","text":"<pre><code>hash(session, ignored=['observed_at'], progress=None)\n</code></pre> <p>Hash the content of the rows.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Database connection to use for object lookups.</p> required <code>ignored</code> <code>List[str]</code> <p>List of column names to exclude from hashing.</p> <code>['observed_at']</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to track the status of the hashing.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of the row hashes keyed by the JSON dump of primary keys.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef hash(\n    cls,\n    session: Session,\n    ignored: List[str] = [\"observed_at\"],\n    progress: Optional[Progress] = None,\n) -&gt; dict:\n    \"\"\"Hash the content of the rows.\n\n    Args:\n        session: Database connection to use for object lookups.\n        ignored: List of column names to exclude from hashing.\n        progress: Optional progress bar to track the status of the hashing.\n\n    Returns:\n        Dictionary of the row hashes keyed by the JSON dump of primary keys.\n    \"\"\"\n    pks = sorted(cls.get_columns()[\"primary_keys\"])\n    rows = session.exec(statement=select(cls))\n    row_count = session.query(cls).count()\n    if progress:\n        table_task_id = progress.add_task(\n            cls.get_table_name(),\n            total=row_count,\n        )\n    # no use of a generator as will need to serialize to JSON anyway\n    hashes = {}\n    for i, row in enumerate(rows):\n        # NOTE Pydantic is warning when read Gpu/Storage as dict\n        # https://github.com/tiangolo/sqlmodel/issues/63#issuecomment-1081555082\n        rowdict = row.model_dump(warnings=False)\n        keys = {pk: rowdict.get(pk) for pk in pks}\n        keys_id = dumps(keys, sort_keys=True)\n        for dropkey in [*ignored, *pks]:\n            rowdict.pop(dropkey, None)\n        rowhash = sha1(dumps(rowdict, sort_keys=True).encode()).hexdigest()\n        hashes[keys_id] = rowhash\n        if progress:\n            # updating the progress bar is expensive, so limit with manu iterations\n            if row_count &gt; 1e3:\n                if (i + 1) % 1000 == 0:\n                    progress.update(table_task_id, advance=1000)\n                if i == row_count - 1:\n                    progress.update(table_task_id, advance=row_count % 1000)\n            else:\n                progress.update(table_task_id, advance=1)\n\n    return hashes\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.MetaColumns","title":"MetaColumns","text":"<p>               Bases: <code>ScModel</code></p> <p>Helper class to add the <code>status</code> and <code>observed_at</code> columns.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class MetaColumns(ScModel):\n    \"\"\"Helper class to add the `status` and `observed_at` columns.\"\"\"\n\n    status: Status = Field(\n        default=Status.ACTIVE,\n        description=\"Status of the resource (active or inactive).\",\n    )\n    observed_at: datetime = Field(\n        default_factory=lambda: datetime.now(UTC),\n        sa_column_kwargs={\"onupdate\": lambda: datetime.now(UTC)},\n        description=\"Timestamp of the last observation.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.HasPriceFieldsBase","title":"HasPriceFieldsBase","text":"<p>               Bases: <code>ScModel</code></p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class HasPriceFieldsBase(ScModel):\n    unit: PriceUnit = Field(description=\"Billing unit of the pricing model.\")\n    # set to max price if tiered\n    price: float = Field(description=\"Actual price of a billing unit.\")\n    # e.g. setup fee for dedicated servers,\n    # or upfront costs of a reserved instance type\n    price_upfront: float = Field(\n        default=0, description=\"Price to be paid when setting up the resource.\"\n    )\n    price_tiered: List[PriceTier] = Field(\n        default=[],\n        sa_type=JSON,\n        description=\"List of pricing tiers with min/max thresholds and actual prices.\",\n    )\n    currency: str = Field(default=\"USD\", description=\"Currency of the prices.\")\n\n    @field_validator(\"price_tiered\", mode=\"before\")\n    @classmethod\n    def _deserialize_price_tiers(cls, value):\n        \"\"\"Deserialize price_tiered field, converting dicts to PriceTier instances.\"\"\"\n        if value is None:\n            return []\n        return [PriceTier(**item) if isinstance(item, dict) else item for item in value]\n\n    @reconstructor\n    def _reconstruct_price_tiers(self):\n        \"\"\"Ensure price_tiered is always a list of PriceTier instances after loading from the database.\"\"\"\n        if self.price_tiered is None:\n            self.price_tiered = []\n        else:\n            self.price_tiered = [\n                PriceTier(**item) if isinstance(item, dict) else item\n                for item in self.price_tiered\n            ]\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ServerFields","title":"ServerFields","text":"<p>               Bases: <code>HasDescription</code>, <code>HasDisplayName</code>, <code>HasApiReference</code>, <code>HasName</code>, <code>HasServerIdPK</code>, <code>HasVendorPKFK</code></p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class ServerFields(\n    HasDescription,\n    HasDisplayName,\n    HasApiReference,\n    HasName,\n    HasServerIdPK,\n    HasVendorPKFK,\n):\n    family: Optional[str] = Field(\n        default=None,\n        description=\"Server family, e.g. General-purpose machine (GCP), or M5g (AWS).\",\n    )\n    # inspector_status: str = Field(\n    #     default=None,\n    #     description=\"Server family, e.g. General-purpose machine (GCP), or M5g (AWS).\",\n    # )\n    vcpus: int = Field(\n        default=None,\n        description=\"Default number of virtual CPUs (vCPU) of the server.\",\n    )\n    hypervisor: Optional[str] = Field(\n        default=None,\n        description=\"Hypervisor of the virtual server, e.g. Xen, KVM, Nitro or Dedicated.\",\n    )\n    cpu_allocation: CpuAllocation = Field(\n        default=None,\n        description=\"Allocation of CPU(s) to the server, e.g. shared, burstable or dedicated.\",\n    )\n    cpu_cores: Optional[int] = Field(\n        default=None,\n        description=(\n            \"Default number of CPU cores of the server. \"\n            \"Equals to vCPUs when HyperThreading is disabled.\"\n        ),\n    )\n    cpu_speed: Optional[float] = Field(\n        default=None, description=\"Vendor-reported maximum CPU clock speed (GHz).\"\n    )\n    cpu_architecture: CpuArchitecture = Field(\n        default=None,\n        description=\"CPU architecture (arm64, arm64_mac, i386, or x86_64).\",\n    )\n    cpu_manufacturer: Optional[str] = Field(\n        default=None,\n        description=\"The manufacturer of the primary processor, e.g. Intel or AMD.\",\n    )\n    cpu_family: Optional[str] = Field(\n        default=None,\n        description=\"The product line/family of the primary processor, e.g. Xeon, Core i7, Ryzen 9.\",\n    )\n    cpu_model: Optional[str] = Field(\n        default=None,\n        description=\"The model number of the primary processor, e.g. 9750H.\",\n    )\n    cpu_l1_cache: Optional[int] = Field(\n        default=None, description=\"L1 cache size (byte).\"\n    )\n    cpu_l2_cache: Optional[int] = Field(\n        default=None, description=\"L2 cache size (byte).\"\n    )\n    cpu_l3_cache: Optional[int] = Field(\n        default=None, description=\"L3 cache size (byte).\"\n    )\n    cpu_flags: List[str] = Field(\n        sa_type=JSON, default=[], description=\"CPU features/flags.\"\n    )\n    cpus: List[Cpu] = Field(\n        default=[],\n        sa_type=JSON,\n        description=(\n            \"JSON array of known CPU details, e.g. the manufacturer, family, model; \"\n            \"L1/L2/L3 cache size; microcode version; feature flags; bugs etc.\"\n        ),\n    )\n    memory_amount: int = Field(\n        default=None,\n        description=\"RAM amount (MiB).\",\n    )\n    memory_generation: Optional[DdrGeneration] = Field(\n        default=None, description=\"Generation of the DDR SDRAM, e.g. DDR4 or DDR5.\"\n    )\n    memory_speed: Optional[int] = Field(\n        default=None, description=\"DDR SDRAM clock rate (Mhz).\"\n    )\n    memory_ecc: Optional[bool] = Field(\n        default=None,\n        description=\"If the DDR SDRAM uses error correction code to detect and correct n-bit data corruption.\",\n    )\n    gpu_count: float = Field(\n        default=0,\n        description=\"Number of GPU accelerator(s).\",\n    )\n    gpu_memory_min: Optional[int] = Field(\n        default=None,\n        description=\"Memory (MiB) allocated to the lowest-end GPU accelerator.\",\n    )\n    gpu_memory_total: Optional[int] = Field(\n        default=None,\n        description=\"Overall memory (MiB) allocated to all the GPU accelerator(s).\",\n    )\n    gpu_manufacturer: Optional[str] = Field(\n        default=None,\n        description=\"The manufacturer of the primary GPU accelerator, e.g. Nvidia or AMD.\",\n    )\n    gpu_family: Optional[str] = Field(\n        default=None,\n        description=\"The product family of the primary GPU accelerator, e.g. Turing.\",\n    )\n    gpu_model: Optional[str] = Field(\n        default=None,\n        description=\"The model number of the primary GPU accelerator, e.g. Tesla T4.\",\n    )\n    gpus: List[Gpu] = Field(\n        default=[],\n        sa_type=JSON,\n        description=(\n            \"JSON array of GPU accelerator details, including \"\n            \"the manufacturer, name, and memory (MiB) of each GPU.\"\n        ),\n    )\n    storage_size: int = Field(\n        default=0,\n        description=\"Overall size (GB) of the disk(s).\",\n    )\n    storage_type: Optional[StorageType] = Field(\n        default=None,\n        description=\"Primary disk type, e.g. HDD, SSD, NVMe SSD, or network).\",\n    )\n    storages: List[Disk] = Field(\n        default=[],\n        sa_type=JSON,\n        description=(\n            \"JSON array of disks attached to the server, including \"\n            \"the size (MiB) and type of each disk.\"\n        ),\n    )\n    network_speed: Optional[float] = Field(\n        default=None,\n        description=\"The baseline network performance (Gbps) of the network card.\",\n    )\n    inbound_traffic: float = Field(\n        default=0,\n        description=\"Amount of complimentary inbound traffic (GB) per month.\",\n    )\n    outbound_traffic: float = Field(\n        default=0,\n        description=\"Amount of complimentary outbound traffic (GB) per month.\",\n    )\n    ipv4: int = Field(\n        default=0, description=\"Number of complimentary IPv4 address(es).\"\n    )\n\n    @field_validator(\"cpus\", mode=\"before\")\n    @classmethod\n    def _deserialize_cpus(cls, value):\n        \"\"\"Deserialize cpus field, converting dicts to Cpu instances.\"\"\"\n        if value is None:\n            return []\n        return [Cpu(**item) if isinstance(item, dict) else item for item in value]\n\n    @field_validator(\"gpus\", mode=\"before\")\n    @classmethod\n    def _deserialize_gpus(cls, value):\n        \"\"\"Deserialize gpus field, converting dicts to Gpu instances.\"\"\"\n        if value is None:\n            return []\n        return [Gpu(**item) if isinstance(item, dict) else item for item in value]\n\n    @field_validator(\"storages\", mode=\"before\")\n    @classmethod\n    def _deserialize_storages(cls, value):\n        \"\"\"Deserialize storages field, converting dicts to Disk instances.\"\"\"\n        if value is None:\n            return []\n        return [Disk(**item) if isinstance(item, dict) else item for item in value]\n\n    @reconstructor\n    def _reconstruct_json_fields(self):\n        \"\"\"Ensure cpus, gpus and storages are always a list of Cpu, Gpu and Disk instances after loading from the database.\"\"\"\n        if self.cpus is None:\n            self.cpus = []\n        else:\n            self.cpus = [\n                Cpu(**item) if isinstance(item, dict) else item for item in self.cpus\n            ]\n\n        if self.gpus is None:\n            self.gpus = []\n        else:\n            self.gpus = [\n                Gpu(**item) if isinstance(item, dict) else item for item in self.gpus\n            ]\n\n        if self.storages is None:\n            self.storages = []\n        else:\n            self.storages = [\n                Disk(**item) if isinstance(item, dict) else item\n                for item in self.storages\n            ]\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.BenchmarkScoreFields","title":"BenchmarkScoreFields","text":"<p>               Bases: <code>HasBenchmarkPKFK</code>, <code>HasServerPK</code>, <code>HasVendorPKFK</code></p> <p>Methods:</p> Name Description <code>update_config_to_hashable</code> <p>We need a hashable column for the primary key.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class BenchmarkScoreFields(HasBenchmarkPKFK, HasServerPK, HasVendorPKFK):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"before\")\n    def update_config_to_hashable(cls, values):\n        \"\"\"We need a hashable column for the primary key.\n\n        Note that we also sort the keys, so that the resulting JSON\n        can be compared as text as well (as some database engines do).\n        \"\"\"\n        values[\"config\"] = HashableDict(sorted(values.get(\"config\", {}).items()))\n        return values\n\n    # use HashableDict as it's a primary key that needs to be hashable, but\n    # fall back to dict to avoid PydanticInvalidForJsonSchema\n    config: HashableDict | dict = Field(\n        default={},\n        sa_type=HashableJSON,\n        primary_key=True,\n        description='Dictionary of config parameters of the specific benchmark, e.g. {\"bandwidth\": 4096}',\n    )\n    score: float = Field(\n        description=\"The resulting score of the benchmark.\",\n    )\n    note: Optional[str] = Field(\n        default=None,\n        description=\"Optional note, comment or context on the benchmark score.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.BenchmarkScoreFields.update_config_to_hashable","title":"update_config_to_hashable","text":"<pre><code>update_config_to_hashable(values)\n</code></pre> <p>We need a hashable column for the primary key.</p> <p>Note that we also sort the keys, so that the resulting JSON can be compared as text as well (as some database engines do).</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@model_validator(mode=\"before\")\ndef update_config_to_hashable(cls, values):\n    \"\"\"We need a hashable column for the primary key.\n\n    Note that we also sort the keys, so that the resulting JSON\n    can be compared as text as well (as some database engines do).\n    \"\"\"\n    values[\"config\"] = HashableDict(sorted(values.get(\"config\", {}).items()))\n    return values\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/","title":"table_fields","text":""},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields","title":"sc_crawler.table_fields","text":"<p>Enumerations, JSON nested data objects &amp; other helper classes used in sc_crawler.tables.</p> <p>Classes:</p> Name Description <code>HashableDict</code> <p>A dict that can be hashed by its JSON representation.</p> <code>HashableJSON</code> <p>Alternative JSON SQLAlchemy column representation, which can be hashed.</p> <code>Json</code> <p>Custom base SQLModel class that supports dumping as JSON.</p> <code>Status</code> <p>Last known status of a resource, e.g. active or inactive.</p> <code>Cpu</code> <p>CPU details.</p> <code>Gpu</code> <p>GPU accelerator details.</p> <code>StorageType</code> <p>Type of a storage, e.g. HDD or SSD.</p> <code>Disk</code> <p>Disk definition based on size and storage type.</p> <code>TrafficDirection</code> <p>Direction of the network traffic.</p> <code>CpuAllocation</code> <p>CPU allocation methods at cloud vendors.</p> <code>CpuArchitecture</code> <p>CPU architectures.</p> <code>DdrGeneration</code> <p>Generation of the DDR SDRAM.</p> <code>Allocation</code> <p>Server allocation options.</p> <code>PriceUnit</code> <p>Supported units for the price tables.</p> <code>PriceTier</code> <p>Price tier definition.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.HashableDict","title":"HashableDict","text":"<p>               Bases: <code>dict</code></p> <p>A dict that can be hashed by its JSON representation.</p> <p>Useful for typehinting dict-type table columns that are primary keys (which need to be hashable for SQLAlchemy ORM). See sc_crawler.table_fields.HashableJSON class for the related <code>sa_type</code>.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class HashableDict(dict):\n    \"\"\"A dict that can be hashed by its JSON representation.\n\n    Useful for typehinting dict-type table columns that are primary\n    keys (which need to be hashable for SQLAlchemy ORM). See\n    [sc_crawler.table_fields.HashableJSON][] class for the related `sa_type`.\n    \"\"\"\n\n    def __hash__(self):\n        return hash(dumps(self, sort_keys=True))\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.HashableJSON","title":"HashableJSON","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Alternative JSON SQLAlchemy column representation, which can be hashed.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class HashableJSON(TypeDecorator):\n    \"\"\"Alternative JSON SQLAlchemy column representation, which can be hashed.\"\"\"\n\n    impl = JSON\n\n    def process_result_value(self, value: str, dialect: Any) -&gt; Any:\n        if value is None:\n            return None\n        return HashableDict(value)\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Json","title":"Json","text":"<p>               Bases: <code>BaseModel</code></p> <p>Custom base SQLModel class that supports dumping as JSON.</p> <p>Methods:</p> Name Description <code>__json__</code> <p>Call <code>self.model_dump</code> to serialize into JSON.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Json(BaseModel):\n    \"\"\"Custom base SQLModel class that supports dumping as JSON.\"\"\"\n\n    def __json__(self):\n        \"\"\"Call `self.model_dump` to serialize into JSON.\"\"\"\n        return dict(sorted(self.model_dump().items()))\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Json.__json__","title":"__json__","text":"<pre><code>__json__()\n</code></pre> <p>Call <code>self.model_dump</code> to serialize into JSON.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>def __json__(self):\n    \"\"\"Call `self.model_dump` to serialize into JSON.\"\"\"\n    return dict(sorted(self.model_dump().items()))\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Status","title":"Status","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Last known status of a resource, e.g. active or inactive.</p> <p>Attributes:</p> Name Type Description <code>ACTIVE</code> <p>Active and available resource.</p> <code>INACTIVE</code> <p>Inactive resource that is not available anymore.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Status(str, Enum):\n    \"\"\"Last known status of a resource, e.g. active or inactive.\"\"\"\n\n    ACTIVE = \"active\"\n    \"\"\"Active and available resource.\"\"\"\n    INACTIVE = \"inactive\"\n    \"\"\"Inactive resource that is not available anymore.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Status.ACTIVE","title":"ACTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACTIVE = 'active'\n</code></pre> <p>Active and available resource.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Status.INACTIVE","title":"INACTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INACTIVE = 'inactive'\n</code></pre> <p>Inactive resource that is not available anymore.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu","title":"Cpu","text":"<p>               Bases: <code>Json</code></p> <p>CPU details.</p> <p>Attributes:</p> Name Type Description <code>manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the processor, e.g. Intel or AMD.</p> <code>family</code> <code>Optional[str]</code> <p>The product line/family of the processor, e.g. Xeon, Core i7, Ryzen 9.</p> <code>model</code> <code>Optional[str]</code> <p>The model number of the processor, e.g. 9750H.</p> <code>cores</code> <code>Optional[int]</code> <p>Number of CPU cores.</p> <code>threads</code> <code>Optional[int]</code> <p>Number of CPU threads.</p> <code>l1_cache_size</code> <code>Optional[int]</code> <p>L1 cache size in bytes.</p> <code>l2_cache_size</code> <code>Optional[int]</code> <p>L2 cache size in bytes.</p> <code>l3_cache_size</code> <code>Optional[int]</code> <p>L3 cache size in bytes.</p> <code>microcode</code> <code>Optional[str]</code> <p>Microcode version.</p> <code>capabilities</code> <code>List[str]</code> <p>List of CPU flag/features/capabilities, e.g. MMX, Intel SGX etc.</p> <code>bugs</code> <code>List[str]</code> <p>List of known bugs, e.g. cpu_meltdown spectre_v1.</p> <code>bogomips</code> <code>Optional[float]</code> <p>BogoMips value.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Cpu(Json):\n    \"\"\"CPU details.\"\"\"\n\n    manufacturer: Optional[str] = None\n    \"\"\"The manufacturer of the processor, e.g. Intel or AMD.\"\"\"\n    family: Optional[str] = None\n    \"\"\"The product line/family of the processor, e.g. Xeon, Core i7, Ryzen 9.\"\"\"\n    model: Optional[str] = None\n    \"\"\"The model number of the processor, e.g. 9750H.\"\"\"\n    cores: Optional[int] = None\n    \"\"\"Number of CPU cores.\"\"\"\n    threads: Optional[int] = None\n    \"\"\"Number of CPU threads.\"\"\"\n    l1_cache_size: Optional[int] = None\n    \"\"\"L1 cache size in bytes.\"\"\"\n    l2_cache_size: Optional[int] = None\n    \"\"\"L2 cache size in bytes.\"\"\"\n    l3_cache_size: Optional[int] = None\n    \"\"\"L3 cache size in bytes.\"\"\"\n    microcode: Optional[str] = None\n    \"\"\"Microcode version.\"\"\"\n    capabilities: List[str] = []\n    \"\"\"List of CPU flag/features/capabilities, e.g. MMX, Intel SGX etc.\"\"\"\n    bugs: List[str] = []\n    \"\"\"List of known bugs, e.g. cpu_meltdown spectre_v1.\"\"\"\n    bogomips: Optional[float] = None\n    \"\"\"BogoMips value.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.manufacturer","title":"manufacturer  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>manufacturer = None\n</code></pre> <p>The manufacturer of the processor, e.g. Intel or AMD.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.family","title":"family  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>family = None\n</code></pre> <p>The product line/family of the processor, e.g. Xeon, Core i7, Ryzen 9.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model = None\n</code></pre> <p>The model number of the processor, e.g. 9750H.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.cores","title":"cores  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cores = None\n</code></pre> <p>Number of CPU cores.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.threads","title":"threads  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>threads = None\n</code></pre> <p>Number of CPU threads.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.l1_cache_size","title":"l1_cache_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>l1_cache_size = None\n</code></pre> <p>L1 cache size in bytes.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.l2_cache_size","title":"l2_cache_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>l2_cache_size = None\n</code></pre> <p>L2 cache size in bytes.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.l3_cache_size","title":"l3_cache_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>l3_cache_size = None\n</code></pre> <p>L3 cache size in bytes.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.microcode","title":"microcode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>microcode = None\n</code></pre> <p>Microcode version.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.capabilities","title":"capabilities  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>capabilities = []\n</code></pre> <p>List of CPU flag/features/capabilities, e.g. MMX, Intel SGX etc.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.bugs","title":"bugs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bugs = []\n</code></pre> <p>List of known bugs, e.g. cpu_meltdown spectre_v1.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.bogomips","title":"bogomips  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bogomips = None\n</code></pre> <p>BogoMips value.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu","title":"Gpu","text":"<p>               Bases: <code>Json</code></p> <p>GPU accelerator details.</p> <p>Attributes:</p> Name Type Description <code>manufacturer</code> <code>str</code> <p>The manufacturer/brand of the GPU accelerator, e.g. Nvidia or AMD.</p> <code>family</code> <code>Optional[str]</code> <p>The model family/architecture of the GPU accelerator.</p> <code>model</code> <code>Optional[str]</code> <p>The model number of the GPU accelerator.</p> <code>memory</code> <code>int</code> <p>Memory (MiB) allocated to the GPU accelerator.</p> <code>firmware_version</code> <code>Optional[str]</code> <p>Firmware version.</p> <code>bios_version</code> <code>Optional[str]</code> <p>Video BIOS version.</p> <code>graphics_clock</code> <code>Optional[int]</code> <p>GPU core clock speed (Mhz).</p> <code>sm_clock</code> <code>Optional[int]</code> <p>Streaming Multiprocessor clock speed (Mhz).</p> <code>mem_clock</code> <code>Optional[int]</code> <p>Memory clock speed (Mhz).</p> <code>video_clock</code> <code>Optional[int]</code> <p>Video clock speed (Mhz).</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Gpu(Json):\n    \"\"\"GPU accelerator details.\"\"\"\n\n    manufacturer: str\n    \"\"\"The manufacturer/brand of the GPU accelerator, e.g. Nvidia or AMD.\"\"\"\n    family: Optional[str] = None\n    \"\"\"The model family/architecture of the GPU accelerator.\"\"\"\n    model: Optional[str] = None\n    \"\"\"The model number of the GPU accelerator.\"\"\"\n    memory: int\n    \"\"\"Memory (MiB) allocated to the GPU accelerator.\"\"\"\n    firmware_version: Optional[str] = None\n    \"\"\"Firmware version.\"\"\"\n    bios_version: Optional[str] = None\n    \"\"\"Video BIOS version.\"\"\"\n    graphics_clock: Optional[int] = None\n    \"\"\"GPU core clock speed (Mhz).\"\"\"\n    sm_clock: Optional[int] = None\n    \"\"\"Streaming Multiprocessor clock speed (Mhz).\"\"\"\n    mem_clock: Optional[int] = None\n    \"\"\"Memory clock speed (Mhz).\"\"\"\n    video_clock: Optional[int] = None\n    \"\"\"Video clock speed (Mhz).\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.manufacturer","title":"manufacturer  <code>instance-attribute</code>","text":"<pre><code>manufacturer\n</code></pre> <p>The manufacturer/brand of the GPU accelerator, e.g. Nvidia or AMD.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.family","title":"family  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>family = None\n</code></pre> <p>The model family/architecture of the GPU accelerator.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model = None\n</code></pre> <p>The model number of the GPU accelerator.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.memory","title":"memory  <code>instance-attribute</code>","text":"<pre><code>memory\n</code></pre> <p>Memory (MiB) allocated to the GPU accelerator.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.firmware_version","title":"firmware_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>firmware_version = None\n</code></pre> <p>Firmware version.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.bios_version","title":"bios_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bios_version = None\n</code></pre> <p>Video BIOS version.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.graphics_clock","title":"graphics_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>graphics_clock = None\n</code></pre> <p>GPU core clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.sm_clock","title":"sm_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sm_clock = None\n</code></pre> <p>Streaming Multiprocessor clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.mem_clock","title":"mem_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mem_clock = None\n</code></pre> <p>Memory clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.video_clock","title":"video_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>video_clock = None\n</code></pre> <p>Video clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType","title":"StorageType","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Type of a storage, e.g. HDD or SSD.</p> <p>Attributes:</p> Name Type Description <code>HDD</code> <p>Magnetic hard disk drive.</p> <code>SSD</code> <p>Solid-state drive.</p> <code>NVME_SSD</code> <p>NVMe based solid-state drive.</p> <code>NETWORK</code> <p>Storage over network, e.g. using NFS.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class StorageType(str, Enum):\n    \"\"\"Type of a storage, e.g. HDD or SSD.\"\"\"\n\n    HDD = \"hdd\"\n    \"\"\"Magnetic hard disk drive.\"\"\"\n    SSD = \"ssd\"\n    \"\"\"Solid-state drive.\"\"\"\n    NVME_SSD = \"nvme ssd\"\n    \"\"\"NVMe based solid-state drive.\"\"\"\n    NETWORK = \"network\"\n    \"\"\"Storage over network, e.g. using NFS.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.HDD","title":"HDD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HDD = 'hdd'\n</code></pre> <p>Magnetic hard disk drive.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.SSD","title":"SSD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SSD = 'ssd'\n</code></pre> <p>Solid-state drive.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.NVME_SSD","title":"NVME_SSD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NVME_SSD = 'nvme ssd'\n</code></pre> <p>NVMe based solid-state drive.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.NETWORK","title":"NETWORK  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NETWORK = 'network'\n</code></pre> <p>Storage over network, e.g. using NFS.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk","title":"Disk","text":"<p>               Bases: <code>Json</code></p> <p>Disk definition based on size and storage type.</p> <p>Attributes:</p> Name Type Description <code>size</code> <code>int</code> <p>Storage size in GiB.</p> <code>storage_type</code> <code>StorageType</code> <p>Type of the storage.</p> <code>description</code> <code>Optional[str]</code> <p>Optional description of the storage, e.g. temp disk.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Disk(Json):\n    \"\"\"Disk definition based on size and storage type.\"\"\"\n\n    size: int = 0\n    \"\"\"Storage size in GiB.\"\"\"\n    storage_type: StorageType\n    \"\"\"[Type][sc_crawler.table_fields.StorageType] of the storage.\"\"\"\n    description: Optional[str] = None\n    \"\"\"Optional description of the storage, e.g. temp disk.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk.size","title":"size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>size = 0\n</code></pre> <p>Storage size in GiB.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk.storage_type","title":"storage_type  <code>instance-attribute</code>","text":"<pre><code>storage_type\n</code></pre> <p>Type of the storage.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description = None\n</code></pre> <p>Optional description of the storage, e.g. temp disk.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.TrafficDirection","title":"TrafficDirection","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Direction of the network traffic.</p> <p>Attributes:</p> Name Type Description <code>IN</code> <p>Inbound traffic.</p> <code>OUT</code> <p>Outbound traffic.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class TrafficDirection(str, Enum):\n    \"\"\"Direction of the network traffic.\"\"\"\n\n    IN = \"inbound\"\n    \"\"\"Inbound traffic.\"\"\"\n    OUT = \"outbound\"\n    \"\"\"Outbound traffic.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.TrafficDirection.IN","title":"IN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>IN = 'inbound'\n</code></pre> <p>Inbound traffic.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.TrafficDirection.OUT","title":"OUT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OUT = 'outbound'\n</code></pre> <p>Outbound traffic.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation","title":"CpuAllocation","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>CPU allocation methods at cloud vendors.</p> <p>Attributes:</p> Name Type Description <code>SHARED</code> <p>Shared CPU with other virtual server tenants.</p> <code>BURSTABLE</code> <p>CPU that can temporarily burst above its baseline performance.</p> <code>DEDICATED</code> <p>Dedicated CPU with known performance.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class CpuAllocation(str, Enum):\n    \"\"\"CPU allocation methods at cloud vendors.\"\"\"\n\n    SHARED = \"Shared\"\n    \"\"\"Shared CPU with other virtual server tenants.\"\"\"\n    BURSTABLE = \"Burstable\"\n    \"\"\"CPU that can temporarily burst above its baseline performance.\"\"\"\n    DEDICATED = \"Dedicated\"\n    \"\"\"Dedicated CPU with known performance.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation.SHARED","title":"SHARED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SHARED = 'Shared'\n</code></pre> <p>Shared CPU with other virtual server tenants.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation.BURSTABLE","title":"BURSTABLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BURSTABLE = 'Burstable'\n</code></pre> <p>CPU that can temporarily burst above its baseline performance.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation.DEDICATED","title":"DEDICATED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DEDICATED = 'Dedicated'\n</code></pre> <p>Dedicated CPU with known performance.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture","title":"CpuArchitecture","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>CPU architectures.</p> <p>Attributes:</p> Name Type Description <code>ARM64</code> <p>64-bit ARM architecture.</p> <code>ARM64_MAC</code> <p>Apple 64-bit ARM architecture.</p> <code>I386</code> <p>32-bit x86 architecture.</p> <code>X86_64</code> <p>64-bit x86 architecture.</p> <code>X86_64_MAC</code> <p>Apple 64-bit x86 architecture.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class CpuArchitecture(str, Enum):\n    \"\"\"CPU architectures.\"\"\"\n\n    ARM64 = \"arm64\"\n    \"\"\"64-bit ARM architecture.\"\"\"\n    ARM64_MAC = \"arm64_mac\"\n    \"\"\"Apple 64-bit ARM architecture.\"\"\"\n    I386 = \"i386\"\n    \"\"\"32-bit x86 architecture.\"\"\"\n    X86_64 = \"x86_64\"\n    \"\"\"64-bit x86 architecture.\"\"\"\n    X86_64_MAC = \"x86_64_mac\"\n    \"\"\"Apple 64-bit x86 architecture.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.ARM64","title":"ARM64  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ARM64 = 'arm64'\n</code></pre> <p>64-bit ARM architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.ARM64_MAC","title":"ARM64_MAC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ARM64_MAC = 'arm64_mac'\n</code></pre> <p>Apple 64-bit ARM architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.I386","title":"I386  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>I386 = 'i386'\n</code></pre> <p>32-bit x86 architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.X86_64","title":"X86_64  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>X86_64 = 'x86_64'\n</code></pre> <p>64-bit x86 architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.X86_64_MAC","title":"X86_64_MAC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>X86_64_MAC = 'x86_64_mac'\n</code></pre> <p>Apple 64-bit x86 architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration","title":"DdrGeneration","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Generation of the DDR SDRAM.</p> <p>Attributes:</p> Name Type Description <code>DDR3</code> <p>DDR3 SDRAM.</p> <code>DDR4</code> <p>DDR4 SDRAM.</p> <code>DDR5</code> <p>DDR5 SDRAM.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class DdrGeneration(str, Enum):\n    \"\"\"Generation of the DDR SDRAM.\"\"\"\n\n    DDR3 = \"DDR3\"\n    \"\"\"DDR3 SDRAM.\"\"\"\n    DDR4 = \"DDR4\"\n    \"\"\"DDR4 SDRAM.\"\"\"\n    DDR5 = \"DDR5\"\n    \"\"\"DDR5 SDRAM.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration.DDR3","title":"DDR3  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DDR3 = 'DDR3'\n</code></pre> <p>DDR3 SDRAM.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration.DDR4","title":"DDR4  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DDR4 = 'DDR4'\n</code></pre> <p>DDR4 SDRAM.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration.DDR5","title":"DDR5  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DDR5 = 'DDR5'\n</code></pre> <p>DDR5 SDRAM.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation","title":"Allocation","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Server allocation options.</p> <p>Attributes:</p> Name Type Description <code>ONDEMAND</code> <p>On-demand server.</p> <code>RESERVED</code> <p>Reserved server.</p> <code>SPOT</code> <p>Spot/preemptible server.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Allocation(str, Enum):\n    \"\"\"Server allocation options.\"\"\"\n\n    ONDEMAND = \"ondemand\"\n    \"\"\"On-demand server.\"\"\"\n    RESERVED = \"reserved\"\n    \"\"\"Reserved server.\"\"\"\n    SPOT = \"spot\"\n    \"\"\"Spot/preemptible server.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation.ONDEMAND","title":"ONDEMAND  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ONDEMAND = 'ondemand'\n</code></pre> <p>On-demand server.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation.RESERVED","title":"RESERVED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RESERVED = 'reserved'\n</code></pre> <p>Reserved server.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation.SPOT","title":"SPOT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SPOT = 'spot'\n</code></pre> <p>Spot/preemptible server.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit","title":"PriceUnit","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Supported units for the price tables.</p> <p>Attributes:</p> Name Type Description <code>YEAR</code> <p>Price per year.</p> <code>MONTH</code> <p>Price per month.</p> <code>HOUR</code> <p>Price per hour.</p> <code>GIB</code> <p>Price per gibibyte (GiB).</p> <code>GB</code> <p>Price per gigabyte (GB).</p> <code>GB_MONTH</code> <p>Price per gigabyte (GB)/month.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class PriceUnit(str, Enum):\n    \"\"\"Supported units for the price tables.\"\"\"\n\n    YEAR = \"year\"\n    \"\"\"Price per year.\"\"\"\n    MONTH = \"month\"\n    \"\"\"Price per month.\"\"\"\n    HOUR = \"hour\"\n    \"\"\"Price per hour.\"\"\"\n    GIB = \"GiB\"\n    \"\"\"Price per gibibyte (GiB).\"\"\"\n    GB = \"GB\"\n    \"\"\"Price per gigabyte (GB).\"\"\"\n    GB_MONTH = \"GB/month\"\n    \"\"\"Price per gigabyte (GB)/month.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.YEAR","title":"YEAR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>YEAR = 'year'\n</code></pre> <p>Price per year.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.MONTH","title":"MONTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MONTH = 'month'\n</code></pre> <p>Price per month.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.HOUR","title":"HOUR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HOUR = 'hour'\n</code></pre> <p>Price per hour.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.GIB","title":"GIB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GIB = 'GiB'\n</code></pre> <p>Price per gibibyte (GiB).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.GB","title":"GB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GB = 'GB'\n</code></pre> <p>Price per gigabyte (GB).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.GB_MONTH","title":"GB_MONTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GB_MONTH = 'GB/month'\n</code></pre> <p>Price per gigabyte (GB)/month.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier","title":"PriceTier","text":"<p>               Bases: <code>Json</code></p> <p>Price tier definition.</p> <p>Infinite bounds (e.g. for an open-ended upper tier) are stored as <code>float(\"inf\")</code> in Python and automatically serialized to the JSON-safe string <code>\"Infinity\"</code> on export. Both representations are accepted as input: the model validator converts <code>\"Infinity\"</code> back to <code>float(\"inf\")</code> when loading from JSON.</p> <p>Attributes:</p> Name Type Description <code>lower</code> <code>float</code> <p>Lower bound of pricing tier, e.g. 100 GB. Unit is defined in the parent object.</p> <code>upper</code> <code>float</code> <p>Upper bound of pricing tier, e.g. 1 TB. Unit is defined in the parent object.</p> <code>price</code> <code>float</code> <p>Price in the pricing tier. Currency is defined in the parent object.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class PriceTier(Json):\n    \"\"\"Price tier definition.\n\n    Infinite bounds (e.g. for an open-ended upper tier) are stored as\n    `float(\"inf\")` in Python and automatically serialized to the\n    JSON-safe string `\"Infinity\"` on export. Both representations are\n    accepted as input: the model validator converts `\"Infinity\"` back\n    to `float(\"inf\")` when loading from JSON.\"\"\"\n\n    lower: float\n    \"\"\"Lower bound of pricing tier, e.g. 100 GB. Unit is defined in the parent object.\"\"\"\n    upper: float\n    \"\"\"Upper bound of pricing tier, e.g. 1 TB. Unit is defined in the parent object.\"\"\"\n    price: float\n    \"\"\"Price in the pricing tier. Currency is defined in the parent object.\"\"\"\n\n    @field_validator(\"upper\", \"lower\", mode=\"before\")\n    @classmethod\n    def _deserialize_inf_bounds(cls, value):\n        \"\"\"Convert string values to float when deserializing from JSON.\"\"\"\n        if isinstance(value, str):\n            return float(value)\n        return value\n\n    @field_serializer(\"upper\", \"lower\")\n    def _serialize_inf_bounds(self, value):\n        \"\"\"Convert float('inf') bounds to 'Infinity' strings when dumping to JSON.\"\"\"\n        if value == float(\"inf\"):\n            return \"Infinity\"\n        return value\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier.lower","title":"lower  <code>instance-attribute</code>","text":"<pre><code>lower\n</code></pre> <p>Lower bound of pricing tier, e.g. 100 GB. Unit is defined in the parent object.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier.upper","title":"upper  <code>instance-attribute</code>","text":"<pre><code>upper\n</code></pre> <p>Upper bound of pricing tier, e.g. 1 TB. Unit is defined in the parent object.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier.price","title":"price  <code>instance-attribute</code>","text":"<pre><code>price\n</code></pre> <p>Price in the pricing tier. Currency is defined in the parent object.</p>"},{"location":"reference/sc_crawler/tables/","title":"tables","text":""},{"location":"reference/sc_crawler/tables/#sc_crawler.tables","title":"sc_crawler.tables","text":"<p>Table definitions for vendors, regions, zones, and other cloud resources.</p> <p>Classes:</p> Name Description <code>Country</code> <p>Country and continent mapping.</p> <code>ComplianceFramework</code> <p>List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1.</p> <code>Vendor</code> <p>Compute resource vendors, such as cloud and server providers.</p> <code>VendorComplianceLink</code> <p>List of known Compliance Frameworks paired with vendors.</p> <code>Region</code> <p>Regions of Vendors.</p> <code>Zone</code> <p>Availability zones of Regions.</p> <code>Storage</code> <p>Flexible storage options that can be attached to a Server.</p> <code>Server</code> <p>Server types.</p> <code>ServerPrice</code> <p>Server type prices per Region and Allocation method.</p> <code>StoragePrice</code> <p>Flexible Storage prices in each Region.</p> <code>TrafficPrice</code> <p>Extra Traffic prices in each Region.</p> <code>Ipv4Price</code> <p>Price of an IPv4 address in each Region.</p> <code>Benchmark</code> <p>Benchmark scenario definitions.</p> <code>BenchmarkScore</code> <p>Results of running Benchmark scenarios on Servers.</p> <p>Attributes:</p> Name Type Description <code>tables</code> <code>List[SQLModel]</code> <p>List of all SQLModel (table) models.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Country","title":"Country","text":"<p>               Bases: <code>CountryBase</code></p> <p>Country and continent mapping.</p> <p>Attributes:</p> Name Type Description <code>country_id</code> <code>str</code> <p>Country code by ISO 3166 alpha-2.</p> <code>continent</code> <code>str</code> <p>Continent name.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Country(CountryBase, table=True):\n    \"\"\"Country and continent mapping.\"\"\"\n\n    vendors: List[\"Vendor\"] = Relationship(back_populates=\"country\")\n    regions: List[\"Region\"] = Relationship(back_populates=\"country\")\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.ComplianceFramework","title":"ComplianceFramework","text":"<p>               Bases: <code>ComplianceFrameworkBase</code></p> <p>List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1.</p> <p>Attributes:</p> Name Type Description <code>compliance_framework_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>abbreviation</code> <code>Optional[str]</code> <p>Short abbreviation of the Framework name.</p> <code>description</code> <code>Optional[str]</code> <p>Description of the framework in a few paragraphs, outlining key features and characteristics for reference.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Framework's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage with more information on the Framework.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class ComplianceFramework(ComplianceFrameworkBase, table=True):\n    \"\"\"List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1.\"\"\"\n\n    vendor_links: List[\"VendorComplianceLink\"] = Relationship(\n        back_populates=\"compliance_framework\"\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor","title":"Vendor","text":"<p>               Bases: <code>VendorBase</code></p> <p>Compute resource vendors, such as cloud and server providers.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sc_crawler.tables import Vendor\n&gt;&gt;&gt; from sc_crawler.lookup import countries\n&gt;&gt;&gt; aws = Vendor(vendor_id='aws', name='Amazon Web Services', homepage='https://aws.amazon.com', country=countries[\"US\"], founding_year=2002)\n&gt;&gt;&gt; aws\nVendor(vendor_id='aws'...\n&gt;&gt;&gt; from sc_crawler import vendors\n&gt;&gt;&gt; vendors.aws\nVendor(vendor_id='aws'...\n</code></pre> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Vendor's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage of the Vendor.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Vendor's main headquarter is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Vendor's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Vendor's main location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Vendor's main location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Vendor's main location.</p> <code>founding_year</code> <code>int</code> <p>4-digit year when the public cloud service of the Vendor was launched.</p> <code>status_page</code> <code>Optional[str]</code> <p>Public status page of the Vendor.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> <p>Methods:</p> Name Description <code>set_table_rows_inactive</code> <p>Set this vendor's records to INACTIVE in a table.</p> <code>set_table_rows_active</code> <p>Set this vendor's records to ACTIVE in a table.</p> <code>inventory_compliance_frameworks</code> <p>Get the vendor's all compliance frameworks.</p> <code>inventory_regions</code> <p>Get the vendor's all regions.</p> <code>inventory_zones</code> <p>Get all the zones in the vendor's regions.</p> <code>inventory_servers</code> <p>Get the vendor's all server types.</p> <code>inventory_server_prices</code> <p>Get the current standard/ondemand/reserved prices of all server types.</p> <code>inventory_server_prices_spot</code> <p>Get the current spot prices of all server types.</p> <code>inventory_storages</code> <p>Get the vendor's all storage types.</p> <code>inventory_storage_prices</code> <p>Get the current prices of all storage types.</p> <code>inventory_traffic_prices</code> <p>Get the current prices of all traffic types.</p> <code>inventory_ipv4_prices</code> <p>Get the current prices of all IPv4 types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Vendor(VendorBase, table=True):\n    \"\"\"Compute resource vendors, such as cloud and server providers.\n\n    Examples:\n        &gt;&gt;&gt; from sc_crawler.tables import Vendor\n        &gt;&gt;&gt; from sc_crawler.lookup import countries\n        &gt;&gt;&gt; aws = Vendor(vendor_id='aws', name='Amazon Web Services', homepage='https://aws.amazon.com', country=countries[\"US\"], founding_year=2002)\n        &gt;&gt;&gt; aws\n        Vendor(vendor_id='aws'...\n        &gt;&gt;&gt; from sc_crawler import vendors\n        &gt;&gt;&gt; vendors.aws\n        Vendor(vendor_id='aws'...\n    \"\"\"  # noqa: E501\n\n    compliance_framework_links: List[\"VendorComplianceLink\"] = Relationship(\n        back_populates=\"vendor\"\n    )\n    country: Country = Relationship(back_populates=\"vendors\")\n    regions: List[\"Region\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    zones: List[\"Zone\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    storages: List[\"Storage\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    servers: List[\"Server\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    server_prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    traffic_prices: List[\"TrafficPrice\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    ipv4_prices: List[\"Ipv4Price\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    storage_prices: List[\"StoragePrice\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    benchmark_scores: List[\"BenchmarkScore\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n\n    # private attributes\n    _methods: Optional[ImportString[ModuleType]] = PrivateAttr(default=None)\n    _session: Optional[Session] = PrivateAttr()\n    _progress_tracker: Optional[VendorProgressTracker] = PrivateAttr(\n        default=VoidProgressTracker()\n    )\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # SQLModel does not validates pydantic typing,\n        # only when writing to DB (much later in the process)\n        if not self.vendor_id:\n            raise ValueError(\"No vendor id provided\")\n        if not self.name:\n            raise ValueError(\"No vendor name provided\")\n        if not self.homepage:\n            raise ValueError(\"No vendor homepage provided\")\n        if not self.country:\n            raise ValueError(\"No vendor country provided\")\n\n    def _get_methods(self):\n        # private attributes are not (always) initialized correctly by SQLmodel\n        # e.g. the attribute is missing alltogether when loaded from DB\n        # https://github.com/tiangolo/sqlmodel/issues/149\n        try:\n            hasattr(self, \"_methods\")\n        except Exception:\n            self._methods = None\n        if not self._methods:\n            vendor_module = \".\".join(\n                [\n                    __name__.split(\".\", maxsplit=1)[0],\n                    \"vendors\",\n                    f\"_{self.vendor_id}\",\n                ]\n            )\n            try:\n                self._methods = import_module(vendor_module)\n            except Exception as exc:\n                raise NotImplementedError(\n                    f\"Unsupported '{self.vendor_id}' vendor: cannot import its module.\"\n                ) from exc\n            # make sure all required methods exist\n            for method in [\n                \"inventory_compliance_frameworks\",\n                \"inventory_regions\",\n                \"inventory_zones\",\n                \"inventory_servers\",\n                \"inventory_server_prices\",\n                \"inventory_server_prices_spot\",\n                \"inventory_storages\",\n                \"inventory_storage_prices\",\n                \"inventory_traffic_prices\",\n                \"inventory_ipv4_prices\",\n            ]:\n                if not hasattr(self._methods, method):\n                    raise NotImplementedError(\n                        f\"Unsupported '{self.vendor_id}' vendor: missing '{method}' method.\"\n                    )\n        return self._methods\n\n    @property\n    def session(self):\n        \"\"\"The Session to use for merging dependent objects into the database.\"\"\"\n        try:\n            return self._session\n        except Exception:\n            return None\n\n    @session.setter\n    def session(self, session: Session):\n        self._session = session\n\n    @session.deleter\n    def session(self):\n        self._session = None\n\n    @property\n    def progress_tracker(self):\n        \"\"\"The [sc_crawler.logger.VendorProgressTracker][] to use for updating progress bars.\"\"\"\n        return self._progress_tracker\n\n    @progress_tracker.setter\n    def progress_tracker(self, progress_tracker: VendorProgressTracker):\n        self._progress_tracker = progress_tracker\n\n    @progress_tracker.deleter\n    def progress_tracker(self):\n        self._progress_tracker = None\n\n    @property\n    def tasks(self):\n        \"\"\"Reexport progress_tracker.tasks for easier access.\"\"\"\n        return self._progress_tracker.tasks\n\n    def log(self, message: str, level: int = logging.INFO):\n        logger.log(level, self.name + \": \" + message, stacklevel=2)\n\n    def set_table_rows_inactive(self, model: str, *args) -&gt; None:\n        \"\"\"Set this vendor's records to [INACTIVE][sc_crawler.table_fields.Status] in a table.\n\n        Positional arguments can be used to pass further filters\n        (besides the default model.vendor_id filter) referencing the\n        model object with SQLModel syntax.\n\n        Examples:\n            &gt;&gt;&gt; aws.set_table_rows_inactive(ServerPrice, ServerPrice.price &lt; 10)  # doctest: +SKIP\n        \"\"\"\n        if self.session:\n            query = update(model).where(model.vendor_id == self.vendor_id)\n            for arg in args:\n                query = query.where(arg)\n            self.session.execute(query.values(status=Status.INACTIVE))\n\n    def set_table_rows_active(self, model: str, *args) -&gt; None:\n        \"\"\"Set this vendor's records to [ACTIVE][sc_crawler.table_fields.Status] in a table.\n\n        Positional arguments can be used to pass further filters\n        (besides the default model.vendor_id filter) referencing the\n        model object with SQLModel syntax.\n\n        Examples:\n            &gt;&gt;&gt; aws.set_table_rows_active(ServerPrice, ServerPrice.price &lt; 10)  # doctest: +SKIP\n        \"\"\"\n        if self.session:\n            query = update(model).where(model.vendor_id == self.vendor_id)\n            for arg in args:\n                query = query.where(arg)\n            self.session.execute(query.values(status=Status.ACTIVE))\n\n    def _inventory(self, table: ScModel, inventory: Callable):\n        \"\"\"Mark all rows in a table inactive, then insert new/updated items.\"\"\"\n        self.set_table_rows_inactive(table)\n        insert_items(table, inventory(self), self)\n\n    def _inventory_price_rounding(\n        self,\n        table: ScModel,\n        inventory: Callable,\n        *filters,\n        prefix: str = \"\",\n    ):\n        \"\"\"Mark rows in a table inactive, then insert new/updated items with 4-digit price rounding.\n\n        Args:\n            table: The SQLModel table class to update.\n            inventory: Callable that returns list of items to insert.\n            *filters: Optional filter expressions to apply when marking rows inactive.\n            prefix: Optional prefix for progress tracking.\n        \"\"\"\n        self.set_table_rows_inactive(table, *filters)\n        items = inventory(self)\n        for item in items:\n            item[\"price\"] = round(float(item[\"price\"]), 4)\n        insert_items(table, items, self, prefix=prefix)\n\n    @log_start_end\n    def inventory_compliance_frameworks(self):\n        \"\"\"Get the vendor's all compliance frameworks.\"\"\"\n        self._inventory(\n            VendorComplianceLink, self._get_methods().inventory_compliance_frameworks\n        )\n\n    @log_start_end\n    def inventory_regions(self):\n        \"\"\"Get the vendor's all regions.\"\"\"\n        self._inventory(Region, self._get_methods().inventory_regions)\n\n    @log_start_end\n    def inventory_zones(self):\n        \"\"\"Get all the zones in the vendor's regions.\"\"\"\n        self._inventory(Zone, self._get_methods().inventory_zones)\n\n    @log_start_end\n    def inventory_servers(self):\n        \"\"\"Get the vendor's all server types.\"\"\"\n        self.set_table_rows_inactive(Server)\n        servers = self._get_methods().inventory_servers(self)\n        # show progress bar while downloading\n        self.progress_tracker.start_task(\n            name=\"Downloading sc-inspector-data\", total=None\n        )\n        inspector_data_path()\n        self.progress_tracker.hide_task()\n        # actual HW inspection\n        for server in servers:\n            server = inspect_update_server_dict(server)\n        insert_items(Server, servers, self)\n        benchmarks = []\n        self.progress_tracker.start_task(\n            name=\"Searching for benchmark(s)\", total=len(self.servers)\n        )\n        for server in self.servers:\n            benchmarks += inspect_server_benchmarks(server)\n            self.progress_tracker.advance_task()\n        self.progress_tracker.hide_task()\n        self.set_table_rows_inactive(\n            BenchmarkScore, BenchmarkScore.vendor_id == self.vendor_id\n        )\n        insert_items(BenchmarkScore, benchmarks, self)\n\n    @log_start_end\n    def inventory_server_prices(self):\n        \"\"\"Get the current standard/ondemand/reserved prices of all server types.\"\"\"\n        self._inventory_price_rounding(\n            ServerPrice,\n            self._get_methods().inventory_server_prices,\n            ServerPrice.allocation == Allocation.ONDEMAND,\n            prefix=\"ondemand\",\n        )\n\n    @log_start_end\n    def inventory_server_prices_spot(self):\n        \"\"\"Get the current spot prices of all server types.\"\"\"\n        self._inventory_price_rounding(\n            ServerPrice,\n            self._get_methods().inventory_server_prices_spot,\n            ServerPrice.allocation == Allocation.SPOT,\n            prefix=\"spot\",\n        )\n\n    @log_start_end\n    def inventory_storages(self):\n        \"\"\"Get the vendor's all storage types.\"\"\"\n        self._inventory(Storage, self._get_methods().inventory_storages)\n\n    @log_start_end\n    def inventory_storage_prices(self):\n        \"\"\"Get the current prices of all storage types.\"\"\"\n        self._inventory_price_rounding(\n            StoragePrice, self._get_methods().inventory_storage_prices\n        )\n\n    @log_start_end\n    def inventory_traffic_prices(self):\n        \"\"\"Get the current prices of all traffic types.\"\"\"\n        self._inventory_price_rounding(\n            TrafficPrice, self._get_methods().inventory_traffic_prices\n        )\n\n    @log_start_end\n    def inventory_ipv4_prices(self):\n        \"\"\"Get the current prices of all IPv4 types.\"\"\"\n        self._inventory_price_rounding(\n            Ipv4Price, self._get_methods().inventory_ipv4_prices\n        )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.session","title":"session  <code>deletable</code> <code>property</code> <code>writable</code>","text":"<pre><code>session\n</code></pre> <p>The Session to use for merging dependent objects into the database.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.progress_tracker","title":"progress_tracker  <code>deletable</code> <code>property</code> <code>writable</code>","text":"<pre><code>progress_tracker\n</code></pre> <p>The sc_crawler.logger.VendorProgressTracker to use for updating progress bars.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.tasks","title":"tasks  <code>property</code>","text":"<pre><code>tasks\n</code></pre> <p>Reexport progress_tracker.tasks for easier access.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.set_table_rows_inactive","title":"set_table_rows_inactive","text":"<pre><code>set_table_rows_inactive(model, *args)\n</code></pre> <p>Set this vendor's records to INACTIVE in a table.</p> <p>Positional arguments can be used to pass further filters (besides the default model.vendor_id filter) referencing the model object with SQLModel syntax.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; aws.set_table_rows_inactive(ServerPrice, ServerPrice.price &lt; 10)\n</code></pre> Source code in <code>sc_crawler/tables.py</code> <pre><code>def set_table_rows_inactive(self, model: str, *args) -&gt; None:\n    \"\"\"Set this vendor's records to [INACTIVE][sc_crawler.table_fields.Status] in a table.\n\n    Positional arguments can be used to pass further filters\n    (besides the default model.vendor_id filter) referencing the\n    model object with SQLModel syntax.\n\n    Examples:\n        &gt;&gt;&gt; aws.set_table_rows_inactive(ServerPrice, ServerPrice.price &lt; 10)  # doctest: +SKIP\n    \"\"\"\n    if self.session:\n        query = update(model).where(model.vendor_id == self.vendor_id)\n        for arg in args:\n            query = query.where(arg)\n        self.session.execute(query.values(status=Status.INACTIVE))\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.set_table_rows_active","title":"set_table_rows_active","text":"<pre><code>set_table_rows_active(model, *args)\n</code></pre> <p>Set this vendor's records to ACTIVE in a table.</p> <p>Positional arguments can be used to pass further filters (besides the default model.vendor_id filter) referencing the model object with SQLModel syntax.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; aws.set_table_rows_active(ServerPrice, ServerPrice.price &lt; 10)\n</code></pre> Source code in <code>sc_crawler/tables.py</code> <pre><code>def set_table_rows_active(self, model: str, *args) -&gt; None:\n    \"\"\"Set this vendor's records to [ACTIVE][sc_crawler.table_fields.Status] in a table.\n\n    Positional arguments can be used to pass further filters\n    (besides the default model.vendor_id filter) referencing the\n    model object with SQLModel syntax.\n\n    Examples:\n        &gt;&gt;&gt; aws.set_table_rows_active(ServerPrice, ServerPrice.price &lt; 10)  # doctest: +SKIP\n    \"\"\"\n    if self.session:\n        query = update(model).where(model.vendor_id == self.vendor_id)\n        for arg in args:\n            query = query.where(arg)\n        self.session.execute(query.values(status=Status.ACTIVE))\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks()\n</code></pre> <p>Get the vendor's all compliance frameworks.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_compliance_frameworks(self):\n    \"\"\"Get the vendor's all compliance frameworks.\"\"\"\n    self._inventory(\n        VendorComplianceLink, self._get_methods().inventory_compliance_frameworks\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions()\n</code></pre> <p>Get the vendor's all regions.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_regions(self):\n    \"\"\"Get the vendor's all regions.\"\"\"\n    self._inventory(Region, self._get_methods().inventory_regions)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones()\n</code></pre> <p>Get all the zones in the vendor's regions.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_zones(self):\n    \"\"\"Get all the zones in the vendor's regions.\"\"\"\n    self._inventory(Zone, self._get_methods().inventory_zones)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers()\n</code></pre> <p>Get the vendor's all server types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_servers(self):\n    \"\"\"Get the vendor's all server types.\"\"\"\n    self.set_table_rows_inactive(Server)\n    servers = self._get_methods().inventory_servers(self)\n    # show progress bar while downloading\n    self.progress_tracker.start_task(\n        name=\"Downloading sc-inspector-data\", total=None\n    )\n    inspector_data_path()\n    self.progress_tracker.hide_task()\n    # actual HW inspection\n    for server in servers:\n        server = inspect_update_server_dict(server)\n    insert_items(Server, servers, self)\n    benchmarks = []\n    self.progress_tracker.start_task(\n        name=\"Searching for benchmark(s)\", total=len(self.servers)\n    )\n    for server in self.servers:\n        benchmarks += inspect_server_benchmarks(server)\n        self.progress_tracker.advance_task()\n    self.progress_tracker.hide_task()\n    self.set_table_rows_inactive(\n        BenchmarkScore, BenchmarkScore.vendor_id == self.vendor_id\n    )\n    insert_items(BenchmarkScore, benchmarks, self)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices()\n</code></pre> <p>Get the current standard/ondemand/reserved prices of all server types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_server_prices(self):\n    \"\"\"Get the current standard/ondemand/reserved prices of all server types.\"\"\"\n    self._inventory_price_rounding(\n        ServerPrice,\n        self._get_methods().inventory_server_prices,\n        ServerPrice.allocation == Allocation.ONDEMAND,\n        prefix=\"ondemand\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot()\n</code></pre> <p>Get the current spot prices of all server types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_server_prices_spot(self):\n    \"\"\"Get the current spot prices of all server types.\"\"\"\n    self._inventory_price_rounding(\n        ServerPrice,\n        self._get_methods().inventory_server_prices_spot,\n        ServerPrice.allocation == Allocation.SPOT,\n        prefix=\"spot\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages()\n</code></pre> <p>Get the vendor's all storage types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_storages(self):\n    \"\"\"Get the vendor's all storage types.\"\"\"\n    self._inventory(Storage, self._get_methods().inventory_storages)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices()\n</code></pre> <p>Get the current prices of all storage types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_storage_prices(self):\n    \"\"\"Get the current prices of all storage types.\"\"\"\n    self._inventory_price_rounding(\n        StoragePrice, self._get_methods().inventory_storage_prices\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices()\n</code></pre> <p>Get the current prices of all traffic types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_traffic_prices(self):\n    \"\"\"Get the current prices of all traffic types.\"\"\"\n    self._inventory_price_rounding(\n        TrafficPrice, self._get_methods().inventory_traffic_prices\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices()\n</code></pre> <p>Get the current prices of all IPv4 types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_ipv4_prices(self):\n    \"\"\"Get the current prices of all IPv4 types.\"\"\"\n    self._inventory_price_rounding(\n        Ipv4Price, self._get_methods().inventory_ipv4_prices\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.VendorComplianceLink","title":"VendorComplianceLink","text":"<p>               Bases: <code>VendorComplianceLinkBase</code></p> <p>List of known Compliance Frameworks paired with vendors.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>compliance_framework_id</code> <code>str</code> <p>Reference to the Compliance Framework.</p> <code>comment</code> <code>Optional[str]</code> <p>Optional references, such as dates, URLs, and additional information/evidence.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class VendorComplianceLink(VendorComplianceLinkBase, table=True):\n    \"\"\"List of known Compliance Frameworks paired with vendors.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"compliance_framework_links\")\n    compliance_framework: ComplianceFramework = Relationship(\n        back_populates=\"vendor_links\"\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Region","title":"Region","text":"<p>               Bases: <code>RegionBase</code></p> <p>Regions of Vendors.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depending on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>aliases</code> <code>List[str]</code> <p>List of other commonly used names for the same Region.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Region is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Region's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Region's location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Region's location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Region's location.</p> <code>lon</code> <code>Optional[float]</code> <p>Longitude coordinate of the Region's known or approximate location.</p> <code>lat</code> <code>Optional[float]</code> <p>Latitude coordinate of the Region's known or approximate location.</p> <code>founding_year</code> <code>Optional[int]</code> <p>4-digit year when the Region was founded.</p> <code>green_energy</code> <code>Optional[bool]</code> <p>If the Region is 100% powered by renewable energy.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Region(RegionBase, table=True):\n    \"\"\"Regions of Vendors.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"regions\")\n    country: Country = Relationship(back_populates=\"regions\")\n\n    zones: List[\"Zone\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    server_prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    traffic_prices: List[\"TrafficPrice\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    ipv4_prices: List[\"Ipv4Price\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    storage_prices: List[\"StoragePrice\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Zone","title":"Zone","text":"<p>               Bases: <code>ZoneBase</code></p> <p>Availability zones of Regions.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depending on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Zone(ZoneBase, table=True):\n    \"\"\"Availability zones of Regions.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n    )\n\n    region: Region = Relationship(\n        back_populates=\"zones\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(Zone.region_id), \"\n                \"Region.vendor_id == foreign(Zone.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n    vendor: Vendor = Relationship(back_populates=\"zones\")\n\n    server_prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"zone\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Storage","title":"Storage","text":"<p>               Bases: <code>StorageBase</code></p> <p>Flexible storage options that can be attached to a Server.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>storage_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>storage_type</code> <code>StorageType</code> <p>High-level category of the storage, e.g. HDD or SDD.</p> <code>max_iops</code> <code>Optional[int]</code> <p>Maximum Input/Output Operations Per Second.</p> <code>max_throughput</code> <code>Optional[int]</code> <p>Maximum Throughput (MiB/s).</p> <code>min_size</code> <code>Optional[int]</code> <p>Minimum required size (GiB).</p> <code>max_size</code> <code>Optional[int]</code> <p>Maximum possible size (GiB).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Storage(StorageBase, table=True):\n    \"\"\"Flexible storage options that can be attached to a Server.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"storages\")\n\n    prices: List[\"StoragePrice\"] = Relationship(\n        back_populates=\"storage\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Server","title":"Server","text":"<p>               Bases: <code>ServerBase</code></p> <p>Server types.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depending on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>family</code> <code>Optional[str]</code> <p>Server family, e.g. General-purpose machine (GCP), or M5g (AWS).</p> <code>vcpus</code> <code>int</code> <p>Default number of virtual CPUs (vCPU) of the server.</p> <code>hypervisor</code> <code>Optional[str]</code> <p>Hypervisor of the virtual server, e.g. Xen, KVM, Nitro or Dedicated.</p> <code>cpu_allocation</code> <code>CpuAllocation</code> <p>Allocation of CPU(s) to the server, e.g. shared, burstable or dedicated.</p> <code>cpu_cores</code> <code>Optional[int]</code> <p>Default number of CPU cores of the server. Equals to vCPUs when HyperThreading is disabled.</p> <code>cpu_speed</code> <code>Optional[float]</code> <p>Vendor-reported maximum CPU clock speed (GHz).</p> <code>cpu_architecture</code> <code>CpuArchitecture</code> <p>CPU architecture (arm64, arm64_mac, i386, or x86_64).</p> <code>cpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary processor, e.g. Intel or AMD.</p> <code>cpu_family</code> <code>Optional[str]</code> <p>The product line/family of the primary processor, e.g. Xeon, Core i7, Ryzen 9.</p> <code>cpu_model</code> <code>Optional[str]</code> <p>The model number of the primary processor, e.g. 9750H.</p> <code>cpu_l1_cache</code> <code>Optional[int]</code> <p>L1 cache size (byte).</p> <code>cpu_l2_cache</code> <code>Optional[int]</code> <p>L2 cache size (byte).</p> <code>cpu_l3_cache</code> <code>Optional[int]</code> <p>L3 cache size (byte).</p> <code>cpu_flags</code> <code>List[str]</code> <p>CPU features/flags.</p> <code>cpus</code> <code>List[Cpu]</code> <p>JSON array of known CPU details, e.g. the manufacturer, family, model; L1/L2/L3 cache size; microcode version; feature flags; bugs etc.</p> <code>memory_amount</code> <code>int</code> <p>RAM amount (MiB).</p> <code>memory_generation</code> <code>Optional[DdrGeneration]</code> <p>Generation of the DDR SDRAM, e.g. DDR4 or DDR5.</p> <code>memory_speed</code> <code>Optional[int]</code> <p>DDR SDRAM clock rate (Mhz).</p> <code>memory_ecc</code> <code>Optional[bool]</code> <p>If the DDR SDRAM uses error correction code to detect and correct n-bit data corruption.</p> <code>gpu_count</code> <code>float</code> <p>Number of GPU accelerator(s).</p> <code>gpu_memory_min</code> <code>Optional[int]</code> <p>Memory (MiB) allocated to the lowest-end GPU accelerator.</p> <code>gpu_memory_total</code> <code>Optional[int]</code> <p>Overall memory (MiB) allocated to all the GPU accelerator(s).</p> <code>gpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary GPU accelerator, e.g. Nvidia or AMD.</p> <code>gpu_family</code> <code>Optional[str]</code> <p>The product family of the primary GPU accelerator, e.g. Turing.</p> <code>gpu_model</code> <code>Optional[str]</code> <p>The model number of the primary GPU accelerator, e.g. Tesla T4.</p> <code>gpus</code> <code>List[Gpu]</code> <p>JSON array of GPU accelerator details, including the manufacturer, name, and memory (MiB) of each GPU.</p> <code>storage_size</code> <code>int</code> <p>Overall size (GB) of the disk(s).</p> <code>storage_type</code> <code>Optional[StorageType]</code> <p>Primary disk type, e.g. HDD, SSD, NVMe SSD, or network).</p> <code>storages</code> <code>List[Disk]</code> <p>JSON array of disks attached to the server, including the size (MiB) and type of each disk.</p> <code>network_speed</code> <code>Optional[float]</code> <p>The baseline network performance (Gbps) of the network card.</p> <code>inbound_traffic</code> <code>float</code> <p>Amount of complimentary inbound traffic (GB) per month.</p> <code>outbound_traffic</code> <code>float</code> <p>Amount of complimentary outbound traffic (GB) per month.</p> <code>ipv4</code> <code>int</code> <p>Number of complimentary IPv4 address(es).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Server(ServerBase, table=True):\n    \"\"\"Server types.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"servers\")\n    prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"server\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    benchmark_scores: List[\"BenchmarkScore\"] = Relationship(\n        back_populates=\"server\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.ServerPrice","title":"ServerPrice","text":"<p>               Bases: <code>ServerPriceBase</code></p> <p>Server type prices per Region and Allocation method.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Reference to the Zone.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>operating_system</code> <code>str</code> <p>Operating System.</p> <code>allocation</code> <code>Allocation</code> <p>Allocation method, e.g. on-demand or spot.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class ServerPrice(ServerPriceBase, table=True):\n    \"\"\"Server type prices per Region and Allocation method.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\", \"zone_id\"],\n            [\"zone.vendor_id\", \"zone.region_id\", \"zone.zone_id\"],\n        ),\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"server_id\"],\n            [\"server.vendor_id\", \"server.server_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"server_prices\")\n    region: Region = Relationship(\n        back_populates=\"server_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(ServerPrice.region_id), \"\n                \"Region.vendor_id == foreign(ServerPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,zone,server\",\n        },\n    )\n    zone: Zone = Relationship(\n        back_populates=\"server_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Zone.zone_id == foreign(ServerPrice.zone_id), \"\n                \"Zone.region_id == foreign(ServerPrice.region_id),\"\n                \"Zone.vendor_id == foreign(ServerPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,region,server\",\n        },\n    )\n    server: Server = Relationship(\n        back_populates=\"prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Server.server_id == foreign(ServerPrice.server_id), \"\n                \"Server.vendor_id == foreign(ServerPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,region,zone\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.StoragePrice","title":"StoragePrice","text":"<p>               Bases: <code>StoragePriceBase</code></p> <p>Flexible Storage prices in each Region.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>storage_id</code> <code>str</code> <p>Reference to the Storage.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class StoragePrice(StoragePriceBase, table=True):\n    \"\"\"Flexible Storage prices in each Region.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"storage_id\"],\n            [\"storage.vendor_id\", \"storage.storage_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"storage_prices\")\n    region: Region = Relationship(\n        back_populates=\"storage_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(StoragePrice.region_id),\"\n                \"Region.vendor_id == foreign(StoragePrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,storage\",\n        },\n    )\n    storage: Storage = Relationship(\n        back_populates=\"prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Storage.storage_id == foreign(StoragePrice.storage_id), \"\n                \"Storage.vendor_id == foreign(StoragePrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,region\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.TrafficPrice","title":"TrafficPrice","text":"<p>               Bases: <code>TrafficPriceBase</code></p> <p>Extra Traffic prices in each Region.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>direction</code> <code>TrafficDirection</code> <p>Direction of the traffic: inbound or outbound.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class TrafficPrice(TrafficPriceBase, table=True):\n    \"\"\"Extra Traffic prices in each Region.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"traffic_prices\")\n    region: Region = Relationship(\n        back_populates=\"traffic_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(TrafficPrice.region_id),\"\n                \"Region.vendor_id == foreign(TrafficPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Ipv4Price","title":"Ipv4Price","text":"<p>               Bases: <code>Ipv4PriceBase</code></p> <p>Price of an IPv4 address in each Region.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Ipv4Price(Ipv4PriceBase, table=True):\n    \"\"\"Price of an IPv4 address in each Region.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"ipv4_prices\")\n    region: Region = Relationship(\n        back_populates=\"ipv4_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(Ipv4Price.region_id),\"\n                \"Region.vendor_id == foreign(Ipv4Price.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Benchmark","title":"Benchmark","text":"<p>               Bases: <code>BenchmarkBase</code></p> <p>Benchmark scenario definitions.</p> <p>Attributes:</p> Name Type Description <code>benchmark_id</code> <code>str</code> <p>Unique identifier of a specific Benchmark.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>framework</code> <code>str</code> <p>The name of the benchmark framework/software/tool used.</p> <code>config_fields</code> <code>dict</code> <p>A dictionary of descriptions on the framework-specific config options, e.g. {\"bandwidth\": \"Memory amount to use for compression in MB.\"}.</p> <code>measurement</code> <code>Optional[str]</code> <p>The name of measurement recorded in the benchmark.</p> <code>unit</code> <code>Optional[str]</code> <p>Optional unit of measurement for the benchmark score.</p> <code>higher_is_better</code> <code>bool</code> <p>If higher benchmark score means better performance, or vica versa.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Benchmark(BenchmarkBase, table=True):\n    \"\"\"Benchmark scenario definitions.\"\"\"\n\n    benchmark_scores: List[\"BenchmarkScore\"] = Relationship(\n        back_populates=\"benchmark\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.BenchmarkScore","title":"BenchmarkScore","text":"<p>               Bases: <code>BenchmarkScoreBase</code></p> <p>Results of running Benchmark scenarios on Servers.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>benchmark_id</code> <code>str</code> <p>Reference to the Benchmark.</p> <code>config</code> <code>HashableDict | dict</code> <p>Dictionary of config parameters of the specific benchmark, e.g. {\"bandwidth\": 4096}</p> <code>score</code> <code>float</code> <p>The resulting score of the benchmark.</p> <code>note</code> <code>Optional[str]</code> <p>Optional note, comment or context on the benchmark score.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class BenchmarkScore(BenchmarkScoreBase, table=True):\n    \"\"\"Results of running Benchmark scenarios on Servers.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"server_id\"],\n            [\"server.vendor_id\", \"server.server_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"benchmark_scores\")\n    server: Server = Relationship(\n        back_populates=\"benchmark_scores\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Server.server_id == foreign(BenchmarkScore.server_id), \"\n                \"Server.vendor_id == foreign(BenchmarkScore.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n    benchmark: Benchmark = Relationship(back_populates=\"benchmark_scores\")\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.tables","title":"tables  <code>module-attribute</code>","text":"<pre><code>tables = [o for o in (values()) if is_table(o)]\n</code></pre> <p>List of all SQLModel (table) models.</p>"},{"location":"reference/sc_crawler/tables_scd/","title":"tables_scd","text":""},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd","title":"sc_crawler.tables_scd","text":"<p>SCD version of the table definitions in sc_crawler.tables.</p> <p>Classes:</p> Name Description <code>Scd</code> <p>Override the <code>observed_at</code> column to be primary key in SCD tables.</p> <code>CountryScd</code> <p>Country and continent mapping (SCD Type 2).</p> <code>VendorComplianceLinkScd</code> <p>List of known Compliance Frameworks paired with vendors (SCD Type 2).</p> <code>ComplianceFrameworkScd</code> <p>List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1 (SCD Type 2).</p> <code>VendorScd</code> <p>Compute resource vendors, such as cloud and server providers (SCD Type 2).</p> <code>RegionScd</code> <p>Regions of Vendors (SCD Type 2).</p> <code>ZoneScd</code> <p>Availability zones of Regions (SCD Type 2).</p> <code>StorageScd</code> <p>Flexible storage options that can be attached to a Server (SCD Type 2).</p> <code>ServerScd</code> <p>Server types (SCD Type 2).</p> <code>ServerPriceScd</code> <p>Server type prices per Region and Allocation method (SCD Type 2).</p> <code>StoragePriceScd</code> <p>Flexible Storage prices in each Region (SCD Type 2).</p> <code>TrafficPriceScd</code> <p>Extra Traffic prices in each Region (SCD Type 2).</p> <code>Ipv4PriceScd</code> <p>Price of an IPv4 address in each Region (SCD Type 2).</p> <code>BenchmarkScd</code> <p>Benchmark scenario definitions (SCD Type 2).</p> <code>BenchmarkScoreScd</code> <p>Results of running Benchmark scenarios on Servers (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>tables_scd</code> <code>List[SQLModel]</code> <p>List of all SCD SQLModel (table) models.</p>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.Scd","title":"Scd","text":"<p>               Bases: <code>ScModel</code></p> <p>Override the <code>observed_at</code> column to be primary key in SCD tables.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class Scd(ScModel):\n    \"\"\"Override the `observed_at` column to be primary key in SCD tables.\"\"\"\n\n    observed_at: datetime = Field(\n        primary_key=True,\n        default_factory=lambda: datetime.now(UTC),\n        sa_column_kwargs={\"onupdate\": lambda: datetime.now(UTC)},\n        description=\"Timestamp of the last observation.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.CountryScd","title":"CountryScd","text":"<p>               Bases: <code>Scd</code>, <code>CountryBase</code></p> <p>Country and continent mapping (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>country_id</code> <code>str</code> <p>Country code by ISO 3166 alpha-2.</p> <code>continent</code> <code>str</code> <p>Continent name.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class CountryScd(Scd, CountryBase, table=True):\n    \"\"\"SCD version of .tables.Country.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.VendorComplianceLinkScd","title":"VendorComplianceLinkScd","text":"<p>               Bases: <code>Scd</code>, <code>VendorComplianceLinkBase</code></p> <p>List of known Compliance Frameworks paired with vendors (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>compliance_framework_id</code> <code>str</code> <p>Reference to the Compliance Framework.</p> <code>comment</code> <code>Optional[str]</code> <p>Optional references, such as dates, URLs, and additional information/evidence.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class VendorComplianceLinkScd(Scd, VendorComplianceLinkBase, table=True):\n    \"\"\"SCD version of .tables.VendorComplianceLink.\"\"\"\n\n    compliance_framework_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Compliance Framework.\",\n    )\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ComplianceFrameworkScd","title":"ComplianceFrameworkScd","text":"<p>               Bases: <code>Scd</code>, <code>ComplianceFrameworkBase</code></p> <p>List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1 (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>compliance_framework_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>abbreviation</code> <code>Optional[str]</code> <p>Short abbreviation of the Framework name.</p> <code>description</code> <code>Optional[str]</code> <p>Description of the framework in a few paragraphs, outlining key features and characteristics for reference.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Framework's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage with more information on the Framework.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ComplianceFrameworkScd(Scd, ComplianceFrameworkBase, table=True):\n    \"\"\"SCD version of .tables.ComplianceFramework.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.VendorScd","title":"VendorScd","text":"<p>               Bases: <code>Scd</code>, <code>VendorBase</code></p> <p>Compute resource vendors, such as cloud and server providers (SCD Type 2).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sc_crawler.tables import Vendor\n&gt;&gt;&gt; from sc_crawler.lookup import countries\n&gt;&gt;&gt; aws = Vendor(vendor_id='aws', name='Amazon Web Services', homepage='https://aws.amazon.com', country=countries[\"US\"], founding_year=2002)\n&gt;&gt;&gt; aws\nVendor(vendor_id='aws'...\n&gt;&gt;&gt; from sc_crawler import vendors\n&gt;&gt;&gt; vendors.aws\nVendor(vendor_id='aws'...\n</code></pre> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Vendor's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage of the Vendor.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Vendor's main headquarter is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Vendor's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Vendor's main location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Vendor's main location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Vendor's main location.</p> <code>founding_year</code> <code>int</code> <p>4-digit year when the public cloud service of the Vendor was launched.</p> <code>status_page</code> <code>Optional[str]</code> <p>Public status page of the Vendor.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class VendorScd(Scd, VendorBase, table=True):\n    \"\"\"SCD version of .tables.Vendor.\"\"\"\n\n    country_id: str = Field(\n        description=\"Reference to the Country, where the Vendor's main headquarter is located.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.RegionScd","title":"RegionScd","text":"<p>               Bases: <code>Scd</code>, <code>RegionBase</code></p> <p>Regions of Vendors (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depending on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>aliases</code> <code>List[str]</code> <p>List of other commonly used names for the same Region.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Region is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Region's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Region's location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Region's location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Region's location.</p> <code>lon</code> <code>Optional[float]</code> <p>Longitude coordinate of the Region's known or approximate location.</p> <code>lat</code> <code>Optional[float]</code> <p>Latitude coordinate of the Region's known or approximate location.</p> <code>founding_year</code> <code>Optional[int]</code> <p>4-digit year when the Region was founded.</p> <code>green_energy</code> <code>Optional[bool]</code> <p>If the Region is 100% powered by renewable energy.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class RegionScd(Scd, RegionBase, table=True):\n    \"\"\"SCD version of .tables.Region.\"\"\"\n\n    country_id: str = Field(\n        description=\"Reference to the Country, where the Region is located.\",\n    )\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ZoneScd","title":"ZoneScd","text":"<p>               Bases: <code>Scd</code>, <code>ZoneBase</code></p> <p>Availability zones of Regions (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depending on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ZoneScd(Scd, ZoneBase, table=True):\n    \"\"\"SCD version of .tables.Zone.\"\"\"\n\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.StorageScd","title":"StorageScd","text":"<p>               Bases: <code>Scd</code>, <code>StorageBase</code></p> <p>Flexible storage options that can be attached to a Server (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>storage_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>storage_type</code> <code>StorageType</code> <p>High-level category of the storage, e.g. HDD or SDD.</p> <code>max_iops</code> <code>Optional[int]</code> <p>Maximum Input/Output Operations Per Second.</p> <code>max_throughput</code> <code>Optional[int]</code> <p>Maximum Throughput (MiB/s).</p> <code>min_size</code> <code>Optional[int]</code> <p>Minimum required size (GiB).</p> <code>max_size</code> <code>Optional[int]</code> <p>Maximum possible size (GiB).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class StorageScd(Scd, StorageBase, table=True):\n    \"\"\"SCD version of .tables.Storage.\"\"\"\n\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ServerScd","title":"ServerScd","text":"<p>               Bases: <code>Scd</code>, <code>ServerBase</code></p> <p>Server types (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depending on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>family</code> <code>Optional[str]</code> <p>Server family, e.g. General-purpose machine (GCP), or M5g (AWS).</p> <code>vcpus</code> <code>int</code> <p>Default number of virtual CPUs (vCPU) of the server.</p> <code>hypervisor</code> <code>Optional[str]</code> <p>Hypervisor of the virtual server, e.g. Xen, KVM, Nitro or Dedicated.</p> <code>cpu_allocation</code> <code>CpuAllocation</code> <p>Allocation of CPU(s) to the server, e.g. shared, burstable or dedicated.</p> <code>cpu_cores</code> <code>Optional[int]</code> <p>Default number of CPU cores of the server. Equals to vCPUs when HyperThreading is disabled.</p> <code>cpu_speed</code> <code>Optional[float]</code> <p>Vendor-reported maximum CPU clock speed (GHz).</p> <code>cpu_architecture</code> <code>CpuArchitecture</code> <p>CPU architecture (arm64, arm64_mac, i386, or x86_64).</p> <code>cpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary processor, e.g. Intel or AMD.</p> <code>cpu_family</code> <code>Optional[str]</code> <p>The product line/family of the primary processor, e.g. Xeon, Core i7, Ryzen 9.</p> <code>cpu_model</code> <code>Optional[str]</code> <p>The model number of the primary processor, e.g. 9750H.</p> <code>cpu_l1_cache</code> <code>Optional[int]</code> <p>L1 cache size (byte).</p> <code>cpu_l2_cache</code> <code>Optional[int]</code> <p>L2 cache size (byte).</p> <code>cpu_l3_cache</code> <code>Optional[int]</code> <p>L3 cache size (byte).</p> <code>cpu_flags</code> <code>List[str]</code> <p>CPU features/flags.</p> <code>cpus</code> <code>List[Cpu]</code> <p>JSON array of known CPU details, e.g. the manufacturer, family, model; L1/L2/L3 cache size; microcode version; feature flags; bugs etc.</p> <code>memory_amount</code> <code>int</code> <p>RAM amount (MiB).</p> <code>memory_generation</code> <code>Optional[DdrGeneration]</code> <p>Generation of the DDR SDRAM, e.g. DDR4 or DDR5.</p> <code>memory_speed</code> <code>Optional[int]</code> <p>DDR SDRAM clock rate (Mhz).</p> <code>memory_ecc</code> <code>Optional[bool]</code> <p>If the DDR SDRAM uses error correction code to detect and correct n-bit data corruption.</p> <code>gpu_count</code> <code>float</code> <p>Number of GPU accelerator(s).</p> <code>gpu_memory_min</code> <code>Optional[int]</code> <p>Memory (MiB) allocated to the lowest-end GPU accelerator.</p> <code>gpu_memory_total</code> <code>Optional[int]</code> <p>Overall memory (MiB) allocated to all the GPU accelerator(s).</p> <code>gpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary GPU accelerator, e.g. Nvidia or AMD.</p> <code>gpu_family</code> <code>Optional[str]</code> <p>The product family of the primary GPU accelerator, e.g. Turing.</p> <code>gpu_model</code> <code>Optional[str]</code> <p>The model number of the primary GPU accelerator, e.g. Tesla T4.</p> <code>gpus</code> <code>List[Gpu]</code> <p>JSON array of GPU accelerator details, including the manufacturer, name, and memory (MiB) of each GPU.</p> <code>storage_size</code> <code>int</code> <p>Overall size (GB) of the disk(s).</p> <code>storage_type</code> <code>Optional[StorageType]</code> <p>Primary disk type, e.g. HDD, SSD, NVMe SSD, or network).</p> <code>storages</code> <code>List[Disk]</code> <p>JSON array of disks attached to the server, including the size (MiB) and type of each disk.</p> <code>network_speed</code> <code>Optional[float]</code> <p>The baseline network performance (Gbps) of the network card.</p> <code>inbound_traffic</code> <code>float</code> <p>Amount of complimentary inbound traffic (GB) per month.</p> <code>outbound_traffic</code> <code>float</code> <p>Amount of complimentary outbound traffic (GB) per month.</p> <code>ipv4</code> <code>int</code> <p>Number of complimentary IPv4 address(es).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ServerScd(Scd, ServerBase, table=True):\n    \"\"\"SCD version of .tables.Server.\"\"\"\n\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ServerPriceScd","title":"ServerPriceScd","text":"<p>               Bases: <code>Scd</code>, <code>ServerPriceBase</code></p> <p>Server type prices per Region and Allocation method (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Reference to the Zone.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>operating_system</code> <code>str</code> <p>Operating System.</p> <code>allocation</code> <code>Allocation</code> <p>Allocation method, e.g. on-demand or spot.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ServerPriceScd(Scd, ServerPriceBase, table=True):\n    \"\"\"SCD version of .tables.ServerPrice.\"\"\"\n\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.StoragePriceScd","title":"StoragePriceScd","text":"<p>               Bases: <code>Scd</code>, <code>StoragePriceBase</code></p> <p>Flexible Storage prices in each Region (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>storage_id</code> <code>str</code> <p>Reference to the Storage.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class StoragePriceScd(Scd, StoragePriceBase, table=True):\n    \"\"\"SCD version of .tables.StoragePrice.\"\"\"\n\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.TrafficPriceScd","title":"TrafficPriceScd","text":"<p>               Bases: <code>Scd</code>, <code>TrafficPriceBase</code></p> <p>Extra Traffic prices in each Region (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>direction</code> <code>TrafficDirection</code> <p>Direction of the traffic: inbound or outbound.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class TrafficPriceScd(Scd, TrafficPriceBase, table=True):\n    \"\"\"SCD version of .tables.TrafficPrice.\"\"\"\n\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.Ipv4PriceScd","title":"Ipv4PriceScd","text":"<p>               Bases: <code>Scd</code>, <code>Ipv4PriceBase</code></p> <p>Price of an IPv4 address in each Region (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class Ipv4PriceScd(Scd, Ipv4PriceBase, table=True):\n    \"\"\"SCD version of .tables.Ipv4Price.\"\"\"\n\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.BenchmarkScd","title":"BenchmarkScd","text":"<p>               Bases: <code>Scd</code>, <code>BenchmarkBase</code></p> <p>Benchmark scenario definitions (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>benchmark_id</code> <code>str</code> <p>Unique identifier of a specific Benchmark.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>framework</code> <code>str</code> <p>The name of the benchmark framework/software/tool used.</p> <code>config_fields</code> <code>dict</code> <p>A dictionary of descriptions on the framework-specific config options, e.g. {\"bandwidth\": \"Memory amount to use for compression in MB.\"}.</p> <code>measurement</code> <code>Optional[str]</code> <p>The name of measurement recorded in the benchmark.</p> <code>unit</code> <code>Optional[str]</code> <p>Optional unit of measurement for the benchmark score.</p> <code>higher_is_better</code> <code>bool</code> <p>If higher benchmark score means better performance, or vica versa.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class BenchmarkScd(Scd, BenchmarkBase, table=True):\n    \"\"\"SCD version of .tables.Benchmark.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.BenchmarkScoreScd","title":"BenchmarkScoreScd","text":"<p>               Bases: <code>Scd</code>, <code>BenchmarkScoreBase</code></p> <p>Results of running Benchmark scenarios on Servers (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>benchmark_id</code> <code>str</code> <p>Reference to the Benchmark.</p> <code>config</code> <code>HashableDict | dict</code> <p>Dictionary of config parameters of the specific benchmark, e.g. {\"bandwidth\": 4096}</p> <code>score</code> <code>float</code> <p>The resulting score of the benchmark.</p> <code>note</code> <code>Optional[str]</code> <p>Optional note, comment or context on the benchmark score.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class BenchmarkScoreScd(Scd, BenchmarkScoreBase, table=True):\n    \"\"\"SCD version of .tables.BenchmarkScore.\"\"\"\n\n    benchmark_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Benchmark.\",\n    )\n    vendor_id: str = Field(\n        primary_key=True,\n        description=\"Reference to the Vendor.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.tables_scd","title":"tables_scd  <code>module-attribute</code>","text":"<pre><code>tables_scd = [o for o in (values()) if is_table(o)]\n</code></pre> <p>List of all SCD SQLModel (table) models.</p>"},{"location":"reference/sc_crawler/utils/","title":"utils","text":""},{"location":"reference/sc_crawler/utils/#sc_crawler.utils","title":"sc_crawler.utils","text":"<p>Functions:</p> Name Description <code>jsoned_hash</code> <p>Hash the JSON-dump of all positional and keyword arguments.</p> <code>hash_database</code> <p>Hash the content of a database.</p> <code>chunk_list</code> <p>Split a list into chunks of a specified size.</p> <code>scmodels_to_dict</code> <p>Creates a dict indexed by key(s) of the ScModels of the list.</p> <code>is_sqlite</code> <p>Checks if a SQLModel session is binded to a SQLite database.</p> <code>is_postgresql</code> <p>Checks if a SQLModel session is binded to a PostgreSQL-like database.</p> <code>float_inf_to_str</code> <p>Transform to string if a float is inf.</p> <code>table_name_to_model</code> <p>Return the ScModel schema for a table name.</p> <code>get_row_by_pk</code> <p>Get a row from a table definition by primary keys.</p> <code>nesteddefaultdict</code> <p>Recursive defaultdict.</p> <code>list_search</code> <p>Search for a dict in a list with the given key/value pair.</p> <code>convert_gb_to_mib</code> <p>Convert gigabytes to mebibytes.</p>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.jsoned_hash","title":"jsoned_hash","text":"<pre><code>jsoned_hash(*args, **kwargs)\n</code></pre> <p>Hash the JSON-dump of all positional and keyword arguments.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; jsoned_hash(42)\n'0211c62419aece235ba19582d3cf7fd8e25f837c'\n&gt;&gt;&gt; jsoned_hash(everything=42)\n'8f8a7fcade8cb632b856f46fc64c1725ee387617'\n&gt;&gt;&gt; jsoned_hash(42, 42, everything=42)\n'f04a77f000d85929b13de04b436c60a1272dfbf5'\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def jsoned_hash(*args, **kwargs):\n    \"\"\"Hash the JSON-dump of all positional and keyword arguments.\n\n    Examples:\n        &gt;&gt;&gt; jsoned_hash(42)\n        '0211c62419aece235ba19582d3cf7fd8e25f837c'\n        &gt;&gt;&gt; jsoned_hash(everything=42)\n        '8f8a7fcade8cb632b856f46fc64c1725ee387617'\n        &gt;&gt;&gt; jsoned_hash(42, 42, everything=42)\n        'f04a77f000d85929b13de04b436c60a1272dfbf5'\n    \"\"\"\n    return sha1(\n        dumps({\"args\": args, \"kwargs\": kwargs}, sort_keys=True).encode()\n    ).hexdigest()\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.hash_database","title":"hash_database","text":"<pre><code>hash_database(connection_string, level=DATABASE, ignored=['observed_at'], progress=None, exclude_tables=[])\n</code></pre> <p>Hash the content of a database.</p> <p>Parameters:</p> Name Type Description Default <code>connection_string</code> <code>str</code> <p>SQLAlchemy connection string to connect to the database.</p> required <code>level</code> <code>HashLevels</code> <p>The level at which to apply hashing. Possible values are 'DATABASE' (default), 'TABLE', or 'ROW'.</p> <code>DATABASE</code> <code>ignored</code> <code>List[str]</code> <p>List of column names to be ignored during hashing.</p> <code>['observed_at']</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to track the status of the hashing.</p> <code>None</code> <code>exclude_tables</code> <code>List[ScModel]</code> <p>Optional list of tables not to be hashed.</p> <code>[]</code> <p>Returns:</p> Type Description <code>Union[str, dict]</code> <p>A single SHA1 hash or dict of hashes, depending on the level.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def hash_database(\n    connection_string: str,\n    level: HashLevels = HashLevels.DATABASE,\n    ignored: List[str] = [\"observed_at\"],\n    progress: Optional[Progress] = None,\n    exclude_tables: List[ScModel] = [],\n) -&gt; Union[str, dict]:\n    \"\"\"Hash the content of a database.\n\n    Args:\n        connection_string: SQLAlchemy connection string to connect to the database.\n        level: The level at which to apply hashing. Possible values are 'DATABASE' (default), 'TABLE', or 'ROW'.\n        ignored: List of column names to be ignored during hashing.\n        progress: Optional progress bar to track the status of the hashing.\n        exclude_tables: Optional list of tables not to be hashed.\n\n    Returns:\n        A single SHA1 hash or dict of hashes, depending on the level.\n    \"\"\"\n    from .tables import tables as alltables\n\n    tables_to_sync = [t for t in alltables if t not in exclude_tables]\n\n    if progress:\n        tables_task_id = progress.add_task(\"Hashing tables\", total=len(tables_to_sync))\n\n    engine = create_engine(connection_string)\n\n    with Session(engine) as session:\n        hashes = {}\n        for table in tables_to_sync:\n            table_name = table.get_table_name()\n            hashes[table_name] = table.hash(session, ignored=ignored, progress=progress)\n            if progress:\n                progress.update(tables_task_id, advance=1)\n\n    if level == HashLevels.TABLE:\n        hashes = {k: jsoned_hash(v) for k, v in hashes.items()}\n\n    if level == HashLevels.DATABASE:\n        hashes = jsoned_hash(hashes)\n\n    return hashes\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.chunk_list","title":"chunk_list","text":"<pre><code>chunk_list(items, size)\n</code></pre> <p>Split a list into chunks of a specified size.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; [len(x) for x in chunk_list(range(10), 3)]\n[3, 3, 3, 1]\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def chunk_list(items: List[Any], size: int) -&gt; Iterable[List[Any]]:\n    \"\"\"Split a list into chunks of a specified size.\n\n    Examples:\n        &gt;&gt;&gt; [len(x) for x in chunk_list(range(10), 3)]\n        [3, 3, 3, 1]\n    \"\"\"\n    for i in range(0, len(items), size):\n        yield items[i : i + size]\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.scmodels_to_dict","title":"scmodels_to_dict","text":"<pre><code>scmodels_to_dict(scmodels, keys)\n</code></pre> <p>Creates a dict indexed by key(s) of the ScModels of the list.</p> <p>When multiple keys are provided, each ScModel instance will be stored in the dict with all keys. If a key is a list, then each list element is considered (not recursively, only at first level) as a key. Conflict of keys is not checked.</p> <p>Parameters:</p> Name Type Description Default <code>scmodels</code> <code>List[ScModel]</code> <p>list of ScModel instances</p> required <code>keys</code> <code>List[str]</code> <p>a list of strings referring to ScModel fields to be used as keys</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sc_crawler.vendors import aws\n&gt;&gt;&gt; scmodels_to_dict([aws], keys=[\"vendor_id\", \"name\"])\n{'aws': Vendor...\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def scmodels_to_dict(scmodels: List[ScModel], keys: List[str]) -&gt; Dict[str, ScModel]:\n    \"\"\"Creates a dict indexed by key(s) of the ScModels of the list.\n\n    When multiple keys are provided, each ScModel instance will be stored in\n    the dict with all keys. If a key is a list, then each list element is\n    considered (not recursively, only at first level) as a key.\n    Conflict of keys is not checked.\n\n    Args:\n        scmodels: list of ScModel instances\n        keys: a list of strings referring to ScModel fields to be used as keys\n\n    Examples:\n        &gt;&gt;&gt; from sc_crawler.vendors import aws\n        &gt;&gt;&gt; scmodels_to_dict([aws], keys=[\"vendor_id\", \"name\"])\n        {'aws': Vendor...\n    \"\"\"\n    data = {}\n    for key in keys:\n        for scmodel in scmodels:\n            data_keys = getattr(scmodel, key)\n            if not isinstance(data_keys, list):\n                data_keys = [data_keys]\n            for data_key in data_keys:\n                data[data_key] = scmodel\n    return data\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.is_sqlite","title":"is_sqlite","text":"<pre><code>is_sqlite(session)\n</code></pre> <p>Checks if a SQLModel session is binded to a SQLite database.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def is_sqlite(session: Session) -&gt; bool:\n    \"\"\"Checks if a SQLModel session is binded to a SQLite database.\"\"\"\n    return session.bind.dialect.name == \"sqlite\"\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.is_postgresql","title":"is_postgresql","text":"<pre><code>is_postgresql(session)\n</code></pre> <p>Checks if a SQLModel session is binded to a PostgreSQL-like database.</p> <p>Dialect name is checked for PostgreSQL or CockroachDB.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def is_postgresql(session: Session) -&gt; bool:\n    \"\"\"Checks if a SQLModel session is binded to a PostgreSQL-like database.\n\n    Dialect name is checked for PostgreSQL or CockroachDB.\"\"\"\n    return session.bind.dialect.name in [\"postgresql\", \"cockroachdb\"]\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.float_inf_to_str","title":"float_inf_to_str","text":"<pre><code>float_inf_to_str(x)\n</code></pre> <p>Transform to string if a float is inf.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def float_inf_to_str(x: float) -&gt; Union[float, str]:\n    \"\"\"Transform to string if a float is inf.\"\"\"\n    return \"Infinity\" if isinf(x) else x\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.table_name_to_model","title":"table_name_to_model","text":"<pre><code>table_name_to_model(table_name)\n</code></pre> <p>Return the ScModel schema for a table name.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def table_name_to_model(table_name: str) -&gt; ScModel:\n    \"\"\"Return the ScModel schema for a table name.\"\"\"\n    from .tables import tables\n\n    return [t for t in tables if t.get_table_name() == table_name][0]\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.get_row_by_pk","title":"get_row_by_pk","text":"<pre><code>get_row_by_pk(session, model, pks)\n</code></pre> <p>Get a row from a table definition by primary keys.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Connection for database connections.</p> required <code>model</code> <code>ScModel</code> <p>An ScModel schema definition with table reference.</p> required <code>pks</code> <code>dict</code> <p>Dictionary of all the primary keys for the row,.</p> required <p>Returns:</p> Type Description <code>ScModel</code> <p>ScModel object read from the database.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def get_row_by_pk(session: Session, model: ScModel, pks: dict) -&gt; ScModel:\n    \"\"\"Get a row from a table definition by primary keys.\n\n    Args:\n        session: Connection for database connections.\n        model: An ScModel schema definition with table reference.\n        pks: Dictionary of all the primary keys for the row,.\n\n    Returns:\n        ScModel object read from the database.\n    \"\"\"\n    q = select(model)\n    for k, v in pks.items():\n        q = q.where(getattr(model, k) == v)\n    return session.exec(statement=q).one()\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.nesteddefaultdict","title":"nesteddefaultdict","text":"<pre><code>nesteddefaultdict()\n</code></pre> <p>Recursive defaultdict.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; foo = nesteddefaultdict()\n&gt;&gt;&gt; foo[\"bar\"][\"baz\"] = 43\n&gt;&gt;&gt; from json import dumps\n&gt;&gt;&gt; dumps(foo)\n'{\"bar\": {\"baz\": 43}}'\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def nesteddefaultdict():\n    \"\"\"Recursive defaultdict.\n\n    Examples:\n        &gt;&gt;&gt; foo = nesteddefaultdict()\n        &gt;&gt;&gt; foo[\"bar\"][\"baz\"] = 43\n        &gt;&gt;&gt; from json import dumps\n        &gt;&gt;&gt; dumps(foo)\n        '{\"bar\": {\"baz\": 43}}'\n    \"\"\"\n    return defaultdict(nesteddefaultdict)\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.list_search","title":"list_search","text":"<pre><code>list_search(items, key, values)\n</code></pre> <p>Search for a dict in a list with the given key/value pair.</p> <p>When multiple values are provided, it will use the first field with a matching name with either keys.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def list_search(items: List[dict], key: str, values: Union[Any, List[Any]]) -&gt; dict:\n    \"\"\"Search for a dict in a list with the given key/value pair.\n\n    When multiple values are provided, it will use the first field with a\n    matching name with either keys.\n    \"\"\"\n    if not isinstance(values, list):\n        values = [values]\n    return next((item for item in items if item[key] in values), None)\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.convert_gb_to_mib","title":"convert_gb_to_mib","text":"<pre><code>convert_gb_to_mib(gb)\n</code></pre> <p>Convert gigabytes to mebibytes.</p> <p>Parameters:</p> Name Type Description Default <code>gb</code> <code>int</code> <p>Size in gigabytes (GB, decimal: 10^9 bytes).</p> required <p>Returns:</p> Type Description <code>int</code> <p>Size in mebibytes (MiB, binary: 2^20 bytes).</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def convert_gb_to_mib(gb: int) -&gt; int:\n    \"\"\"Convert gigabytes to mebibytes.\n\n    Args:\n        gb: Size in gigabytes (GB, decimal: 10^9 bytes).\n\n    Returns:\n        Size in mebibytes (MiB, binary: 2^20 bytes).\n    \"\"\"\n    return int(gb * 1_000_000_000 / 1_048_576)\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/","title":"vendor_helpers","text":""},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers","title":"sc_crawler.vendor_helpers","text":"<p>Functions:</p> Name Description <code>fetch_servers</code> <p>Fetch servers of a region/zone.</p> <code>parallel_fetch_servers</code> <p>Fetch servers of all regions/zones in parallel on 8 threads.</p> <code>preprocess_servers</code> <p>Preprocess servers before inserting into the database.</p> <code>add_vendor_id</code> <p>Adds <code>vendor_id</code> field to a dict.</p> <code>get_region_by_id</code> <p>Get a region by its ID or alias.</p>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.fetch_servers","title":"fetch_servers","text":"<pre><code>fetch_servers(fn, where, vendor)\n</code></pre> <p>Fetch servers of a region/zone.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>A function that takes the region or zone id as its first and only argument. The returning list must conform with the Server object, or need to be in a format that preprocess_servers's <code>fn</code> can manage.</p> required <code>where</code> <code>str</code> <p>A Region or Zone <code>api_reference</code> or similar that is passed to <code>fn</code>.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional Vendor instance used for logging and progress bar updates.</p> required Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def fetch_servers(fn: Callable, where: str, vendor: Optional[Vendor]) -&gt; List[dict]:\n    \"\"\"Fetch servers of a region/zone.\n\n    Args:\n        fn: A function that takes the region or zone id as its first and only argument.\n            The returning list must conform with the Server object, or need to\n            be in a format that [preprocess_servers][sc_crawler.vendor_helpers.preprocess_servers]'s\n            `fn` can manage.\n        where: A [Region][sc_crawler.tables.Region] or [Zone][sc_crawler.tables.Zone]\n            `api_reference` or similar that is passed to `fn`.\n        vendor: Optional [Vendor][sc_crawler.tables.Vendor] instance used for\n            logging and progress bar updates.\n    \"\"\"\n    servers = fn(where)\n    if vendor:\n        vendor.log(f\"{len(servers)} server(s) found in {where}.\")\n    if vendor:\n        vendor.progress_tracker.advance_task()\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.parallel_fetch_servers","title":"parallel_fetch_servers","text":"<pre><code>parallel_fetch_servers(vendor, fn, id_col, by)\n</code></pre> <p>Fetch servers of all regions/zones in parallel on 8 threads.</p> <p>Parameters:</p> Name Type Description Default <code>vendor</code> <code>Vendor</code> <p>Required Vendor instance used for the regions lookup, logging and progress bar updates.</p> required <code>fn</code> <code>Callable</code> <p>A function to be passed to fetch_servers.</p> required <code>id_col</code> <code>str</code> <p>Field name to be used to deduplicate the list of server dicts.</p> required <code>by</code> <code>Literal['regions', 'zones']</code> <p>What objects of the <code>vendor</code> to iterate on.</p> required Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def parallel_fetch_servers(\n    vendor: Vendor, fn: Callable, id_col: str, by: Literal[\"regions\", \"zones\"]\n) -&gt; List[dict]:\n    \"\"\"Fetch servers of all regions/zones in parallel on 8 threads.\n\n    Args:\n        vendor: Required [Vendor][sc_crawler.tables.Vendor] instance used for\n            the regions lookup, logging and progress bar updates.\n        fn: A function to be passed to [fetch_servers][sc_crawler.vendor_helpers.fetch_servers].\n        id_col: Field name to be used to deduplicate the list of server dicts.\n        by: What objects of the `vendor` to iterate on.\n    \"\"\"\n\n    locations = [\n        i.api_reference for i in getattr(vendor, by) if i.status == Status.ACTIVE\n    ]\n    vendor.progress_tracker.start_task(\n        name=f\"Scanning {by} for server(s)\", total=len(locations)\n    )\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        servers = executor.map(fetch_servers, repeat(fn), locations, repeat(vendor))\n    servers = list(chain.from_iterable(servers))\n\n    vendor.log(f\"{len(servers)} server(s) found in {len(locations)} {by}.\")\n    servers = list({s[id_col]: s for s in servers}.values())\n    vendor.log(f\"{len(servers)} unique server(s) found.\")\n    active_servers = [\n        s for s in servers if s.get(\"status\", Status.ACTIVE) == Status.ACTIVE\n    ]\n    vendor.log(f\"{len(active_servers)} ACTIVE server(s) found.\")\n    vendor.progress_tracker.hide_task()\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.preprocess_servers","title":"preprocess_servers","text":"<pre><code>preprocess_servers(servers, vendor, fn)\n</code></pre> <p>Preprocess servers before inserting into the database.</p> <p>Takes a list of dicts and tranform to a list of dicts that follows the Server schema.</p> <p>Parameters:</p> Name Type Description Default <code>servers</code> <code>List[dict]</code> <p>To be passed to <code>fn</code>.</p> required <code>vendor</code> <code>Vendor</code> <p>The related Vendor instance used for database connection, logging and progress bar updates.</p> required <code>fn</code> <code>Callable</code> <p>A function that takes a server from <code>servers</code> (one-by-one) and the <code>vendor</code>.</p> required Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def preprocess_servers(servers: List[dict], vendor: Vendor, fn: Callable) -&gt; List[dict]:\n    \"\"\"Preprocess servers before inserting into the database.\n\n    Takes a list of dicts and tranform to a list of dicts that\n    follows the [Server][sc_crawler.tables.Server] schema.\n\n    Args:\n        servers: To be passed to `fn`.\n        vendor: The related [Vendor][sc_crawler.tables.Vendor] instance used\n            for database connection, logging and progress bar updates.\n        fn: A function that takes a server from `servers` (one-by-one) and the `vendor`.\n    \"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Preprocessing server(s)\", total=len(servers)\n    )\n    processed = []\n    for server in servers:\n        processed.append(fn(server, vendor))\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return processed\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.add_vendor_id","title":"add_vendor_id","text":"<pre><code>add_vendor_id(obj, vendor)\n</code></pre> <p>Adds <code>vendor_id</code> field to a dict.</p> Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def add_vendor_id(obj: dict, vendor: Vendor) -&gt; dict:\n    \"\"\"Adds `vendor_id` field to a dict.\"\"\"\n    obj[\"vendor_id\"] = vendor.vendor_id\n    return obj\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.get_region_by_id","title":"get_region_by_id","text":"<pre><code>get_region_by_id(region_id, vendor)\n</code></pre> <p>Get a region by its ID or alias.</p> <p>Parameters:</p> Name Type Description Default <code>region_id</code> <code>str</code> <p>The ID or alias of the region to get.</p> required <code>vendor</code> <code>Vendor</code> <p>The vendor to get the region from.</p> required <p>Returns:</p> Type Description <code>Optional[Region]</code> <p>The region if found, otherwise None.</p> Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def get_region_by_id(region_id: str, vendor: Vendor) -&gt; Optional[Region]:\n    \"\"\"Get a [region][sc_crawler.tables.Region] by its ID or alias.\n\n    Args:\n        region_id: The ID or alias of the region to get.\n        vendor: The [vendor][sc_crawler.tables.Vendor] to get the region from.\n\n    Returns:\n        The [region][sc_crawler.tables.Region] if found, otherwise None.\n    \"\"\"\n    return next(\n        (\n            region\n            for region in vendor.regions\n            if (region_id in [region.api_reference, *region.aliases])\n        ),\n        None,\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/","title":"vendors","text":""},{"location":"reference/sc_crawler/vendors/#sc_crawler.vendors","title":"sc_crawler.vendors","text":"<p>Helper methods for each cloud compute resource provider.</p> <p>Modules:</p> Name Description <code>vendors</code> <p>Supported cloud and VPS provider vendors.</p>"},{"location":"reference/sc_crawler/vendors/_alicloud/","title":"_alicloud","text":""},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud","title":"sc_crawler.vendors._alicloud","text":"<p>Functions:</p> Name Description <code>inventory_compliance_frameworks</code> <p>Manual list of compliance frameworks known for Alibaba Cloud.</p> <code>inventory_regions</code> <p>List all available Alibaba Cloud regions.</p> <code>inventory_zones</code> <p>List all availability zones.</p> <code>inventory_servers</code> <p>List all server types at Alibaba Cloud using the <code>DescribeInstanceTypes</code> API endpoint.</p> <code>inventory_server_prices</code> <p>Fetch server pricing and regional availability using the <code>QuerySkuPriceListRequest</code> API endpoint.</p> <code>inventory_server_prices_spot</code> <p>Fetch spot instance pricing by time-based sampling of on-demand instances per region.</p> <code>inventory_storages</code> <p>List all block storage offerings.</p> <code>inventory_storage_prices</code> <p>Fetch server prices using the <code>QuerySkuPriceListRequest</code> API endpoint.</p> <code>inventory_traffic_prices</code> <p>Collect inbound and outbound traffic prices of Alibaba Cloud regions.</p> <code>inventory_ipv4_prices</code> <p>Static IPv4 pricing of Alibaba Cloud regions.</p>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of compliance frameworks known for Alibaba Cloud.</p> <p>Resources: https://www.alibabacloud.com/en/trust-center/compliance</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of compliance frameworks known for Alibaba Cloud.\n\n    Resources: &lt;https://www.alibabacloud.com/en/trust-center/compliance&gt;\n    \"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id, [\"hipaa\", \"soc2t2\", \"iso27001\"]\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all available Alibaba Cloud regions.</p> <p>Data sources:</p> <ul> <li>https://api.alibabacloud.com/document/Ecs/2014-05-26/DescribeRegions</li> <li>Foundation year collected from https://www.alibabacloud.com/en/global-locations?_p_lc=1</li> <li>Aliases (old region names) collected from https://help.aliyun.com/zh/user-center/product-overview/regional-name-change-announcement</li> </ul> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"\n    List all available Alibaba Cloud regions.\n\n    Data sources:\n\n    - &lt;https://api.alibabacloud.com/document/Ecs/2014-05-26/DescribeRegions&gt;\n    - Foundation year collected from &lt;https://www.alibabacloud.com/en/global-locations?_p_lc=1&gt;\n    - Aliases (old region names) collected from &lt;https://help.aliyun.com/zh/user-center/product-overview/regional-name-change-announcement&gt;\n    \"\"\"\n    request = DescribeRegionsRequest(accept_language=\"en-US\")\n    response = _ecs_client().describe_regions(request)\n    regions = [region.to_map() for region in response.body.regions.region]\n\n    items = []\n    for region in regions:\n        location = locations[region.get(\"RegionId\")]\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.get(\"RegionId\"),\n                \"name\": region.get(\"LocalName\"),\n                \"api_reference\": region.get(\"RegionId\"),\n                \"display_name\": f\"{location['city']} ({location['country_id']})\",\n                \"aliases\": location.get(\"alias\", []),\n                \"country_id\": location.get(\"country_id\"),\n                \"state\": None,  # not available\n                \"city\": location.get(\"city\"),\n                \"address_line\": None,  # not available\n                \"zip_code\": None,  # not available\n                \"lon\": location.get(\"lon\"),\n                \"lat\": location.get(\"lat\"),\n                \"founding_year\": location.get(\"founding_year\"),\n                # \"Clean electricity accounted for 56.0% of the total electricity consumption at Alibaba Cloud's self-built data centers\"\n                # https://www.alibabagroup.com/en-US/esg?spm=a3c0i.28208492.4078276800.1.3ee123b78lagGT\n                \"green_energy\": None,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all availability zones.</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all availability zones.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Scanning region(s) for zone(s)\", total=len(vendor.regions)\n    )\n    clients = _ecs_clients(vendor)\n\n    @cachier(hash_func=jsoned_hash, separate_files=True)\n    def fetch_zones_for_region(region_id):\n        \"\"\"Worker function to fetch zones for a single region.\"\"\"\n        request = DescribeZonesRequest(region_id=region_id, accept_language=\"en-US\")\n        try:\n            response = clients[region_id].describe_zones(request)\n            zone_items = []\n            for zone in response.body.to_map()[\"Zones\"][\"Zone\"]:\n                zone_items.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region_id,\n                        \"zone_id\": zone.get(\"ZoneId\"),\n                        \"name\": zone.get(\"LocalName\"),\n                        \"api_reference\": zone.get(\"ZoneId\"),\n                        \"display_name\": zone.get(\"LocalName\"),\n                    }\n                )\n            return zone_items\n        except Exception as e:\n            logger.error(f\"Failed to get zones for region {region_id}: {e}\")\n            return []\n        finally:\n            vendor.progress_tracker.advance_task()\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        items = executor.map(\n            fetch_zones_for_region, [r.region_id for r in vendor.regions]\n        )\n    items = list(chain.from_iterable(items))\n    vendor.progress_tracker.hide_task()\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all server types at Alibaba Cloud using the <code>DescribeInstanceTypes</code> API endpoint.</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all server types at Alibaba Cloud using the `DescribeInstanceTypes` API endpoint.\"\"\"\n    client = _ecs_client()\n    request = DescribeInstanceTypesRequest(max_results=1000)\n    response = client.describe_instance_types(request)\n    instance_types = [\n        instance_type.to_map()\n        for instance_type in response.body.instance_types.instance_type\n    ]\n    while response.body.next_token:\n        request = DescribeInstanceTypesRequest(\n            max_results=1000, next_token=response.body.next_token\n        )\n        response = client.describe_instance_types(request)\n        for instance_type in response.body.instance_types.instance_type:\n            instance_types.append(instance_type.to_map())\n\n    region_availability_info: dict[str, list[dict]] = _get_region_availability_info(\n        vendor\n    )\n\n    CPU_ARCH_MAP = {\"X86\": CpuArchitecture.X86_64, \"ARM\": CpuArchitecture.ARM64}\n    STORAGE_CATEGORY_MAP = {\n        \"\": None,\n        \"local_ssd_pro\": StorageType.SSD,\n        \"local_hdd_pro\": StorageType.HDD,\n    }\n\n    def drop_zero_value(x):\n        return None if x == 0 else x\n\n    items = []\n    for instance_type in instance_types:\n        family = instance_type.get(\"InstanceTypeFamily\")\n        vcpus = instance_type.get(\"CpuCoreCount\")\n        cpu_model = instance_type.get(\"PhysicalProcessorModel\")\n        memory_size_mb = int((instance_type.get(\"MemorySize\") * 1024))\n        memory_size_gb = (\n            memory_size_mb // 1024\n            if memory_size_mb &gt;= 1024\n            else round(memory_size_mb / 1024, 2)\n        )\n        storage_size = int(\n            instance_type.get(\"LocalStorageAmount\", 0)\n            * instance_type.get(\"LocalStorageCapacity\", 0)\n            # convert GiB to GB\n            * 1024**3\n            / 1000**3\n        )\n        storage_type = STORAGE_CATEGORY_MAP[instance_type[\"LocalStorageCategory\"]]\n        gpu_count = _standardize_gpu_count(\n            instance_type[\"GPUSpec\"], instance_type.get(\"GPUAmount\", 0)\n        )\n        gpu_memory_per_gpu = instance_type.get(\"GPUMemorySize\", 0) * 1024  # GiB -&gt; MiB\n        # GPUMemorySize contains total memory for fractional or single GPUs, but per-GPU memory for multiple GPUs\n        gpu_memory_total = (\n            gpu_count * gpu_memory_per_gpu if gpu_count &gt;= 1 else gpu_memory_per_gpu\n        )\n        gpu_model = _standardize_gpu_model(instance_type[\"GPUSpec\"])\n        description_parts = [\n            f\"{vcpus} vCPUs\",\n            f\"{memory_size_gb} GiB RAM\",\n            f\"{storage_size} GB {storage_type.value if storage_type else ''} storage\",\n            (\n                f\"{gpu_count}x{gpu_model} {gpu_memory_per_gpu} GiB VRAM\"\n                if gpu_count and gpu_model\n                else None\n            ),\n        ]\n        description = f\"{family} family ({', '.join(filter(None, description_parts))})\"\n        server_id = instance_type.get(\"InstanceTypeId\")\n        status = (\n            Status.ACTIVE\n            if any(\n                _is_resource_available(\n                    region_availability_info,\n                    region_id,\n                    zone_info.get(\"ZoneId\"),\n                    server_id,\n                )\n                for region_id, zones in region_availability_info.items()\n                for zone_info in zones\n            )\n            else Status.INACTIVE\n        )\n\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"server_id\": server_id,\n                \"name\": server_id,\n                \"api_reference\": server_id,\n                \"display_name\": server_id,\n                \"description\": description,\n                \"family\": family,\n                \"vcpus\": vcpus,\n                \"hypervisor\": \"KVM\",\n                \"cpu_allocation\": _determine_cpu_allocation_type(instance_type),\n                \"cpu_cores\": instance_type.get(\"CpuCoreCount\", 0),\n                \"cpu_speed\": drop_zero_value(instance_type.get(\"CpuSpeedFrequency\")),\n                \"cpu_architecture\": CPU_ARCH_MAP[instance_type.get(\"CpuArchitecture\")],\n                \"cpu_manufacturer\": _extract_manufacturer(cpu_model),\n                \"cpu_family\": _extract_family(cpu_model),\n                \"cpu_model\": _standardize_cpu_model(cpu_model),\n                \"cpu_l1_cache\": None,\n                \"cpu_l2_cache\": None,\n                \"cpu_l3_cache\": None,\n                \"cpu_flags\": [],\n                \"cpus\": [],\n                \"memory_amount\": memory_size_mb,\n                \"memory_generation\": None,\n                \"memory_speed\": None,\n                \"memory_ecc\": None,\n                \"gpu_count\": gpu_count,\n                \"gpu_memory_min\": drop_zero_value(int(gpu_memory_per_gpu)),\n                \"gpu_memory_total\": drop_zero_value(int(gpu_memory_total)),\n                # TODO fill in from GPUSpec? or just let the inspector fill it in?\n                \"gpu_manufacturer\": None,\n                \"gpu_family\": None,\n                \"gpu_model\": gpu_model,\n                \"gpus\": [],\n                \"storage_size\": storage_size,\n                \"storage_type\": storage_type,\n                \"storages\": [],\n                \"network_speed\": drop_zero_value(\n                    instance_type.get(\"InstanceBandwidthRx\", 0) / 1024 / 1000\n                ),\n                \"inbound_traffic\": 0,\n                \"outbound_traffic\": 0,\n                \"ipv4\": 0,\n                \"status\": status,\n            }\n        )\n\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>Fetch server pricing and regional availability using the <code>QuerySkuPriceListRequest</code> API endpoint.</p> <p>Alternative approach could be looking at https://g.alicdn.com/aliyun/ecs-price-info-intl/2.0.375/price/download/instancePrice.json.</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_server_prices(vendor):\n    \"\"\"Fetch server pricing and regional availability using the `QuerySkuPriceListRequest` API endpoint.\n\n    Alternative approach could be looking at &lt;https://g.alicdn.com/aliyun/ecs-price-info-intl/2.0.375/price/download/instancePrice.json&gt;.\n    \"\"\"\n    skus = _get_sku_prices(\n        sku_type=\"server\",\n        extra_request_params={\n            \"price_entity_code\": \"instance_type\",\n            # filter for Linux prices only for now\n            \"price_factor_condition_map\": {\"vm_os_kind\": [\"linux\"]},\n        },\n        vendor=vendor,\n    )\n\n    items = []\n    unsupported_regions = set()\n    region_availability_info: dict[str, list[dict]] = _get_region_availability_info(\n        vendor\n    )\n\n    for sku in skus:\n        sku_region_id = sku[\"SkuFactorMap\"][\"vm_region_no\"]\n        region = get_region_by_id(sku_region_id, vendor)\n        if not region:\n            unsupported_regions.add(sku_region_id)\n            continue\n        for zone in region.zones:\n            server_id = sku.get(\"SkuFactorMap\", {}).get(\"instance_type\")\n            status = (\n                Status.ACTIVE\n                if _is_resource_available(\n                    region_availability_info, region.region_id, zone.zone_id, server_id\n                )\n                else Status.INACTIVE\n            )\n\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"zone_id\": zone.zone_id,\n                    \"server_id\": server_id,\n                    \"operating_system\": sku.get(\"SkuFactorMap\").get(\"vm_os_kind\"),\n                    \"allocation\": Allocation.ONDEMAND,\n                    \"unit\": PriceUnit.HOUR,\n                    \"price\": float(sku.get(\"CskuPriceList\")[0].get(\"Price\")),\n                    \"price_upfront\": 0,\n                    \"price_tiered\": [],\n                    \"currency\": sku.get(\"CskuPriceList\")[0].get(\"Currency\"),\n                    \"status\": status,\n                }\n            )\n    for unsupported_region in unsupported_regions:\n        vendor.log(f\"Found non-supported region: {unsupported_region}\", level=WARN)\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>Fetch spot instance pricing by time-based sampling of on-demand instances per region.</p> <p>Each region worker fetches spot prices for a random sample of instances within sample_time, adapting to different response times, parallelized across regions.</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"Fetch spot instance pricing by time-based sampling of on-demand instances per region.\n\n    Each region worker fetches spot prices for a random sample of instances within sample_time,\n    adapting to different response times, parallelized across regions.\n    \"\"\"\n    sample_time = 120  # seconds\n\n    ecs_clients: dict[str, EcsClient] = _ecs_clients(vendor)\n\n    ondemand_instances = defaultdict(list)\n    for server_price in vendor.server_prices:\n        if (\n            server_price.allocation == Allocation.ONDEMAND\n            and server_price.status == Status.ACTIVE\n        ):\n            ondemand_instances[server_price.region_id].append(\n                (server_price.zone_id, server_price.server_id)\n            )\n\n    if not ondemand_instances:\n        logger.error(\"No active ondemand instances found\")\n        return []\n\n    for region_id in ondemand_instances:\n        shuffle(ondemand_instances[region_id])\n\n    def fetch_spot_instance_price(\n        region_id: str, zone_instance_list: list[tuple[str, str]], client: EcsClient\n    ):\n        spot_instances = []\n        start_time = time()\n\n        for zone_id, instance_type in zone_instance_list:\n            try:\n                # Check if time limit exceeded\n                elapsed = time() - start_time\n                if elapsed &gt;= sample_time:\n                    break\n\n                price_response_body: DescribePriceResponseBody = _get_instance_price(\n                    region_id=region_id,\n                    zone_id=zone_id,\n                    instance_type=instance_type,\n                    client=client,\n                    spot_strategy=\"SpotAsPriceGo\",\n                )\n\n                if not price_response_body:\n                    continue\n\n                if not next(\n                    (\n                        r\n                        for r in price_response_body.price_info.rules.rule\n                        if r.description == \"Preemptible Instance discount\"\n                    ),\n                    None,\n                ):\n                    continue\n\n                trade_price = next(\n                    (\n                        p.trade_price\n                        for p in price_response_body.price_info.price.detail_infos.detail_info\n                        if p.resource == \"instanceType\"\n                    ),\n                    None,\n                )\n\n                if not trade_price:\n                    continue\n\n                spot_instances.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region_id,\n                        \"zone_id\": zone_id,\n                        \"server_id\": instance_type,\n                        \"operating_system\": \"linux\",\n                        \"allocation\": Allocation.SPOT,\n                        \"unit\": PriceUnit.HOUR,\n                        \"price\": float(trade_price),\n                        \"price_upfront\": 0,\n                        \"price_tiered\": [],\n                        \"currency\": price_response_body.price_info.price.currency,\n                        \"status\": Status.ACTIVE,\n                    }\n                )\n            except AttributeError:\n                continue\n            except Exception as e:\n                logger.error(\n                    f\"Failed to get spot price for {instance_type} in {region_id}/{zone_id}: {e}\"\n                )\n                continue\n            finally:\n                vendor.progress_tracker.advance_task()\n\n        if not spot_instances:\n            logger.info(f\"No spot prices found in region {region_id}\")\n\n        return spot_instances\n\n    vendor.progress_tracker.start_task(\n        name=f\"Fetching spot instance prices for {sample_time} second(s)\",\n        total=sum(len(zil) for zil in ondemand_instances.values()),\n    )\n\n    with ThreadPoolExecutor(max_workers=len(ondemand_instances)) as executor:\n        items = executor.map(\n            lambda args: fetch_spot_instance_price(*args),\n            [\n                (region_id, zone_instance_list, ecs_clients[region_id])\n                for region_id, zone_instance_list in ondemand_instances.items()\n            ],\n        )\n    items = list(chain.from_iterable(items))\n\n    vendor.progress_tracker.hide_task()\n\n    vendor.set_table_rows_active(\n        ServerPrice,\n        ServerPrice.allocation == Allocation.SPOT,\n        ServerPrice.observed_at &gt;= datetime.now() - timedelta(days=30),\n    )\n\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all block storage offerings.</p> <p>Data sources:</p> <ul> <li>https://www.alibabacloud.com/help/en/ecs/user-guide/essds</li> <li>https://www.alibabacloud.com/help/en/ecs/developer-reference/api-ecs-2014-05-26-createdisk</li> </ul> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"List all block storage offerings.\n\n    Data sources:\n\n    - &lt;https://www.alibabacloud.com/help/en/ecs/user-guide/essds&gt;\n    - &lt;https://www.alibabacloud.com/help/en/ecs/developer-reference/api-ecs-2014-05-26-createdisk&gt;\n    \"\"\"\n    disk_info = [\n        # NOTE there's only a single `cloud_essd` ID at Alibaba Cloud,\n        # but we suffix with the performance level (PL0, PL1, PL2, PL3)\n        # to differentiate them as these are products with very different characteristics\n        {\n            \"name\": \"cloud_essd-pl0\",\n            \"min_size\": 1,\n            \"max_size\": 65536,\n            \"max_iops\": 10000,\n            \"max_tp\": 1440,\n            \"info\": \"Enterprise SSD with performance level 0.\",\n        },\n        {\n            \"name\": \"cloud_essd-pl1\",\n            \"min_size\": 20,\n            \"max_size\": 65536,\n            \"max_iops\": 50000,\n            \"max_tp\": 2800,\n            \"info\": \"Enterprise SSD with performance level 1.\",\n        },\n        {\n            \"name\": \"cloud_essd-pl2\",\n            \"min_size\": 461,\n            \"max_size\": 65536,\n            \"max_iops\": 100000,\n            \"max_tp\": 6000,\n            \"info\": \"Enterprise SSD with performance level 2.\",\n        },\n        {\n            \"name\": \"cloud_essd-pl3\",\n            \"min_size\": 1261,\n            \"max_size\": 65536,\n            \"max_iops\": 1000000,\n            \"max_tp\": 32000,\n            \"info\": \"Enterprise SSD with performance level 3.\",\n        },\n        {\n            \"name\": \"cloud_ssd\",\n            \"min_size\": 20,\n            \"max_size\": 32768,\n            \"max_iops\": 20000,\n            \"max_tp\": 256,\n            \"info\": \"Standard SSD.\",\n        },\n        {\n            \"name\": \"cloud_efficiency\",\n            \"min_size\": 20,\n            \"max_size\": 32768,\n            \"max_iops\": 3000,\n            \"max_tp\": 80,\n            \"info\": \"Ultra Disk, older generation.\",\n        },\n        {\n            \"name\": \"cloud\",\n            \"min_size\": 5,\n            \"max_size\": 2000,\n            \"max_iops\": 300,\n            \"max_tp\": 40,\n            \"info\": \"Lowest cost HDD.\",\n        },\n    ]\n\n    items = []\n    for disk in disk_info:\n        items.append(\n            {\n                \"storage_id\": disk.get(\"name\"),\n                \"vendor_id\": vendor.vendor_id,\n                \"name\": disk.get(\"name\"),\n                \"description\": disk.get(\"info\"),\n                \"storage_type\": (\n                    StorageType.HDD if disk.get(\"name\") == \"cloud\" else StorageType.SSD\n                ),\n                \"max_iops\": disk.get(\"max_iops\"),\n                \"max_throughput\": disk.get(\"max_tp\"),\n                \"min_size\": disk.get(\"min_size\"),\n                \"max_size\": disk.get(\"max_size\"),\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>Fetch server prices using the <code>QuerySkuPriceListRequest</code> API endpoint.</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"Fetch server prices using the `QuerySkuPriceListRequest` API endpoint.\"\"\"\n    skus = _get_sku_prices(\n        sku_type=\"storage\",\n        extra_request_params={\"price_entity_code\": \"datadisk\"},\n        vendor=vendor,\n    )\n\n    items = []\n    unsupported_regions = set()\n    for sku in skus:\n        storage_id = sku[\"SkuFactorMap\"][\"datadisk_category\"]\n        pl = sku[\"SkuFactorMap\"][\"datadisk_performance_level\"]\n        if storage_id in [\"cloud\", \"cloud_ssd\", \"cloud_efficiency\"]:\n            # no diff in performance levels, pick one\n            if pl != \"PL1\":\n                continue\n        else:\n            # keep the 4 performance levels\n            if pl not in [\"PL0\", \"PL1\", \"PL2\", \"PL3\"]:\n                continue\n            storage_id = storage_id + \"-\" + pl.lower()\n        region_id = sku[\"SkuFactorMap\"][\"vm_region_no\"]\n        region = get_region_by_id(region_id, vendor)\n        if not region:\n            unsupported_regions.add(region_id)\n            continue\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"storage_id\": storage_id,\n                \"unit\": PriceUnit.GB_MONTH,\n                \"price\": float(sku[\"CskuPriceList\"][0][\"Price\"]),\n                \"currency\": sku[\"CskuPriceList\"][0][\"Currency\"],\n            }\n        )\n    for unsupported_region in unsupported_regions:\n        vendor.log(f\"Found non-supported region: {unsupported_region}\", level=WARN)\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>Collect inbound and outbound traffic prices of Alibaba Cloud regions.</p> <p>Inbound is free as per https://www.alibabacloud.com/help/en/ecs/public-bandwidth. Outbound traffic pricing collected from the <code>QuerySkuPriceListRequest</code> API endpoint.</p> <p>Account level tiering information can be found at https://www.alibabacloud.com/help/en/cdt/internet-data-transfers/#4a98c9ee8eemn.</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"Collect inbound and outbound traffic prices of Alibaba Cloud regions.\n\n    Inbound is free as per &lt;https://www.alibabacloud.com/help/en/ecs/public-bandwidth&gt;.\n    Outbound traffic pricing collected from the `QuerySkuPriceListRequest` API endpoint.\n\n    Account level tiering information can be found at &lt;https://www.alibabacloud.com/help/en/cdt/internet-data-transfers/#4a98c9ee8eemn&gt;.\n    \"\"\"\n    items = []\n    skus = _get_sku_prices(\n        sku_type=\"traffic\",\n        extra_request_params={\"price_entity_code\": \"vm_flow_out\"},\n        # vendor=vendor,\n    )\n    unsupported_regions = set()\n    for sku in skus:\n        region_id = sku[\"SkuFactorMap\"][\"vm_region_no\"]\n        region = get_region_by_id(region_id, vendor)\n        if not region:\n            unsupported_regions.add(region_id)\n            continue\n        price = next(p for p in sku[\"CskuPriceList\"] if float(p[\"Price\"]) &gt; 0)\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": float(price[\"Price\"]),\n                \"price_tiered\": [],\n                \"currency\": price[\"Currency\"],\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.OUT,\n            }\n        )\n        # incoming traffic is free\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0,\n                \"price_tiered\": [],\n                \"currency\": price[\"Currency\"],\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.IN,\n            }\n        )\n    for unsupported_region in unsupported_regions:\n        vendor.log(f\"Found non-supported region: {unsupported_region}\", level=WARN)\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_alicloud/#sc_crawler.vendors._alicloud.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>Static IPv4 pricing of Alibaba Cloud regions.</p> <p>Static (not Elastic) IP addresses are free, you only pay for bandwidth or traffic as per https://www.alibabacloud.com/help/en/ecs/user-guide/public-ip-address?spm=a2c63.p38356.0.i1#52c0fa8bbcee6.</p> Source code in <code>sc_crawler/vendors/_alicloud.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"Static IPv4 pricing of Alibaba Cloud regions.\n\n    Static (not Elastic) IP addresses are free, you only pay for bandwidth or traffic\n    as per &lt;https://www.alibabacloud.com/help/en/ecs/user-guide/public-ip-address?spm=a2c63.p38356.0.i1#52c0fa8bbcee6&gt;.\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0,\n                \"currency\": \"USD\",\n                \"unit\": PriceUnit.MONTH,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/","title":"_aws","text":""},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws","title":"sc_crawler.vendors._aws","text":"<p>Functions:</p> Name Description <code>inventory_compliance_frameworks</code> <p>Manual list of compliance frameworks known for AWS.</p> <code>inventory_regions</code> <p>List all available AWS regions via <code>boto3</code> calls.</p> <code>inventory_zones</code> <p>List all available AWS availability zones via <code>boto3</code> calls.</p> <code>inventory_servers</code> <p>List all available AWS instance types in all regions via <code>boto3</code> calls.</p> <code>inventory_server_prices</code> <p>List all on-demand instance prices in all regions via <code>boto3</code> calls.</p> <code>inventory_server_prices_spot</code> <p>List all spot instance prices in all availability zones via <code>boto3</code> calls.</p> <code>inventory_storages</code> <p>List all storage types via <code>boto3</code> calls.</p> <code>inventory_storage_prices</code> <p>List all storage prices in all regions via <code>boto3</code> calls.</p> <code>inventory_traffic_prices</code> <p>List all inbound and outbound traffic prices in all regions via <code>boto3</code> calls.</p> <code>inventory_ipv4_prices</code> <p>List IPV4 prices in all regions via <code>boto3</code> calls.</p>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of compliance frameworks known for AWS.</p> <p>Resources: https://aws.amazon.com/compliance/programs/</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of compliance frameworks known for AWS.\n\n    Resources: &lt;https://aws.amazon.com/compliance/programs/&gt;\n    \"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id, [\"hipaa\", \"soc2t2\", \"iso27001\"]\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all available AWS regions via <code>boto3</code> calls.</p> <p>Some data sources are not available from APIs, and were collected manually:</p> <ul> <li>launch date: https://aws.amazon.com/about-aws/global-infrastructure/regions_az/,</li> <li>energy source: https://sustainability.aboutamazon.com/products-services/the-cloud?energyType=true#renewable-energy and https://www.aboutamazon.com/news/sustainability/amazon-renewable-energy-goal,</li> <li>lon/lat coordinates: https://gist.github.com/martinheidegger/88950cb51ee5bdeafd51bc55287b1092 and approximation based on the city when no more accurate data was available.</li> </ul> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all available AWS regions via `boto3` calls.\n\n    Some data sources are not available from APIs, and were collected manually:\n\n    - launch date: &lt;https://aws.amazon.com/about-aws/global-infrastructure/regions_az/&gt;,\n    - energy source: &lt;https://sustainability.aboutamazon.com/products-services/the-cloud?energyType=true#renewable-energy&gt; and &lt;https://www.aboutamazon.com/news/sustainability/amazon-renewable-energy-goal&gt;,\n    - lon/lat coordinates: &lt;https://gist.github.com/martinheidegger/88950cb51ee5bdeafd51bc55287b1092&gt; and approximation based on the city when no more accurate data was available.\n    \"\"\"  # noqa: E501\n    regions = [\n        {\n            \"region_id\": \"af-south-1\",\n            \"name\": \"Africa (Cape Town)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"ZA\",\n            \"city\": \"Cape Town\",\n            \"founding_year\": 2020,\n            \"lat\": -33.914651,\n            \"lon\": 18.3758801,\n        },\n        {\n            \"region_id\": \"ap-east-1\",\n            \"name\": \"Asia Pacific (Hong Kong)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"HK\",\n            \"city\": \"Hong Kong\",\n            \"founding_year\": 2019,\n            \"lat\": 22.2908475,\n            \"lon\": 114.2723379,\n        },\n        {\n            \"region_id\": \"ap-east-2\",\n            \"name\": \"Asia Pacific (Taipei)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"TW\",\n            \"city\": \"Taipei\",\n            \"founding_year\": 2025,\n            # approximation based on city\n            \"lat\": 25.037518,\n            \"lon\": 121.563667,\n        },\n        {\n            \"region_id\": \"ap-northeast-1\",\n            \"name\": \"Asia Pacific (Tokyo)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"JP\",\n            \"city\": \"Tokyo\",\n            \"founding_year\": 2011,\n            \"lat\": 35.617436,\n            \"lon\": 139.7459176,\n        },\n        {\n            \"region_id\": \"ap-northeast-2\",\n            \"name\": \"Asia Pacific (Seoul)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"KR\",\n            \"city\": \"Seoul\",\n            \"founding_year\": 2016,\n            \"lat\": 37.5616592,\n            \"lon\": 126.8736237,\n        },\n        {\n            \"region_id\": \"ap-northeast-3\",\n            \"name\": \"Asia Pacific (Osaka)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"JP\",\n            \"city\": \"Osaka\",\n            \"founding_year\": 2021,\n            \"lat\": 34.693889,\n            \"lon\": 135.502222,\n        },\n        {\n            \"region_id\": \"ap-south-1\",\n            \"name\": \"Asia Pacific (Mumbai)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IN\",\n            \"city\": \"Mumbai\",\n            \"founding_year\": 2016,\n            \"lat\": 19.2425503,\n            \"lon\": 72.9667878,\n        },\n        {\n            \"region_id\": \"ap-south-2\",\n            \"name\": \"Asia Pacific (Hyderabad)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IN\",\n            \"city\": \"Hyderabad\",\n            \"founding_year\": 2022,\n            # approximation based on city location\n            \"lat\": 17.412281,\n            \"lon\": 78.243237,\n        },\n        {\n            \"region_id\": \"ap-southeast-1\",\n            \"name\": \"Asia Pacific (Singapore)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"SG\",\n            \"city\": \"Singapore\",\n            \"founding_year\": 2010,\n            \"lat\": 1.3218269,\n            \"lon\": 103.6930643,\n        },\n        {\n            \"region_id\": \"ap-southeast-2\",\n            \"name\": \"Asia Pacific (Sydney)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"AU\",\n            \"city\": \"Sydney\",\n            \"founding_year\": 2012,\n            \"lat\": -33.9117717,\n            \"lon\": 151.1907535,\n        },\n        {\n            \"region_id\": \"ap-southeast-3\",\n            \"name\": \"Asia Pacific (Jakarta)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"ID\",\n            \"city\": \"Jakarta\",\n            \"founding_year\": 2021,\n            \"lat\": -6.2,\n            \"lon\": 106.816667,\n        },\n        {\n            \"region_id\": \"ap-southeast-4\",\n            \"name\": \"Asia Pacific (Melbourne)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"AU\",\n            \"city\": \"Melbourne\",\n            \"founding_year\": 2023,\n            # approximation based on city location\n            \"lat\": -37.8038607,\n            \"lon\": 144.7119569,\n        },\n        {\n            \"region_id\": \"ap-southeast-5\",\n            \"name\": \"Asia Pacific (Malaysia)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"MY\",\n            \"founding_year\": 2024,\n            # approximation based on country\n            \"lat\": 4.1230237,\n            \"lon\": 104.3228082,\n        },\n        {\n            \"region_id\": \"ap-southeast-6\",\n            \"name\": \"Asia Pacific (New Zealand)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"NZ\",\n            \"founding_year\": 2025,\n            # approximation based on country\n            \"lat\": -40.900775,\n            \"lon\": 174.802185,\n        },\n        {\n            \"region_id\": \"ap-southeast-7\",\n            \"name\": \"Asia Pacific (Thailand)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"TH\",\n            \"founding_year\": 2022,\n            # approximation based on country\n            \"lat\": 15.870032,\n            \"lon\": 100.992538,\n        },\n        {\n            \"region_id\": \"ca-central-1\",\n            \"name\": \"Canada (Central)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CA\",\n            \"city\": \"Quebec\",  # NOTE needs city name\n            \"founding_year\": 2016,\n            \"lat\": 45.5,\n            \"lon\": -73.6,\n        },\n        {\n            \"region_id\": \"ca-west-1\",\n            \"name\": \"Canada West (Calgary)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CA\",\n            \"city\": \"Calgary\",\n            \"founding_year\": 2023,\n            # approximation based on city location\n            \"lat\": 51.046574,\n            \"lon\": -114.129024,\n        },\n        {\n            \"region_id\": \"cn-north-1\",\n            \"name\": \"China (Beijing)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CN\",\n            \"city\": \"Beijing\",\n            \"founding_year\": 2016,\n            \"lat\": 39.8094478,\n            \"lon\": 116.5783234,\n        },\n        {\n            \"region_id\": \"cn-northwest-1\",\n            \"name\": \"China (Ningxia)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CN\",\n            \"city\": \"Ningxia\",  # NOTE needs city name\n            \"founding_year\": 2017,\n            \"lat\": 37.5024418,\n            \"lon\": 105.1627193,\n        },\n        {\n            \"region_id\": \"eu-central-1\",\n            \"name\": \"Europe (Frankfurt)\",\n            \"aliases\": [\"EU (Frankfurt)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"DE\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2014,\n            \"lat\": 50.0992094,\n            \"lon\": 8.6303932,\n        },\n        {\n            \"region_id\": \"eu-central-2\",\n            \"name\": \"Europe (Zurich)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CH\",\n            \"city\": \"Zurich\",\n            \"founding_year\": 2022,\n            # approximation based on city location\n            \"lat\": 47.3862924,\n            \"lon\": 8.4448814,\n        },\n        {\n            \"region_id\": \"eu-north-1\",\n            \"name\": \"Europe (Stockholm)\",\n            \"aliases\": [\"EU (Stockholm)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"SE\",\n            \"city\": \"Stockholm\",\n            \"founding_year\": 2018,\n            \"lat\": 59.326242,\n            \"lon\": 17.8419717,\n        },\n        {\n            \"region_id\": \"eu-south-1\",\n            \"name\": \"Europe (Milan)\",\n            \"aliases\": [\"EU (Milan)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IT\",\n            \"city\": \"Milan\",\n            \"founding_year\": 2020,\n            \"lat\": 45.4628328,\n            \"lon\": 9.1076927,\n        },\n        {\n            \"region_id\": \"eu-south-2\",\n            \"name\": \"Europe (Spain)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"ES\",\n            \"city\": \"Arag\u00f3n\",  # NOTE needs city name\n            \"founding_year\": 2022,\n            # approximation based on city location\n            \"lat\": 41.7943702,\n            \"lon\": -0.8516735,\n        },\n        {\n            \"region_id\": \"eu-west-1\",\n            \"name\": \"Europe (Ireland)\",\n            \"aliases\": [\"EU (Ireland)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IE\",\n            \"city\": \"Dublin\",\n            \"founding_year\": 2007,\n            \"lat\": 53.4056545,\n            \"lon\": -6.224503,\n        },\n        {\n            \"region_id\": \"eu-west-2\",\n            \"name\": \"Europe (London)\",\n            \"aliases\": [\"EU (London)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"GB\",\n            \"city\": \"London\",\n            \"founding_year\": 2016,\n            \"lat\": 51.5085036,\n            \"lon\": -0.0609266,\n        },\n        {\n            \"region_id\": \"eu-west-3\",\n            \"name\": \"Europe (Paris)\",\n            \"aliases\": [\"EU (Paris)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"FR\",\n            \"city\": \"Paris\",\n            \"founding_year\": 2017,\n            \"lat\": 48.6009709,\n            \"lon\": 2.2976644,\n        },\n        {\n            \"region_id\": \"il-central-1\",\n            \"name\": \"Israel (Tel Aviv)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IL\",\n            \"city\": \"Tel Aviv\",\n            \"founding_year\": 2023,\n            # approximation based on city location\n            \"lat\": 32.0491183,\n            \"lon\": 34.7891105,\n        },\n        {\n            \"region_id\": \"me-central-1\",\n            \"name\": \"Middle East (UAE)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"AE\",\n            # NOTE city and state unknown\n            \"display_name\": \"United Arab Emirates\",\n            \"founding_year\": 2022,\n            # approximation based on country\n            \"lat\": 25.0647937,\n            \"lon\": 55.1363688,\n        },\n        {\n            \"region_id\": \"me-south-1\",\n            \"name\": \"Middle East (Bahrain)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"BH\",\n            # NOTE city and stateunknown\n            \"display_name\": \"Bahrain\",\n            \"founding_year\": 2019,\n            \"lat\": 25.941298,\n            \"lon\": 50.3073907,\n        },\n        {\n            \"region_id\": \"mx-central-1\",\n            \"name\": \"Mexico (Central)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"MX\",\n            \"founding_year\": 2025,\n            # approximation based on country\n            \"lat\": 20.5896,\n            \"lon\": -100.3897,\n        },\n        {\n            \"region_id\": \"sa-east-1\",\n            \"name\": \"South America (Sao Paulo)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"BR\",\n            \"city\": \"Sao Paulo\",\n            \"founding_year\": 2011,\n            \"lat\": -23.4925798,\n            \"lon\": -46.8105593,\n        },\n        {\n            \"region_id\": \"us-east-1\",\n            \"name\": \"US East (N. Virginia)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"Northern Virgina\",\n            # NOTE city unknown\n            \"founding_year\": 2006,\n            \"lat\": 38.9940541,\n            \"lon\": -77.4524237,\n        },\n        {\n            \"region_id\": \"us-east-2\",\n            \"name\": \"US East (Ohio)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"Ohio\",\n            # NOTE city unknown\n            \"founding_year\": 2016,\n            \"lat\": 40.0946354,\n            \"lon\": -82.7541337,\n        },\n        {\n            \"region_id\": \"us-west-1\",\n            \"name\": \"US West (N. California)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"California\",\n            # NOTE city unknown\n            \"founding_year\": 2009,\n            \"lat\": 37.443680,\n            \"lon\": -122.153664,\n        },\n        {\n            \"region_id\": \"us-west-2\",\n            \"name\": \"US West (Oregon)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"Oregon\",\n            # NOTE city unknown\n            \"founding_year\": 2011,\n            \"lat\": 45.9174667,\n            \"lon\": -119.2684488,\n        },\n    ]\n\n    # add API reference and display names\n    for region in regions:\n        region[\"api_reference\"] = region[\"region_id\"]\n        if region.get(\"display_name\") is None:\n            display_name_prefix = region.get(\"city\", region.get(\"state\", \"\"))\n            region[\"display_name\"] = f\"{display_name_prefix} ({region['country_id']})\"\n\n    # look for undocumented (new) regions in AWS\n    supported_regions = [d[\"region_id\"] for d in regions]\n    available_regions = _boto_describe_regions()\n    for available_region in available_regions:\n        region_name = available_region[\"RegionName\"]\n        if \"gov\" in region_name:\n            next()\n        if region_name not in supported_regions:\n            raise NotImplementedError(f\"Unsupported AWS region: {region_name}\")\n\n    # mark inactive regions\n    active_regions = [region[\"RegionName\"] for region in available_regions]\n    for region in regions:\n        if region[\"region_id\"] in active_regions:\n            region[\"status\"] = \"active\"\n        else:\n            region[\"status\"] = \"inactive\"\n\n    # all regions are matched with 100% renewable energy\n    # https://www.aboutamazon.com/news/sustainability/amazon-renewable-energy-goal\n    for region in regions:\n        region[\"green_energy\"] = True\n\n    return regions\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all available AWS availability zones via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all available AWS availability zones via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Scanning region(s) for zone(s)\", total=len(vendor.regions)\n    )\n\n    def get_zones(region: Region, vendor: Vendor) -&gt; List[dict]:\n        new = []\n        if region.status == \"active\":\n            for zone in _boto_describe_availability_zones(region.region_id):\n                new.append(\n                    {\n                        \"zone_id\": zone[\"ZoneId\"],\n                        \"name\": zone[\"ZoneName\"],\n                        \"api_reference\": zone[\"ZoneName\"],\n                        \"display_name\": zone[\"ZoneName\"],\n                        \"region_id\": region.region_id,\n                        \"vendor_id\": vendor.vendor_id,\n                    }\n                )\n        vendor.progress_tracker.advance_task()\n        return new\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        zones = executor.map(get_zones, vendor.regions, repeat(vendor))\n    zones = list(chain.from_iterable(zones))\n    vendor.progress_tracker.hide_task()\n    return zones\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all available AWS instance types in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all available AWS instance types in all regions via `boto3` calls.\"\"\"\n    # TODO consider dropping this in favor of pricing.get_products, as\n    #      it has info e.g. on instanceFamily although other fields\n    #      are messier (e.g. extract memory from string)\n    servers = parallel_fetch_servers(\n        vendor, _boto_describe_instance_types, \"InstanceType\", \"regions\"\n    )\n    servers = preprocess_servers(servers, vendor, _make_server_from_instance_type)\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>List all on-demand instance prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_server_prices(vendor):\n    \"\"\"List all on-demand instance prices in all regions via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Searching for ondemand server_price(s)\", total=None\n    )\n    products = _boto_get_products(\n        service_code=\"AmazonEC2\",\n        filters={\n            # TODO ingest win, mac etc others\n            \"operatingSystem\": \"Linux\",\n            \"preInstalledSw\": \"NA\",\n            \"licenseModel\": \"No License required\",\n            \"locationType\": \"AWS Region\",\n            \"capacitystatus\": \"Used\",\n            # TODO reserved pricing options - might decide not to, as not in scope?\n            \"marketoption\": \"OnDemand\",\n            # TODO dedicated options?\n            \"tenancy\": \"Shared\",\n        },\n    )\n    vendor.progress_tracker.hide_task()\n\n    # lookup tables\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n    servers = scmodels_to_dict(vendor.servers, keys=[\"server_id\"])\n\n    # check all regions for instance types per zone\n    active_region_ids = [\n        r.api_reference for r in regions.values() if r.status == Status.ACTIVE\n    ]\n    vendor.progress_tracker.start_task(\n        name=\"Look up supported server types in all ACTIVE regions/zones\",\n        total=len(active_region_ids),\n    )\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        regions_servers = executor.map(\n            _describe_instance_type_offerings_per_zone_with_progress,\n            active_region_ids,\n            repeat(vendor),\n        )\n    regions_servers = dict(zip(active_region_ids, regions_servers))\n    vendor.progress_tracker.hide_task()\n\n    server_prices = []\n    vendor.progress_tracker.start_task(\n        name=\"Preprocess ondemand server_price(s)\", total=len(products)\n    )\n    for product in products:\n        try:\n            attributes = product[\"product\"][\"attributes\"]\n            # early drop Gov regions\n            if \"GovCloud\" in attributes[\"location\"]:\n                continue\n            server = servers[attributes[\"instanceType\"]]\n            region = regions[attributes[\"location\"]]\n            zones = regions_servers.get(region.api_reference, {}).get(\n                server.server_id, []\n            )\n            price = _extract_ondemand_price(product[\"terms\"])\n            for zone in zones:\n                server_prices.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"zone_id\": zone,\n                        \"server_id\": server.server_id,\n                        # TODO ingest other OSs\n                        \"operating_system\": \"Linux\",\n                        \"allocation\": Allocation.ONDEMAND,\n                        \"price\": float(price[0]),\n                        \"currency\": price[1],\n                        \"unit\": PriceUnit.HOUR,\n                    }\n                )\n        except KeyError as e:\n            vendor.log(\n                f\"Cannot make ondemand server_price due to unknown {str(e)}: {str(attributes)}\",\n                DEBUG,\n            )\n        finally:\n            vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return server_prices\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>List all spot instance prices in all availability zones via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"List all spot instance prices in all availability zones via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Scanning regions for spot server_price(s)\",\n        total=len(vendor.regions),\n    )\n\n    def get_spot_prices(region: Region, vendor: Vendor) -&gt; List[dict]:\n        new = []\n        if region.status == \"active\":\n            try:\n                new = _describe_spot_price_history(region.region_id)\n                vendor.log(\n                    f\"{len(new)} spot server_price(s) found in {region.region_id}.\"\n                )\n            except ClientError as e:\n                vendor.log(\n                    f\"Cannot get spot server_price in {region.region_id}: {str(e)}\"\n                )\n        vendor.progress_tracker.advance_task()\n        return new\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        products = executor.map(get_spot_prices, vendor.regions, repeat(vendor))\n    products = list(chain.from_iterable(products))\n    vendor.log(f\"{len(products)} spot server_price(s) found.\")\n    vendor.progress_tracker.hide_task()\n\n    # lookup tables\n    zones = scmodels_to_dict(vendor.zones, keys=[\"name\"])\n    servers = scmodels_to_dict(vendor.servers, keys=[\"server_id\"])\n\n    server_prices = []\n    vendor.progress_tracker.start_task(\n        name=\"Preprocess spot server_price(s)\", total=len(products)\n    )\n    for product in products:\n        try:\n            zone = zones[product[\"AvailabilityZone\"]]\n            server = servers[product[\"InstanceType\"]]\n        except KeyError as e:\n            vendor.log(\n                f\"Cannot make ondemand server_price due to unknown {str(e)}: {str(product)}\",\n                DEBUG,\n            )\n            continue\n        server_prices.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": zone.region.region_id,\n                \"zone_id\": zone.zone_id,\n                \"server_id\": server.server_id,\n                # TODO ingest other OSs\n                \"operating_system\": \"Linux\",\n                \"allocation\": Allocation.SPOT,\n                \"price\": float(product[\"SpotPrice\"]),\n                \"currency\": \"USD\",\n                \"unit\": PriceUnit.HOUR,\n                # use reported time instead of current timestamp\n                \"observed_at\": product[\"Timestamp\"],\n            }\n        )\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return server_prices\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all storage types via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"List all storage types via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Searching for storages\", total=len(storage_manual_data)\n    )\n\n    # look up all volume types in us-east-1\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        products = executor.map(\n            _search_storage,\n            storage_types,\n            repeat(vendor),\n            repeat(\"US East (N. Virginia)\"),\n        )\n    products = list(chain.from_iterable(products))\n    vendor.progress_tracker.hide_task()\n\n    storages = []\n    for product in products:\n        attributes = product[\"product\"][\"attributes\"]\n        product_id = attributes[\"volumeApiName\"]\n\n        def get_attr(key: str) -&gt; float:\n            return extract_last_number(\n                str(\n                    attributes.get(\n                        key,\n                        storage_manual_data[product_id][key],\n                    )\n                )\n            )\n\n        storage_type = (\n            StorageType.HDD if \"HDD\" in attributes[\"storageMedia\"] else StorageType.SSD\n        )\n        storages.append(\n            {\n                \"storage_id\": product_id,\n                \"vendor_id\": vendor.vendor_id,\n                \"name\": attributes[\"volumeType\"],\n                \"description\": attributes[\"storageMedia\"],\n                \"storage_type\": storage_type,\n                \"max_iops\": get_attr(\"maxIopsvolume\"),\n                \"max_throughput\": get_attr(\"maxThroughputvolume\"),\n                \"min_size\": get_attr(\"minVolumeSize\") * 1024,\n                \"max_size\": get_attr(\"maxVolumeSize\") * 1024,\n            }\n        )\n\n    return storages\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>List all storage prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"List all storage prices in all regions via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Searching for storage_price(s)\", total=len(storage_manual_data)\n    )\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        products = executor.map(\n            _search_storage,\n            storage_types,\n            repeat(vendor),\n        )\n    products = list(chain.from_iterable(products))\n    vendor.progress_tracker.hide_task()\n    vendor.log(f\"Found {len(products)} storage_price(s).\")\n\n    # lookup tables\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n\n    vendor.progress_tracker.start_task(\n        name=\"Preprocessing storage_price(s)\", total=len(products)\n    )\n    prices = []\n    for product in products:\n        try:\n            attributes = product[\"product\"][\"attributes\"]\n            region = regions[attributes[\"location\"]]\n            price = _extract_ondemand_price(product[\"terms\"])\n            prices.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"storage_id\": attributes[\"volumeApiName\"],\n                    \"unit\": PriceUnit.GB_MONTH,\n                    \"price\": float(price[0]),\n                    \"currency\": price[1],\n                }\n            )\n        except KeyError:\n            continue\n        finally:\n            vendor.progress_tracker.advance_task()\n\n    vendor.progress_tracker.hide_task()\n    return prices\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>List all inbound and outbound traffic prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"List all inbound and outbound traffic prices in all regions via `boto3` calls.\"\"\"\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n    items = []\n    for direction in list(TrafficDirection):\n        loc_dir = \"toLocation\" if direction == TrafficDirection.IN else \"fromLocation\"\n        vendor.progress_tracker.start_task(\n            name=f\"Searching for {direction.value} traffic_price(s)\", total=None\n        )\n        products = _boto_get_products(\n            service_code=\"AWSDataTransfer\",\n            filters={\n                \"transferType\": \"AWS \" + direction.value.title(),\n            },\n        )\n        vendor.log(f\"Found {len(products)} {direction.value} traffic_price(s).\")\n        vendor.progress_tracker.update_task(\n            description=f\"Syncing {direction.value} traffic_price(s)\",\n            total=len(products),\n        )\n        for product in products:\n            try:\n                region = regions[product[\"product\"][\"attributes\"][loc_dir]]\n                prices = _extract_ondemand_prices(product[\"terms\"], fix_1024=True)\n                price = [PriceTier.model_validate(p).model_dump() for p in prices[0]]\n                items.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"price\": max([float(t[\"price\"]) for t in prices[0]]),\n                        \"price_tiered\": price,\n                        \"currency\": prices[1],\n                        \"unit\": PriceUnit.GB_MONTH,\n                        \"direction\": direction,\n                    }\n                )\n            except KeyError:\n                continue\n            finally:\n                vendor.progress_tracker.advance_task()\n        vendor.progress_tracker.hide_task()\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_aws/#sc_crawler.vendors._aws.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>List IPV4 prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/_aws.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"List IPV4 prices in all regions via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(name=\"Searching for ipv4_price(s)\", total=None)\n    products = _boto_get_products(\n        service_code=\"AmazonVPC\",\n        filters={\n            \"group\": \"VPCPublicIPv4Address\",\n            \"groupDescription\": \"Hourly charge for In-use Public IPv4 Addresses\",\n        },\n    )\n    vendor.log(f\"Found {len(products)} ipv4_price(s).\")\n    vendor.progress_tracker.update_task(\n        description=\"Syncing ipv4_price(s)\", total=len(products)\n    )\n    # lookup tables\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n    items = []\n    for product in products:\n        try:\n            region = regions[product[\"product\"][\"attributes\"][\"location\"]]\n        except KeyError as e:\n            vendor.log(\"region not found: %s\" % str(e), DEBUG)\n            continue\n        price = _extract_ondemand_price(product[\"terms\"])\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": float(price[0]),\n                \"currency\": price[1],\n                \"unit\": PriceUnit.HOUR,\n            }\n        )\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/","title":"_azure","text":""},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure","title":"sc_crawler.vendors._azure","text":"<p>Functions:</p> Name Description <code>inventory_compliance_frameworks</code> <p>Manual list of known compliance frameworks at Azure.</p> <code>inventory_regions</code> <p>List all regions via API call.</p> <code>inventory_zones</code> <p>List all availability zones.</p> <code>inventory_servers</code> <p>List all available instance types in all regions.</p> <code>inventory_server_prices</code> <p>List all known server ondemand prices in all regions using the Azure Retail Pricing API.</p> <code>inventory_server_prices_spot</code> <p>List all known server spot prices in all regions using the Azure Retail Pricing API.</p> <code>inventory_storages</code> <p>List all storage options via the Compute resource manager client.</p> <code>inventory_storage_prices</code> <p>Look up Storage prices via the Azure Retail Prices API.</p> <code>inventory_traffic_prices</code> <p>Look up Internet Egress/Ingress prices via the Azure Retail Prices API.</p> <code>inventory_ipv4_prices</code> <p>Look up Internet Egress/Ingress prices via the Azure Retail Prices API.</p> <p>Attributes:</p> Name Type Description <code>SERVER_FEATURES</code> <p>Map lowercase chars from the server name to features.</p> <code>STORAGE_METER_MAPPING</code> <p>Map Storage price meter names to the Storage name and the related disk's size.</p>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.SERVER_FEATURES","title":"SERVER_FEATURES  <code>module-attribute</code>","text":"<pre><code>SERVER_FEATURES = {'a': 'AMD processor', 'p': 'ARM processor', 'b': 'Block Storage performance', 'd': 'Local Disk', 'i': 'Isolated', 'l': 'Low Memory', 'm': 'Memory Intensive', 't': 'Tiny Memory', 's': 'Premium Storage capable', 'r': 'RDMA capable', 'e': 'Memory Optimized', 'x': 'Unmatched Memory Capacity', 'o': 'o'}\n</code></pre> <p>Map lowercase chars from the server name to features.</p>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.STORAGE_METER_MAPPING","title":"STORAGE_METER_MAPPING  <code>module-attribute</code>","text":"<pre><code>STORAGE_METER_MAPPING = {'P2 LRS Disk Mount': ('PremiumV2_LRS', 1), 'P1 LRS Disk': ('Premium_LRS', 4), 'P1 ZRS Disk': ('Premium_ZRS', 4), 'E1 LRS Disk': ('StandardSSD_LRS', 4), 'E1 ZRS Disk': ('StandardSSD_ZRS', 4), 'S4 LRS Disk': ('Standard_LRS', 32), 'Ultra LRS Provisioned Capacity': ('UltraSSD_LRS', 1)}\n</code></pre> <p>Map Storage price meter names to the Storage name and the related disk's size.</p>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of known compliance frameworks at Azure.</p> <p>Data collected from https://learn.microsoft.com/en-us/azure/compliance/.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of known compliance frameworks at Azure.\n\n    Data collected from &lt;https://learn.microsoft.com/en-us/azure/compliance/&gt;.\n    \"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id, [\"hipaa\", \"soc2t2\", \"iso27001\"]\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all regions via API call.</p> <p>Location (country and state) and founding year were collected manually from https://datacenters.microsoft.com/globe/explore/ and its underlying JSON at https://datacenters.microsoft.com/globe/data/geo/regions.json.</p> <p>City and the energy source information was collected from the sustainability fact sheets referenced in the above page and JSON.</p> <p>Coordinates were provided by the Microsoft API, which doesn't seem to be very reliable.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all regions via API call.\n\n    Location (country and state) and founding year\n    were collected manually from\n    &lt;https://datacenters.microsoft.com/globe/explore/&gt;\n    and its underlying JSON at\n    &lt;https://datacenters.microsoft.com/globe/data/geo/regions.json&gt;.\n\n    City and the energy source information was collected from\n    the sustainability fact sheets referenced in the above page and JSON.\n\n    Coordinates were provided by the Microsoft API, which doesn't seem\n    to be very reliable.\n    \"\"\"\n\n    manual_datas = {\n        # Canada\n        \"canadaeast\": {\n            \"country_id\": \"CA\",\n            \"state\": \"Quebec\",\n            \"city\": \"Quebec City\",\n            \"founding_year\": 2016,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"canadacentral\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Toronto\",\n            \"founding_year\": 2016,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # United States\n        \"centralus\": {\n            \"country_id\": \"US\",\n            \"state\": \"Iowa\",\n            \"founding_year\": 2014,\n            \"green_energy\": True,\n        },\n        \"centraluseuap\": {\n            \"country_id\": \"US\",\n            \"state\": \"Iowa\",\n            \"green_energy\": True,\n        },\n        \"eastus\": {\n            \"country_id\": \"US\",\n            \"city\": \"Boydton\",\n            \"state\": \"Virginia\",\n            # official site says 2014 with a dead link, but it was 2012 as per\n            # https://web.archive.org/web/20120530115120/http:/blogs.msdn.com/b/windowsazure/archive/2012/04/05/announcing-new-datacenter-options-for-windows-azure.aspx\n            \"founding_year\": 2012,\n            \"green_energy\": False,\n        },\n        \"eastusstg\": {\n            \"country_id\": \"US\",\n            \"state\": \"Virginia\",\n            \"green_energy\": False,\n        },\n        \"eastus2\": {\n            \"country_id\": \"US\",\n            \"city\": \"Boydton\",\n            \"state\": \"Virginia\",\n            # official site says 2012 with a dead link, but it was 2014 as per\n            # https://azure.microsoft.com/en-us/updates/general-availability-microsoft-azure-us-central-and-us-east-2-regions/\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"eastus2euap\": {\n            \"country_id\": \"US\",\n            \"state\": \"Virginia\",\n            \"green_energy\": False,\n        },\n        \"northcentralus\": {\n            \"country_id\": \"US\",\n            \"city\": \"Chicago\",\n            \"state\": \"Illinois\",\n            \"founding_year\": 2009,\n            \"green_energy\": False,\n        },\n        \"southcentralus\": {\n            \"country_id\": \"US\",\n            \"state\": \"Texas\",\n            \"city\": \"San Antonio\",\n            \"founding_year\": 2008,\n            \"green_energy\": True,\n        },\n        \"southcentralusstg\": {\n            \"country_id\": \"US\",\n            \"state\": \"Texas\",\n            \"city\": \"San Antonio\",\n        },\n        \"westcentralus\": {\n            \"country_id\": \"US\",\n            \"state\": \"Wyoming\",\n            \"city\": \"Cheyenne\",\n            \"founding_year\": 2016,\n            \"green_energy\": False,\n        },\n        \"westus\": {\n            \"country_id\": \"US\",\n            \"state\": \"California\",\n            \"founding_year\": 2012,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"westus2\": {\n            \"country_id\": \"US\",\n            \"state\": \"Washington\",\n            \"founding_year\": 2007,\n            \"green_energy\": False,\n        },\n        \"westus3\": {\n            \"country_id\": \"US\",\n            \"state\": \"Arizona\",\n            \"city\": \"Phoenix\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n        },\n        # Mexico\n        \"mexicocentral\": {\n            \"country_id\": \"ZA\",\n            \"state\": \"Quer\u00e9taro\",\n            \"founding_year\": 2024,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # South America\n        \"brazilsouth\": {\n            \"country_id\": \"BR\",\n            \"state\": \"Campinas\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"brazilsoutheast\": {\n            \"country_id\": \"US\",\n            \"city\": \"Rio de Janeiro\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"chilecentral\": {\n            \"country_id\": \"CL\",\n            \"city\": \"Santiago\",\n            # coming soon\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # not production region?\n        # https://github.com/Azure/azure-dev/issues/2165#issuecomment-1542948509\n        \"brazilus\": {\n            \"country_id\": \"BR\",\n        },\n        # Asia Pacific\n        \"australiacentral\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Canberra\",\n            \"founding_year\": 2018,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"australiacentral2\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Canberra\",\n            \"founding_year\": 2018,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"australiaeast\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Sydney\",\n            \"state\": \"New South Wales\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"australiasoutheast\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Melbourne\",\n            \"state\": \"Victoria\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"eastasia\": {\n            \"country_id\": \"HK\",\n            \"founding_year\": 2010,\n            \"green_energy\": False,\n        },\n        \"southeastasia\": {\n            \"country_id\": \"SG\",\n            \"city\": \"Singapore\",\n            \"founding_year\": 2010,\n            \"green_energy\": False,\n        },\n        \"japaneast\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Tokyo\",\n            \"founding_year\": 2014,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"japanwest\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Osaka\",\n            \"founding_year\": 2014,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"jioindiacentral\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Nagpur\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"jioindiawest\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Jamnagar\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"centralindia\": {\n            \"country_id\": \"IN\",\n            \"state\": \"Pune\",\n            \"founding_year\": 2015,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"southindia\": {\n            \"country_id\": \"IN\",\n            \"state\": \"Chennai\",\n            \"founding_year\": 2015,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"westindia\": {\n            \"country_id\": \"IN\",\n            \"state\": \"Mumbai\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"koreacentral\": {\n            \"country_id\": \"KR\",\n            \"city\": \"Seoul\",\n            \"founding_year\": 2017,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"koreasouth\": {\n            \"country_id\": \"KR\",\n            \"city\": \"Busan\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"newzealandnorth\": {\n            \"country_id\": \"NZ\",\n            \"city\": \"Auckland\",\n            \"founding_year\": 2024,\n            \"green_energy\": False,\n        },\n        \"indonesiacentral\": {\n            \"country_id\": \"ID\",\n            \"city\": \"Jakarta\",\n            # coming soon\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"malaysiawest\": {\n            \"country_id\": \"MY\",\n            \"city\": \"Kuala Lumpur\",\n            # coming soon\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # Europe\n        \"denmarkeast\": {\n            \"country_id\": \"DK\",\n            \"city\": \"Copenhagen\",\n            \"founding_year\": 2026,\n            # https://news.microsoft.com/source/emea/features/accelerating-europes-digital-future-microsoft-announces-plans-for-a-new-datacenter-region-in-west-denmark\n            \"green_energy\": True,\n        },\n        \"francecentral\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Paris\",\n            \"founding_year\": 2018,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"francesouth\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Marseille\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"germanynorth\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Berlin\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"germanywestcentral\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"italynorth\": {\n            \"country_id\": \"IT\",\n            \"city\": \"Milan\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n        },\n        \"northeurope\": {\n            \"country_id\": \"IE\",\n            \"city\": \"Dublin\",\n            \"founding_year\": 2009,\n            \"green_energy\": False,\n        },\n        \"norwayeast\": {\n            \"country_id\": \"NO\",\n            \"city\": \"Oslo\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"norwaywest\": {\n            \"country_id\": \"NO\",\n        },\n        \"polandcentral\": {\n            \"country_id\": \"PL\",\n            \"city\": \"Warsaw\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n        },\n        \"spaincentral\": {\n            \"country_id\": \"ES\",\n            \"city\": \"Madrid\",\n            \"founding_year\": 2024,\n            \"green_energy\": False,\n        },\n        \"swedencentral\": {\n            \"country_id\": \"SE\",\n            \"city\": \"G\u00e4vle and Sandviken\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n        },\n        \"switzerlandnorth\": {\n            \"country_id\": \"CH\",\n            \"city\": \"Z\u00fcrich\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"switzerlandwest\": {\n            \"country_id\": \"CH\",\n            \"city\": \"Geneva\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"uksouth\": {\n            \"country_id\": \"GB\",\n            \"city\": \"London\",\n            \"founding_year\": 2016,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"ukwest\": {\n            \"country_id\": \"GB\",\n            \"city\": \"Cardiff\",\n            \"founding_year\": 2017,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"westeurope\": {\n            \"country_id\": \"NL\",\n            \"founding_year\": 2010,\n            \"green_energy\": False,\n        },\n        \"belgiumcentral\": {\n            \"country_id\": \"BE\",\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # Middle East\n        \"israelcentral\": {\n            \"country_id\": \"IL\",\n            \"founding_year\": 2023,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"qatarcentral\": {\n            \"country_id\": \"QA\",\n            \"city\": \"Doha\",\n            \"founding_year\": 2022,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"uaecentral\": {\n            \"country_id\": \"AE\",\n            \"city\": \"Abu Dhabi\",\n        },\n        \"uaenorth\": {\n            \"country_id\": \"AE\",\n            \"city\": \"Dubai\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"austriaeast\": {\n            \"country_id\": \"AT\",\n            \"city\": \"Vienna\",\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # Africa\n        \"southafricanorth\": {\n            \"country_id\": \"ZA\",\n            \"city\": \"Johannesburg\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"southafricawest\": {\n            \"country_id\": \"ZA\",\n            \"city\": \"Cape Town\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # China TODO enable\n    }\n\n    items = []\n    for region in _regions():\n        # TODO drop this once the metadata field doesn't show up randomly anymore\n        # as the non-metadata responses do not seem to have these logical regions anymore\n        if region.get(\"metadata\", {}).get(\"region_type\", \"Physical\") != \"Physical\":\n            continue\n        # no idea what are these\n        if region[\"name\"].endswith(\"stg\"):\n            continue\n        # not production region?\n        # https://github.com/Azure/azure-dev/issues/2165#issuecomment-1542948509\n        if region[\"name\"] == \"brazilus\":\n            continue\n        # exclude for now as this new region is popping up and being removed\n        # from their API response randomly, so messing with git history\n        if region[\"name\"] == \"newzealandnorth\":\n            continue\n        manual_data = manual_datas.get(region[\"name\"])\n        if not manual_data:\n            raise KeyError(f\"No manual data found for {region['name']}.\")\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region[\"name\"],\n                \"name\": region[\"display_name\"],\n                \"api_reference\": region[\"name\"],\n                \"display_name\": (\n                    region[\"display_name\"] + \" (\" + manual_data[\"country_id\"] + \")\"\n                ),\n                \"country_id\": manual_data[\"country_id\"],\n                \"state\": manual_data.get(\"state\"),\n                \"city\": manual_data.get(\"city\"),\n                \"address_line\": None,\n                \"zip_code\": None,\n                # sometimes the API passes \"metadata\" and the lat/long nested, sometimes it's not\n                # TODO revisit after a few days passed since this change:\n                # https://github.com/Azure/azure-sdk-for-python/blob/azure-mgmt-resource_25.0.0/sdk/resources/azure-mgmt-resource/CHANGELOG.md#2500-2026-02-04\n                \"lat\": region.get(\"metadata\", {}).get(\n                    \"latitude\", region.get(\"latitude\")\n                ),\n                \"lon\": region.get(\"metadata\", {}).get(\n                    \"longitude\", region.get(\"longitude\")\n                ),\n                \"founding_year\": manual_data.get(\"founding_year\"),\n                \"green_energy\": manual_data.get(\"green_energy\"),\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all availability zones.</p> <p>API call to list existing availability zones (\"1\", \"2\", and \"3\") for each region, and creating a dummy \"0\" zone for the regions without availability zones.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all availability zones.\n\n    API call to list existing availability zones (\"1\", \"2\", and \"3\")\n    for each region, and creating a dummy \"0\" zone for the regions\n    without availability zones.\n    \"\"\"\n    items = []\n    resources = _resources(\"Microsoft.Compute\")\n    locations = [i for i in resources if i[\"resource_type\"] == \"virtualMachines\"][0]\n    locations = {item[\"location\"]: item[\"zones\"] for item in locations[\"zone_mappings\"]}\n    for region in vendor.regions:\n        # default to zone with 0 ID if there are no real availability zones\n        region_zones = locations.get(region.name, [\"0\"])\n        for zone in region_zones:\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"zone_id\": zone,\n                    \"name\": zone,\n                    \"api_reference\": zone,\n                    \"display_name\": region.region_id + \"-\" + zone,\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all available instance types in all regions.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all available instance types in all regions.\"\"\"\n    servers = _servers()\n    for i in range(len(servers) - 1, -1, -1):\n        name = servers[i].get(\"name\")\n        # drop Basic servers as to be deprecated by Aug 2024\n        if name.startswith(\"Basic\"):\n            vendor.log(f\"Excluding deprecated: {name}\")\n            servers.pop(i)\n        # servers that are likely to be not available, with zero pricing\n        if name.endswith(\"Promo\"):\n            vendor.log(f\"Excluding nonsense pricing: {name}\")\n            servers.pop(i)\n        # servers probably not intended for our eyes\n        if \"Internal\" in name:\n            vendor.log(f\"Excluding internal server: {name}\")\n            servers.pop(i)\n        # servers randomly switching between active/inactive status\n        # TODO review from time to time\n        if name in [\"Standard_M896ixds_32_v3\", \"Standard_M64-32bds_1_v3\"]:\n            vendor.log(f\"Excluding server with questionable availability: {name}\")\n            servers.pop(i)\n    servers = preprocess_servers(servers, vendor, _standardize_server)\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>List all known server ondemand prices in all regions using the Azure Retail Pricing API.</p> <p>More information: https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_server_prices(vendor):\n    \"\"\"List all known server ondemand prices in all regions using the Azure Retail Pricing API.\n\n    More information: &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n    return _inventory_server_prices(vendor, Allocation.ONDEMAND)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>List all known server spot prices in all regions using the Azure Retail Pricing API.</p> <p>See details at inventory_server_prices.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"List all known server spot prices in all regions using the Azure Retail Pricing API.\n\n    See details at [inventory_server_prices][sc_crawler.vendors._azure.inventory_server_prices].\n    \"\"\"\n    return _inventory_server_prices(vendor, Allocation.SPOT)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all storage options via the Compute resource manager client.</p> <p>For more information, see https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"List all storage options via the Compute resource manager client.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types&gt;.\n    \"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of compute resources\", total=None\n    )\n\n    disks = []\n    for resource in _compute_resources():\n        if resource[\"resource_type\"] == \"disks\":\n            disks.append(resource)\n\n    disks = list({d[\"name\"]: d for d in disks}.values())\n    vendor.progress_tracker.hide_task()\n\n    items = []\n    for disk in disks:\n\n        def _search(values):\n            return list_search(disk[\"capabilities\"], \"name\", values)[\"value\"]\n\n        storage_type = (\n            StorageType.HDD\n            if \"Standard\" in disk[\"name\"] and \"SSD\" not in disk[\"name\"]\n            else StorageType.SSD\n        )\n        redundancy_type = (\n            \"Locally Redundant Storage\"\n            if \"LRS\" in disk[\"name\"]\n            else \"Zone-Redundant Storage\"\n        )\n        description = f\"{disk['tier']} tier {storage_type.name} ({redundancy_type})\"\n\n        items.append(\n            {\n                \"storage_id\": disk[\"name\"],\n                \"vendor_id\": vendor.vendor_id,\n                \"name\": disk[\"name\"],\n                \"description\": description,\n                \"storage_type\": storage_type,\n                \"max_iops\": _search([\"MaxIOpsReadWrite\", \"MaxIOps\"]),\n                \"max_throughput\": _search(\n                    [\"MaxBandwidthMBpsReadWrite\", \"MaxBandwidthMBps\"]\n                ),\n                # NOTE this is 16TB for most drives?!\n                \"min_size\": _search(\"MinSizeGiB\"),\n                \"max_size\": _search(\"MaxSizeGiB\"),\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>Look up Storage prices via the Azure Retail Prices API.</p> <p>For more information, see https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"Look up Storage prices via the Azure Retail Prices API.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of storage resources\", total=None\n    )\n    retail_prices = _prices(\"$filter=serviceName eq 'Storage'\")\n    vendor.progress_tracker.hide_task()\n\n    regions = scmodels_to_dict(vendor.regions, keys=[\"region_id\"])\n    storages = scmodels_to_dict(vendor.storages, keys=[\"storage_id\"])\n\n    items = []\n    for p in retail_prices:\n        mapping = STORAGE_METER_MAPPING.get(p[\"meterName\"])\n        if (\n            mapping\n            and mapping[0] in storages.keys()\n            and p[\"armRegionName\"] in regions.keys()\n        ):\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": p[\"armRegionName\"],\n                    \"storage_id\": mapping[0],\n                    \"unit\": PriceUnit.GB_MONTH,\n                    \"price\": p[\"retailPrice\"] / mapping[1],\n                    \"currency\": p[\"currencyCode\"],\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>Look up Internet Egress/Ingress prices via the Azure Retail Prices API.</p> <p>For more information, see https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"Look up Internet Egress/Ingress prices via the Azure Retail Prices API.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n\n    def get_tiers(prices: List[dict]) -&gt; List[dict]:\n        def prep_tiers(d: dict) -&gt; dict:\n            return {\n                \"lower\": d.get(\"tierMinimumUnits\", 0),\n                \"price\": d[\"retailPrice\"],\n            }\n\n        tiers = [prep_tiers(p) for p in prices]\n        tiers.sort(key=lambda x: x.get(\"lower\"))\n        for i in range(len(tiers)):\n            if i == len(tiers) - 1:\n                tiers[i][\"upper\"] = \"Infinity\"\n            else:\n                tiers[i][\"upper\"] = tiers[i + 1][\"lower\"]\n        return tiers\n\n    def by_region(prices: List[dict], region: str) -&gt; List[dict]:\n        return [p for p in prices if p[\"armRegionName\"] == region]\n\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of traffic prices\", total=None\n    )\n    inbound_prices = _prices(\n        \"$filter=serviceFamily eq 'Networking' and meterName eq 'Standard Data Transfer In'\"\n    )\n    outbound_prices = _prices(\n        \"$filter=serviceFamily eq 'Networking' and \"\n        \"meterName eq 'Standard Data Transfer Out' and \"\n        \"productName eq 'Bandwidth - Routing Preference: Internet'\"\n    )\n    vendor.progress_tracker.hide_task()\n\n    items = []\n    regions = scmodels_to_dict(vendor.regions, keys=[\"api_reference\"])\n    for region in regions.values():\n        for direction in [\"inbound\", \"outbound\"]:\n            prices = inbound_prices if direction == \"inbound\" else outbound_prices\n            tiers = get_tiers(by_region(prices, region.api_reference))\n            if tiers:\n                items.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"price\": max([float(t[\"price\"]) for t in tiers]),\n                        \"price_tiered\": tiers,\n                        \"currency\": prices[0].get(\"currencyCode\", \"USD\"),\n                        \"unit\": PriceUnit.GB_MONTH,\n                        \"direction\": (\n                            TrafficDirection.IN\n                            if direction == \"inbound\"\n                            else TrafficDirection.OUT\n                        ),\n                    }\n                )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_azure/#sc_crawler.vendors._azure.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>Look up Internet Egress/Ingress prices via the Azure Retail Prices API.</p> <p>For more information, see https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/_azure.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"Look up Internet Egress/Ingress prices via the Azure Retail Prices API.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of traffic prices\", total=None\n    )\n    prices = _prices(\n        \"$filter=serviceFamily eq 'Networking' and \"\n        \"meterName eq 'Basic IPv4 Dynamic Public IP' and \"\n        \"type eq 'Consumption'\"\n    )\n    vendor.progress_tracker.hide_task()\n\n    items = []\n    regions = scmodels_to_dict(vendor.regions, keys=[\"api_reference\"])\n    for region in regions.values():\n        price = list_search(prices, \"armRegionName\", region.api_reference)\n        if price:\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"price\": float(price[\"retailPrice\"]),\n                    \"currency\": price.get(\"currencyCode\", \"USD\"),\n                    \"unit\": PriceUnit.HOUR,\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/","title":"_gcp","text":""},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp","title":"sc_crawler.vendors._gcp","text":"<p>Functions:</p> Name Description <code>inventory_compliance_frameworks</code> <p>Manual list of compliance frameworks known for GCP.</p> <code>inventory_regions</code> <p>List all available GCP regions via API calls.</p> <code>inventory_zones</code> <p>List all available GCP zones via API calls.</p> <code>inventory_servers</code> <p>List all available GCP servers available in all zones.</p> <code>inventory_server_prices</code> <p>List all available GCP server ondemand prices in all regions.</p> <code>inventory_server_prices_spot</code> <p>List all available GCP server spot prices in all regions.</p> <code>inventory_storages</code> <p>List all available GCP disk storage options available in all zones.</p> <code>inventory_storage_prices</code> <p>List all available GCP disk storage prices in all regions.</p> <code>inventory_traffic_prices</code> <p>List inbound and outbound network traffic prices in all GCP regions.</p> <code>inventory_ipv4_prices</code> <p>List the price of an attached IPv4 address in all GCP regions.</p>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of compliance frameworks known for GCP.</p> <p>Resources: https://cloud.google.com/compliance?hl=en</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of compliance frameworks known for GCP.\n\n    Resources: &lt;https://cloud.google.com/compliance?hl=en&gt;\"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id, [\"hipaa\", \"soc2t2\", \"iso27001\"]\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all available GCP regions via API calls.</p> <p>Some data sources are not available from APIs, and were collected manually:</p> <ul> <li>location: https://cloud.google.com/compute/docs/regions-zones#available and https://en.wikipedia.org/wiki/Google_data_centers,</li> <li>lon/lat coordinates: https://en.wikipedia.org/wiki/Google_data_centers#Locations and approximation based on the city when no more accurate data was available.</li> <li>energy carbon data: https://cloud.google.com/sustainability/region-carbon#data and https://github.com/GoogleCloudPlatform/region-carbon-info,</li> <li>launch dates were collected from Wikipedia and GCP blog posts, such as https://medium.com/@retomeier/an-annotated-history-of-googles-cloud-platform-90b90f948920 and https://cloud.google.com/blog/products/infrastructure/introducing-new-google-cloud-regions.</li> </ul> <p>Note that many GCP regions use more than 90% green energy, but the related flag in our database is set to <code>False</code> as not being 100%.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all available GCP regions via API calls.\n\n    Some data sources are not available from APIs, and were collected manually:\n\n    - location: &lt;https://cloud.google.com/compute/docs/regions-zones#available&gt; and &lt;https://en.wikipedia.org/wiki/Google_data_centers&gt;,\n    - lon/lat coordinates: &lt;https://en.wikipedia.org/wiki/Google_data_centers#Locations&gt; and approximation based on the city when no more accurate data was available.\n    - energy carbon data: &lt;https://cloud.google.com/sustainability/region-carbon#data&gt; and &lt;https://github.com/GoogleCloudPlatform/region-carbon-info&gt;,\n    - launch dates were collected from [Wikipedia](https://en.wikipedia.org/wiki/Google_Cloud_Platform#Regions_and_zones) and GCP blog posts, such as &lt;https://medium.com/@retomeier/an-annotated-history-of-googles-cloud-platform-90b90f948920&gt; and &lt;https://cloud.google.com/blog/products/infrastructure/introducing-new-google-cloud-regions&gt;.\n\n    Note that many GCP regions use more than 90% green energy,\n    but the related flag in our database is set to `False` as not being 100%.\n    \"\"\"\n\n    manual_data = {\n        \"africa-south1\": {\n            \"country_id\": \"ZA\",\n            \"city\": \"Johannesburg\",\n            # https://cloud.google.com/blog/products/infrastructure/heita-south-africa-new-cloud-region\n            \"founding_year\": 2024,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -26.0420631,\n            \"lon\": 28.0589808,\n        },\n        \"asia-east1\": {\n            \"country_id\": \"TW\",\n            \"state\": \"Changhua County\",\n            \"founding_year\": 2013,\n            \"green_energy\": False,\n            \"lat\": 24.1385,\n            \"lon\": 120.425722,\n        },\n        \"asia-east2\": {\n            \"country_id\": \"HK\",\n            # https://cloud.google.com/blog/products/gcp/gcps-region-in-hong-kong-is-now-open\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            # approximation based on country\n            \"lat\": 22.2772377,\n            \"lon\": 114.1703066,\n            \"display_name\": \"Hong Kong\",\n        },\n        \"asia-northeast1\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Tokyo\",\n            \"state\": \"Japan\",\n            \"founding_year\": 2016,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 35.6433846,\n            \"lon\": 139.7684933,\n        },\n        \"asia-northeast2\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Osaka\",\n            \"founding_year\": 2019,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 34.6696646,\n            \"lon\": 135.4846612,\n        },\n        \"asia-northeast3\": {\n            \"country_id\": \"KR\",\n            \"city\": \"Seoul\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 37.5514982,\n            \"lon\": 126.97784,\n        },\n        \"asia-south1\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Mumbai\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 19.0709441,\n            \"lon\": 72.8726468,\n        },\n        \"asia-south2\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Delhi\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 28.6439839,\n            \"lon\": 76.9284239,\n        },\n        \"asia-southeast1\": {\n            \"country_id\": \"SG\",\n            \"city\": \"Jurong West\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            \"lat\": 1.351333,\n            \"lon\": 103.709778,\n        },\n        \"asia-southeast2\": {\n            \"country_id\": \"ID\",\n            \"city\": \"Jakarta\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -6.2297401,\n            \"lon\": 106.747117,\n        },\n        \"asia-southeast3\": {\n            \"country_id\": \"TH\",\n            \"city\": \"Bangkok\",\n            \"founding_year\": 2025,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 15.870032,\n            \"lon\": 100.992538,\n        },\n        \"australia-southeast1\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Sydney\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -33.8375583,\n            \"lon\": 150.9488095,\n        },\n        \"australia-southeast2\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Melbourne\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -37.8038607,\n            \"lon\": 144.7119569,\n        },\n        \"europe-central2\": {\n            \"country_id\": \"PL\",\n            \"city\": \"Warsaw\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 52.2328871,\n            \"lon\": 20.8966164,\n        },\n        \"europe-north1\": {\n            \"country_id\": \"FI\",\n            \"city\": \"Hamina\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            \"lat\": 60.536578,\n            \"lon\": 27.117003,\n        },\n        \"europe-north2\": {\n            \"country_id\": \"SE\",\n            \"city\": \"Stockholm\",\n            \"founding_year\": 2025,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 59.334591,\n            \"lon\": 18.06324,\n        },\n        \"europe-southwest1\": {\n            \"country_id\": \"ES\",\n            \"city\": \"Madrid\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            \"lat\": 40.519533,\n            \"lon\": -3.340937,\n        },\n        \"europe-west1\": {\n            \"country_id\": \"BE\",\n            \"city\": \"St. Ghislain\",\n            # https://medium.com/@retomeier/an-annotated-history-of-googles-cloud-platform-90b90f948920\n            \"founding_year\": 2015,\n            \"green_energy\": False,\n            \"lat\": 50.469333,\n            \"lon\": 3.865472,\n        },\n        \"europe-west10\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Berlin\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 52.5105672,\n            \"lon\": 13.3806972,\n        },\n        \"europe-west12\": {\n            \"country_id\": \"IT\",\n            \"city\": \"Turin\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            \"lat\": 45.146729,\n            \"lon\": 7.742147,\n        },\n        \"europe-west2\": {\n            \"country_id\": \"GB\",\n            \"city\": \"London\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 51.5090133,\n            \"lon\": -0.2118157,\n        },\n        \"europe-west3\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            \"lat\": 50.12263,\n            \"lon\": 8.974168,\n        },\n        \"europe-west4\": {\n            \"country_id\": \"NL\",\n            \"city\": \"Eemshaven\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            \"lat\": 52.790105,\n            \"lon\": 5.029219,\n        },\n        \"europe-west6\": {\n            \"country_id\": \"CH\",\n            \"city\": \"Zurich\",\n            \"founding_year\": 2019,\n            \"green_energy\": False,\n            \"lat\": 47.445926,\n            \"lon\": 8.210909,\n        },\n        \"europe-west8\": {\n            \"country_id\": \"IT\",\n            \"city\": \"Milan\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 45.4615551,\n            \"lon\": 9.1389572,\n        },\n        \"europe-west9\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Paris\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 48.8641797,\n            \"lon\": 2.3109137,\n        },\n        \"me-central1\": {\n            \"country_id\": \"QA\",\n            \"city\": \"Doha\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 25.272868,\n            \"lon\": 51.4717522,\n        },\n        \"me-central2\": {\n            \"country_id\": \"SA\",\n            \"city\": \"Dammam\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 26.3826288,\n            \"lon\": 49.9675732,\n        },\n        \"me-west1\": {\n            \"country_id\": \"IL\",\n            \"city\": \"Tel Aviv\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 32.0491183,\n            \"lon\": 34.7891105,\n        },\n        \"northamerica-northeast1\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Montr\u00e9al\",\n            \"founding_year\": 2018,\n            \"green_energy\": True,\n            # approximation based on city\n            \"lat\": 45.4933996,\n            \"lon\": -73.728239,\n        },\n        \"northamerica-northeast2\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Toronto\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 43.72666,\n            \"lon\": -79.5355309,\n        },\n        \"southamerica-east1\": {\n            \"country_id\": \"BR\",\n            \"city\": \"Osasco\",\n            \"state\": \"S\u00e3o Paulo\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -23.5267431,\n            \"lon\": -46.8096539,\n        },\n        \"southamerica-west1\": {\n            \"country_id\": \"CL\",\n            \"city\": \"Santiago\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            \"lat\": -33.520515,\n            \"lon\": -70.721695,\n        },\n        # NOTE this is not announced yet, but showing up in API from time to time\n        \"northamerica-south1\": {\n            # https://mexicobusiness.news/cloudanddata/news/google-cloud-announces-first-mexican-data-region-queretaro\n            \"country_id\": \"MX\",\n            \"city\": \"Queretaro\",\n            \"founding_year\": 2025,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 20.5896,\n            \"lon\": -100.3897,\n        },\n        \"us-central1\": {\n            \"country_id\": \"US\",\n            \"city\": \"Council Bluffs\",\n            \"state\": \"Iowa\",\n            \"founding_year\": 2009,\n            \"green_energy\": False,\n            \"lat\": 41.168253,\n            \"lon\": -95.796125,\n        },\n        \"us-east1\": {\n            \"country_id\": \"US\",\n            \"city\": \"Moncks Corner\",\n            \"state\": \"South Carolina\",\n            \"founding_year\": 2015,\n            \"green_energy\": False,\n            \"lat\": 33.064111,\n            \"lon\": -80.043361,\n        },\n        \"us-east4\": {\n            \"country_id\": \"US\",\n            \"city\": \"Ashburn\",\n            \"state\": \"Virginia\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            \"lat\": 38.943331,\n            \"lon\": -77.524336,\n        },\n        \"us-east5\": {\n            \"country_id\": \"US\",\n            \"city\": \"Columbus\",\n            \"state\": \"Ohio\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 39.9773124,\n            \"lon\": -83.0423282,\n        },\n        \"us-south1\": {\n            \"country_id\": \"US\",\n            \"city\": \"Dallas\",\n            \"state\": \"Texas\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            \"lat\": 32.44317,\n            \"lon\": -97.062324,\n        },\n        \"us-west1\": {\n            \"country_id\": \"US\",\n            \"city\": \"The Dalles\",\n            \"state\": \"Oregon\",\n            \"founding_year\": 2016,\n            \"green_energy\": False,\n            \"lat\": 45.632511,\n            \"lon\": -121.202267,\n        },\n        \"us-west2\": {\n            \"country_id\": \"US\",\n            \"city\": \"Los Angeles\",\n            \"state\": \"California\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 34.0549694,\n            \"lon\": -118.3753618,\n        },\n        \"us-west3\": {\n            \"country_id\": \"US\",\n            \"city\": \"Salt Lake City\",\n            \"state\": \"Utah\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 40.7386099,\n            \"lon\": -111.9609998,\n        },\n        \"us-west4\": {\n            \"country_id\": \"US\",\n            \"city\": \"Las Vegas\",\n            \"state\": \"Nevada\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            \"lat\": 36.055625,\n            \"lon\": -115.010226,\n        },\n    }\n\n    # add API reference and display names\n    for k, v in manual_data.items():\n        v[\"api_reference\"] = k\n        if v.get(\"display_name\") is None:\n            v[\"display_name\"] = v.get(\"city\", v.get(\"state\", \"\"))\n            if v.get(\"display_name\"):\n                v[\"display_name\"] = v[\"display_name\"] + \" (\" + v[\"country_id\"] + \")\"\n            else:\n                v[\"display_name\"] = v[\"country_id\"]\n\n    regions = _regions()\n    items = []\n    for region in regions:\n        if region.name not in manual_data:\n            raise KeyError(f\"Unknown region metadata for {region.name}\")\n        item = {\n            \"vendor_id\": vendor.vendor_id,\n            \"region_id\": str(region.id),\n            \"name\": region.name,\n        }\n        for k, v in manual_data[region.name].items():\n            item[k] = v\n        items.append(item)\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all available GCP zones via API calls.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all available GCP zones via API calls.\"\"\"\n    items = []\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\"])\n    for zone in _zones():\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                # example `zone.region`:\n                # https://www.googleapis.com/compute/v1/projects/algebraic-pier-412621/regions/us-east4\n                \"region_id\": regions[zone.region.split(\"/\")[-1]].region_id,\n                \"zone_id\": str(zone.id),\n                \"name\": zone.name,\n                \"api_reference\": zone.name,\n                \"display_name\": zone.name,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all available GCP servers available in all zones.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all available GCP servers available in all zones.\"\"\"\n    servers = parallel_fetch_servers(vendor, _search_servers, \"name\", \"zones\")\n    servers = preprocess_servers(servers, vendor, add_vendor_id)\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>List all available GCP server ondemand prices in all regions.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_server_prices(vendor):\n    \"\"\"List all available GCP server ondemand prices in all regions.\"\"\"\n    return _inventory_server_prices(vendor, Allocation.ONDEMAND)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>List all available GCP server spot prices in all regions.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"List all available GCP server spot prices in all regions.\"\"\"\n    return _inventory_server_prices(vendor, Allocation.SPOT)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all available GCP disk storage options available in all zones.</p> <p>For more details on the disk types, check https://cloud.google.com/compute/docs/disks#disk-types.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"List all available GCP disk storage options available in all zones.\n\n    For more details on the disk types, check &lt;https://cloud.google.com/compute/docs/disks#disk-types&gt;.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Scanning zone(s) for storage(s)\", total=len(vendor.zones)\n    )\n\n    def search_storages(zone: Zone, vendor: Vendor) -&gt; List[dict]:\n        zone_storages = []\n        for storage in _storages(zone.name):\n            valid_sizes = storage.valid_disk_size.replace(\"GB\", \"\").split(\"-\")\n            zone_storages.append(\n                {\n                    \"storage_id\": str(storage.id),\n                    \"vendor_id\": vendor.vendor_id,\n                    \"name\": storage.name,\n                    \"description\": storage.description,\n                    \"storage_type\": (\n                        StorageType.SSD\n                        if storage.name != \"pd-standard\"\n                        else StorageType.HDD\n                    ),\n                    \"max_iops\": None,\n                    \"max_throughput\": None,\n                    \"min_size\": int(valid_sizes[0]),\n                    \"max_size\": int(valid_sizes[1]),\n                }\n            )\n        vendor.log(f\"{len(zone_storages)} storage(s) found in {zone.name}.\")\n        vendor.progress_tracker.advance_task()\n        return zone_storages\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        storages = executor.map(search_storages, vendor.zones, repeat(vendor))\n    storages = list(chain.from_iterable(storages))\n\n    vendor.log(f\"{len(storages)} storage(s) found in {len(vendor.zones)} zones.\")\n    storages = list({p[\"name\"]: p for p in storages}.values())\n    vendor.log(f\"{len(storages)} unique storage(s) found.\")\n    storages = [s for s in storages if s[\"name\"] in STORAGE_ALLOWLIST]\n    vendor.log(f\"{len(storages)} storage(s) after dropping items with complex pricing.\")\n    vendor.progress_tracker.hide_task()\n    return storages\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>List all available GCP disk storage prices in all regions.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"List all available GCP disk storage prices in all regions.\"\"\"\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\"])\n    skus = _skus_dict()\n    items = []\n    for storage in vendor.storages:\n        storage_regions = skus[\"storage\"][storage.name].keys()\n        for storage_region in storage_regions:\n            # skip edge regions\n            region = regions.get(storage_region)\n            if region is None:\n                vendor.log(\n                    f\"Skip unknown '{storage_region}' region for {storage.name}\",\n                    DEBUG,\n                )\n                continue\n\n            price, currency = skus[\"storage\"][storage.name][storage_region][\"ondemand\"]\n            for zone in region.zones:\n                items.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"storage_id\": storage.storage_id,\n                        \"unit\": PriceUnit.GB_MONTH,\n                        \"price\": float(price),\n                        \"currency\": currency,\n                    }\n                )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>List inbound and outbound network traffic prices in all GCP regions.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"List inbound and outbound network traffic prices in all GCP regions.\"\"\"\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\"])\n    skus = _skus(\"Compute Engine\")\n    items = []\n    for sku in skus:\n        # skip not processed items early\n        if sku.category.resource_family != \"Network\":\n            continue\n        if sku.category.resource_group not in [\n            \"StandardInternetEgress\",\n            \"StandardInternetIngress\",\n        ]:\n            continue\n\n        # helper variables\n        traffic_regions = sku.service_regions\n        tiered_rates = sku.pricing_info[0].pricing_expression.tiered_rates\n        price_tiers = []\n        for i in range(len(tiered_rates)):\n            price_tiers.append(\n                {\n                    \"lower\": tiered_rates[i].start_usage_amount,\n                    \"upper\": \"Infinity\"\n                    if i == len(tiered_rates) - 1\n                    else tiered_rates[i + 1].start_usage_amount,\n                    \"price\": tiered_rates[i].unit_price.nanos / 1e9,\n                }\n            )\n\n        for traffic_region in traffic_regions:\n            region = regions.get(traffic_region)\n            if region is None:\n                vendor.log(\n                    f\"Skip unknown '{traffic_region}' region for {sku.description}\",\n                    DEBUG,\n                )\n                continue\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"price\": max([float(t[\"price\"]) for t in price_tiers]),\n                    \"price_tiered\": price_tiers,\n                    \"currency\": tiered_rates[0].unit_price.currency_code,\n                    \"unit\": PriceUnit.GB_MONTH,\n                    \"direction\": (\n                        TrafficDirection.OUT\n                        if sku.category.resource_group == \"StandardInternetEgress\"\n                        else TrafficDirection.IN\n                    ),\n                }\n            )\n\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_gcp/#sc_crawler.vendors._gcp.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>List the price of an attached IPv4 address in all GCP regions.</p> <p>Note that this data was not found using the APIs (only unattached static IPs), so the values are recorded manually from https://cloud.google.com/vpc/network-pricing#ipaddress.</p> Source code in <code>sc_crawler/vendors/_gcp.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"List the price of an attached IPv4 address in all GCP regions.\n\n    Note that this data was not found using the APIs (only unattached static IPs),\n    so the values are recorded manually from &lt;https://cloud.google.com/vpc/network-pricing#ipaddress&gt;.\n    \"\"\"\n    # skus = _skus(\"Compute Engine\")\n    # for sku in skus:\n    #     if sku.category.resource_family != \"Network\":\n    #         continue\n    #     if sku.description == \"Static Ip Charge\":\n    #         pass\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0.005,\n                \"currency\": \"USD\",\n                \"unit\": PriceUnit.HOUR,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/","title":"_hcloud","text":""},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud","title":"sc_crawler.vendors._hcloud","text":"<p>Functions:</p> Name Description <code>inventory_compliance_frameworks</code> <p>Manual list of known compliance frameworks at Hetzner.</p> <code>inventory_regions</code> <p>List all regions via API call.</p> <code>inventory_zones</code> <p>List all regions as availability zones.</p> <code>inventory_servers</code> <p>List all server types from API and manual data entry from the Hetzner Cloud homepage.</p> <code>inventory_server_prices_spot</code> <p>There are no spot instaces at Hetzner.</p> <code>inventory_storages</code> <p>Block storage volume information collected manually.</p> <code>inventory_storage_prices</code> <p>Block storage volume pricing information collected manually.</p> <code>inventory_traffic_prices</code> <p>Traffic price collected manually.</p> <code>inventory_ipv4_prices</code> <p>IPv4 price collected manually.</p>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of known compliance frameworks at Hetzner.</p> <p>Data collected from https://www.hetzner.com/unternehmen/zertifizierung.</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of known compliance frameworks at Hetzner.\n\n    Data collected from &lt;https://www.hetzner.com/unternehmen/zertifizierung&gt;.\"\"\"\n    return map_compliance_frameworks_to_vendor(vendor.vendor_id, [\"iso27001\"])\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all regions via API call.</p> <p>Hetzner Cloud uses integers for the region (virtual datacenter) id that we convert into string. Best to use the unique <code>name</code>, which can be also passed instead of the <code>id</code> in most <code>hcloud</code> API endpoints via the <code>id_or_name</code> method.</p> <p>Not taking the Hetzner unique <code>name</code> as id, as it's not stated to be unique for other resources, and uniqueness for servers might also change in the future.</p> <p>All regions are powered by green energy as per https://www.hetzner.com/unternehmen/umweltschutz/.</p> <p>Lon/lat coordinates were collected by searching for Hetzner locations in the Region's city.</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all regions via API call.\n\n    Hetzner Cloud uses integers for the region (virtual datacenter) id\n    that we convert into string. Best to use the unique `name`, which\n    can be also passed instead of the `id` in most `hcloud` API\n    endpoints via the `id_or_name` method.\n\n    Not taking the Hetzner unique `name` as id, as it's not\n    stated to be unique for other resources, and uniqueness\n    for servers might also change in the future.\n\n    All regions are powered by green energy as per\n    &lt;https://www.hetzner.com/unternehmen/umweltschutz/&gt;.\n\n    Lon/lat coordinates were collected by searching for Hetzner\n    locations in the Region's city.\n\n    \"\"\"\n    regions = {\n        \"2\": {  # Nuremberg\n            \"lat\": 49.4498349,\n            \"lon\": 11.0128772,\n        },\n        \"3\": {  # Helsinki\n            \"lat\": 60.3433291,\n            \"lon\": 25.02683,\n        },\n        \"4\": {  # Falkenstein\n            \"lat\": 50.4793313,\n            \"lon\": 12.3331105,\n        },\n        \"5\": {  # Ashburn, VA\n            \"lat\": 39.0176685,\n            \"lon\": -77.468102,\n        },\n        \"6\": {  # Hillsboro, OR\n            \"lat\": 45.558319,\n            \"lon\": -122.9306602,\n        },\n        \"7\": {  # Singapore\n            \"lat\": 1.290270,\n            \"lon\": 103.851959,\n        },\n    }\n\n    items = []\n    for region in _client().datacenters.get_all():\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": str(region.id),\n                \"name\": region.name,\n                \"api_reference\": region.name,\n                \"display_name\": (\n                    region.location.city + f\" ({region.location.country})\"\n                ),\n                # TODO add region.description\n                \"aliases\": [region.location.name],\n                \"country_id\": region.location.country,\n                \"state\": None,\n                \"city\": region.location.city,\n                \"address_line\": None,\n                \"zip_code\": None,\n                \"lat\": regions[str(region.id)][\"lat\"],\n                \"lon\": regions[str(region.id)][\"lon\"],\n                \"founding_year\": None,\n                \"green_energy\": True,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all regions as availability zones.</p> <p>There is no concept of having multiple availability zones withing a region (virtual datacenter) at Hetzner Cloud, so creating 1-1 dummy Zones reusing the Region id and name.</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all regions as availability zones.\n\n    There is no concept of having multiple availability zones withing\n    a region (virtual datacenter) at Hetzner Cloud, so creating 1-1\n    dummy Zones reusing the Region id and name.\n\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"zone_id\": region.region_id,\n                \"name\": region.name,\n                \"api_reference\": region.name,\n                \"display_name\": region.name,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all server types from API and manual data entry from the Hetzner Cloud homepage.</p> <p>CPU information is recorded from https://www.hetzner.com/cloud/ as not exposed via API.</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all server types from API and manual data entry from the Hetzner Cloud homepage.\n\n    CPU information is recorded from &lt;https://www.hetzner.com/cloud/&gt; as not exposed via API.\"\"\"\n    items = []\n    for server in _client().server_types.get_all():\n        # CPU info not available via the API,\n        # collected from https://www.hetzner.com/cloud/\n        cpu = _server_cpu(server.name)\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"server_id\": str(server.id),\n                \"name\": server.name,\n                \"api_reference\": server.name,\n                \"display_name\": server.name,\n                \"description\": server.description,\n                \"family\": server.name.rstrip(\"0123456789\"),\n                \"vcpus\": server.cores,\n                \"hypervisor\": \"QEMU\",\n                \"cpu_allocation\": (\n                    CpuAllocation.SHARED\n                    if server.cpu_type == \"shared\"\n                    else CpuAllocation.DEDICATED\n                ),\n                \"cpu_cores\": None,\n                \"cpu_speed\": None,\n                \"cpu_architecture\": (\n                    CpuArchitecture.ARM64\n                    if server.architecture == \"arm\"\n                    else CpuArchitecture.X86_64\n                ),\n                \"cpu_manufacturer\": cpu[0],\n                \"cpu_family\": cpu[1],\n                \"cpu_model\": cpu[2],\n                \"cpus\": [],\n                \"memory_amount\": server.memory * 1024,\n                \"gpu_count\": 0,\n                \"gpu_memory_min\": None,\n                \"gpu_memory_total\": None,\n                \"gpu_manufacturer\": None,\n                \"gpu_model\": None,\n                \"gpus\": [],\n                \"storage_size\": server.disk,\n                \"storage_type\": (\n                    StorageType.SSD\n                    if server.storage_type == \"local\"\n                    else StorageType.NETWORK\n                ),\n                \"storages\": [],\n                \"network_speed\": None,\n                # https://docs.hetzner.com/cloud/billing/faq/#how-do-you-bill-for-traffic\n                \"inbound_traffic\": 0,  # free\n                \"outbound_traffic\": (\n                    max([region.get(\"included_traffic\") for region in server.prices])\n                    / (1024**3)\n                ),\n                \"ipv4\": 0,\n                \"status\": Status.ACTIVE if not server.deprecation else Status.INACTIVE,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>There are no spot instaces at Hetzner.</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"There are no spot instaces at Hetzner.\"\"\"\n    return []\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>Block storage volume information collected manually.</p> <p>There is not information shared vie the API, so information was collected manually from:</p> <ul> <li>https://www.hetzner.com/cloud/</li> <li>https://docs.hetzner.cloud/#volumes-create-a-volume</li> </ul> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"Block storage volume information collected manually.\n\n    There is not information shared vie the API, so information\n    was collected manually from:\n\n    - &lt;https://www.hetzner.com/cloud/&gt;\n    - &lt;https://docs.hetzner.cloud/#volumes-create-a-volume&gt;\n    \"\"\"\n    items = [\n        {\n            \"storage_id\": \"block\",\n            \"vendor_id\": vendor.vendor_id,\n            \"name\": \"Block storage volume\",\n            \"description\": None,\n            \"storage_type\": StorageType.NETWORK,\n            \"max_iops\": None,\n            \"max_throughput\": None,\n            \"min_size\": 10,\n            \"max_size\": 10240,\n        }\n    ]\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>Block storage volume pricing information collected manually.</p> <p>Source: https://www.hetzner.com/cloud/</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"Block storage volume pricing information collected manually.\n\n    Source: &lt;https://www.hetzner.com/cloud/&gt;\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"storage_id\": \"block\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"price\": 0.0440,\n                \"currency\": \"EUR\",\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>Traffic price collected manually.</p> <p>Source: https://docs.hetzner.com/robot/general/traffic/</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"Traffic price collected manually.\n\n    Source: &lt;https://docs.hetzner.com/robot/general/traffic/&gt;\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0,\n                \"price_tiered\": [],\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.IN,\n            }\n        )\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 1 / 1024,\n                \"price_tiered\": [],\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.OUT,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_hcloud/#sc_crawler.vendors._hcloud.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>IPv4 price collected manually.</p> <p>Source: https://docs.hetzner.com/general/others/ipv4-pricing/#cloud</p> Source code in <code>sc_crawler/vendors/_hcloud.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"IPv4 price collected manually.\n\n    Source: &lt;https://docs.hetzner.com/general/others/ipv4-pricing/#cloud&gt;\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0.50,\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.MONTH,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/","title":"_ovh","text":""},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh","title":"sc_crawler.vendors._ovh","text":"<p>Functions:</p> Name Description <code>inventory_compliance_frameworks</code> <p>Manual list of known compliance frameworks on OVHcloud.</p> <code>inventory_regions</code> <p>List all available OVHcloud Public Cloud regions.</p> <code>inventory_zones</code> <p>List all availability zones.</p> <code>inventory_servers</code> <p>List all server types (called \"flavors\" at OVHcloud).</p> <code>inventory_server_prices</code> <p>Fetch server pricing and regional availability.</p> <code>inventory_server_prices_spot</code> <p>There are no spot instances in OVHcloud Public Cloud.</p> <code>inventory_storages</code> <p>List all block storage offerings.</p> <code>inventory_storage_prices</code> <p>Extract storage prices from OVHCloud catalog.</p> <code>inventory_traffic_prices</code> <p>OVHcloud Public Cloud bandwidth pricing.</p> <code>inventory_ipv4_prices</code> <p>OVHcloud Public Cloud IPv4 pricing.</p>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of known compliance frameworks on OVHcloud.</p> <p>Data sources:</p> <ul> <li>General information and list of supported compliance programs: https://www.ovhcloud.com/en/compliance/</li> <li>ISO/IEC 27001/27017/27018: https://www.ovhcloud.com/en/compliance/iso-27001-27017-27018/</li> <li>SOC 1, SOC 2, SOC 3 with SOC 2 Type 2 details: https://www.ovhcloud.com/en/compliance/soc-1-2-3/</li> </ul> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of known compliance frameworks on OVHcloud.\n\n    Data sources:\n\n    - General information and list of supported compliance programs: &lt;https://www.ovhcloud.com/en/compliance/&gt;\n    - ISO/IEC 27001/27017/27018: &lt;https://www.ovhcloud.com/en/compliance/iso-27001-27017-27018/&gt;\n    - SOC 1, SOC 2, SOC 3 with SOC 2 Type 2 details: &lt;https://www.ovhcloud.com/en/compliance/soc-1-2-3/&gt;\n    \"\"\"\n    # Additional OVHcloud compliance frameworks you may want to support later\n    # (not yet present in lookup.py \u2014 listed here for reference only):\n    #   - ISO/IEC 27017 (cloud security controls)\n    #       URL: https://www.ovhcloud.com/en/compliance/iso-27001-27017-27018/\n    #       Suggested ID: \"iso27017\"\n    #   - ISO/IEC 27018 (protection of PII in public cloud)\n    #       URL: https://www.ovhcloud.com/en/compliance/iso-27001-27017-27018/\n    #       Suggested ID: \"iso27018\"\n    #   - SOC 1 (SSAE18 Type 2)\n    #       URL: https://www.ovhcloud.com/en/compliance/soc-1-2-3/\n    #       Suggested ID: \"soc1t2\"\n    #   - SOC 3 (general report)\n    #       URL: https://www.ovhcloud.com/en/compliance/soc-1-2-3/\n    #       Suggested ID: \"soc3\"\n    #   - PCI DSS (payment card industry data security standard)\n    #       URL: https://www.ovhcloud.com/en/compliance/pci-dss/\n    #       Suggested ID: \"pci-dss\"\n    #   - HDS (H\u00e9bergement de Donn\u00e9es de Sant\u00e9 / Healthcare data hosting compliance)\n    #       URL: https://www.ovhcloud.com/en/compliance/hds/\n    #       Suggested ID: \"hds\"\n    #   - ANSSI SecNumCloud (France national cloud security label)\n    #       URL: https://www.ovhcloud.com/en/compliance/secnumcloud/\n    #       Suggested ID: \"secnumcloud\"\n    #   - ISO 14001 (environmental management systems \u2014 non-security but published by OVHcloud)\n    #       URL: https://www.ovhcloud.com/en/compliance/iso-14001/\n    #       Suggested ID: \"iso14001\"\n    return map_compliance_frameworks_to_vendor(vendor.vendor_id, [\"iso27001\", \"soc2t2\"])\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all available OVHcloud Public Cloud regions.</p> <p>Data sources:</p> <ul> <li>https://www.ovhcloud.com/en/public-cloud/regions-availability/</li> <li>https://www.ovhcloud.com/en/about-us/global-infrastructure/expansion-regions-az/</li> <li>https://vms.status-ovhcloud.com/</li> <li>Google Maps search for the datacenter location or city-level coordinates</li> </ul> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_regions(vendor) -&gt; list[dict]:\n    \"\"\"List all available OVHcloud Public Cloud regions.\n\n    Data sources:\n\n    - &lt;https://www.ovhcloud.com/en/public-cloud/regions-availability/&gt;\n    - &lt;https://www.ovhcloud.com/en/about-us/global-infrastructure/expansion-regions-az/&gt;\n    - &lt;https://vms.status-ovhcloud.com/&gt;\n    - Google Maps search for the datacenter location or city-level coordinates\n    \"\"\"\n    items = []\n    regions = _get_regions()\n    datacenters = {\n        # Europe (EMEA)\n        \"SBG\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Strasbourg\",\n            \"address_line\": \"9 Rue du Bass. de l'Industrie\",\n            \"zip_code\": \"67000\",\n            \"lat\": 48.5854388,\n            \"lon\": 7.7974307,\n        },\n        \"GRA\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Gravelines\",\n            \"address_line\": \"1 Rte de la Frm Masson\",\n            \"zip_code\": \"59820\",\n            \"lat\": 51.0166852,\n            \"lon\": 2.1551437,\n        },\n        \"RBX\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Roubaix\",\n            \"address_line\": \"2 Rue Kellermann\",\n            \"zip_code\": \"59100\",\n            \"lat\": 50.691834,\n            \"lon\": 3.2003148,\n        },\n        \"PAR\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Paris\",\n            \"address_line\": \"12 Rue Riquet\",\n            \"zip_code\": \"75019\",\n            \"lat\": 48.8885363,\n            \"lon\": 2.3755977,\n        },\n        \"UK\": {\n            \"country_id\": \"GB\",\n            \"city\": \"London\",\n            \"address_line\": \"8 Viking Way\",\n            \"zip_code\": \"DA8 1EW\",\n            \"lat\": 51.4915264,\n            \"lon\": 0.1668186,\n        },\n        \"DE\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Frankfurt\",\n            # city-level coordinates from Google Maps\n            \"lat\": 50.1109221,\n            \"lon\": 8.6821267,\n        },\n        \"WAW\": {\n            \"country_id\": \"PL\",\n            \"city\": \"Warsaw\",\n            \"address_line\": \"Kazimierza Kami\u0144skiego 6\",\n            \"zip_code\": \"05-850\",\n            \"lat\": 52.2077264,\n            \"lon\": 20.8080621,\n        },\n        \"MIL\": {\n            \"country_id\": \"IT\",\n            \"city\": \"Milan\",\n            # OVH office in Milan, Italy\n            \"lat\": 45.4992183,\n            \"lon\": 9.1832528,\n        },\n        # North America\n        \"BHS\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Beauharnois\",\n            \"address_line\": \"50 Rue de l'Aluminerie\",\n            \"state\": \"Quebec\",\n            \"zip_code\": \"J6N 0C2\",\n            \"lat\": 45.3093037,\n            \"lon\": -73.8965535,\n        },\n        \"TOR\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Toronto\",\n            \"address_line\": \"17 Vondrau Dr\",\n            \"state\": \"Ontario\",\n            \"zip_code\": \"N3E 1B8\",\n            \"lat\": 43.4273216,\n            \"lon\": -80.3726843,\n        },\n        \"HIL\": {\n            \"country_id\": \"US\",\n            \"city\": \"Hillsboro\",\n            \"state\": \"Oregon\",\n            # city-level coordinates from Google Maps\n            \"lat\": 45.520137,\n            \"lon\": -122.9898308,\n        },\n        \"VIN\": {\n            \"country_id\": \"US\",\n            \"city\": \"Vint Hill\",\n            \"address_line\": \"6872 Watson Ct\",\n            \"state\": \"North Virginia\",\n            \"zip_code\": \"20187\",\n            \"lat\": 38.7474561,\n            \"lon\": -77.6744531,\n        },\n        # Asia-Pacific\n        \"SGP\": {\n            \"country_id\": \"SG\",\n            \"city\": \"Singapore\",\n            \"address_line\": \"1 Paya Lebar Link\",\n            \"zip_code\": \"408533\",\n            \"lat\": 1.3177101,\n            \"lon\": 103.893902,\n        },\n        \"SYD\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Sydney\",\n            # city-level coordinates from Google Maps\n            \"lat\": -33.8727409,\n            \"lon\": 151.2057136,\n        },\n        \"YNM\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Mumbai\",\n            # city-level coordinates from Google Maps\n            \"lat\": 19.0824822,\n            \"lon\": 72.7141328,\n        },\n    }\n\n    vendor.progress_tracker.start_task(name=\"Fetching regions\", total=len(regions))\n    for region in regions:\n        datacenter = _get_region(region)[\"datacenterLocation\"]\n        lookup = datacenters[datacenter]\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region,\n                \"name\": region,\n                \"api_reference\": region,\n                \"display_name\": f\"{region} ({lookup['country_id']})\",\n                \"aliases\": [],\n                \"country_id\": lookup[\"country_id\"],\n                \"state\": lookup.get(\"state\"),\n                \"city\": lookup.get(\"city\"),\n                \"address_line\": lookup.get(\"address_line\"),\n                \"zip_code\": lookup.get(\"zip_code\"),\n                \"lon\": lookup.get(\"lon\"),\n                \"lat\": lookup.get(\"lat\"),\n                # OVHcloud region page confirms Frankfurt (Limburg), Warsaw (O\u017car\u00f3w), London (Erith)\n                # as specific datacenter locations opened in 2016\n                \"founding_year\": 2016 if datacenter in [\"DE\", \"WAW\", \"UK\"] else None,\n                \"green_energy\": None,\n            }\n        )\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all availability zones.</p> <p>Data sources:</p> <ul> <li><code>/cloud/project/{serviceName}/region/{regionName}</code> API endpoint provides AZs for 3AZ regions</li> <li>1AZ zones have a standard \"a\" suffix as per https://www.ovhcloud.com/en/about-us/global-infrastructure/expansion-regions-az/</li> </ul> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_zones(vendor) -&gt; list[dict]:\n    \"\"\"List all availability zones.\n\n    Data sources:\n\n    - `/cloud/project/{serviceName}/region/{regionName}` API endpoint provides AZs for 3AZ regions\n    - 1AZ zones have a standard \"a\" suffix as per &lt;https://www.ovhcloud.com/en/about-us/global-infrastructure/expansion-regions-az/&gt;\n    \"\"\"\n\n    items = []\n    regions = _get_regions()\n    vendor.progress_tracker.start_task(name=\"Fetching zones\", total=len(regions))\n    for region in regions:\n        zones = _get_region(region, _get_project_id())[\"availabilityZones\"]\n        if not zones:\n            # single zone regions have a standard \"a\" suffix\n            zones = [region.lower() + \"-a\"]\n        for zone in zones:\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region,\n                    \"zone_id\": zone,\n                    \"name\": zone,\n                    \"api_reference\": zone,\n                    \"display_name\": zone,\n                }\n            )\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all server types (called \"flavors\" at OVHcloud).</p> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_servers(vendor) -&gt; list[dict]:\n    \"\"\"List all server types (called \"flavors\" at OVHcloud).\"\"\"\n    items = []\n\n    server_plans = [\n        s\n        for s in _get_catalog()[\"addons\"]\n        if (\n            s.get(\"product\") == \"publiccloud-instance\"\n            and s.get(\"blobs\")\n            and s[\"blobs\"].get(\"technical\")\n            # TODO list Windows machines later\n            and s[\"blobs\"].get(\"technical\").get(\"os\", {}).get(\"family\") == \"linux\"\n            # filter for hourly rates for now\n            and s.get(\"planCode\", \"\").endswith(\".consumption\")\n        )\n    ]\n    # dedupe just in case\n    servers = {}\n    for server_plan in server_plans:\n        servers[server_plan[\"invoiceName\"]] = server_plan\n\n    for server_id, server in servers.items():\n        blobs = server.get(\"blobs\", {})\n        if not blobs:\n            continue\n\n        commercial = blobs.get(\"commercial\", {})\n        technical = blobs.get(\"technical\", {})\n        name = commercial.get(\"name\", server_id)\n        family = _get_server_family(server_id)\n\n        # all resources are dedicated expect for the Discovery series\n        vcpus = technical.get(\"cpu\", {}).get(\"cores\", 0)\n        cpu_allocation = (\n            CpuAllocation.SHARED\n            if commercial.get(\"brickSubtype\") == \"discovery\"\n            else CpuAllocation.DEDICATED\n        )\n\n        memory = technical.get(\"memory\", {})\n        memory_size_gb = memory.get(\"size\", None)\n        memory_size = memory_size_gb * MIB_PER_GIB if memory_size_gb else None\n\n        _gpu_count, _gpu_memory_total, gpu_manufacturer, gpu_family, _gpu_model = (\n            _get_gpu_info(server_id)\n        )\n        gpu = technical.get(\"gpu\", {})\n        gpu_count = _gpu_count or gpu.get(\"number\", 0)\n        gpu_memory_per_gpu = (\n            gpu.get(\"memory\").get(\"size\", 0) * MIB_PER_GIB\n            if gpu.get(\"memory\")\n            else None\n        )\n        gpu_memory_total = _gpu_memory_total or (\n            gpu_memory_per_gpu * gpu_count if gpu_memory_per_gpu and gpu_count else None\n        )\n        gpu_model = _gpu_model or gpu.get(\"model\", None)\n\n        has_nvme = any(\n            \"nvme\"\n            in disk.get(\"technology\", \"\").lower() + disk.get(\"interface\", \"\").lower()\n            for disk in technical.get(\"storage\", {}).get(\"disks\", [])\n        )\n        storage_type = StorageType.NVME_SSD if has_nvme else StorageType.SSD\n        storage_size = sum(\n            [\n                disk.get(\"number\", 1) * disk.get(\"capacity\", 0)\n                for disk in technical.get(\"storage\", {}).get(\"disks\", [])\n            ]\n        )\n\n        status = Status.ACTIVE if \"active\" in blobs.get(\"tags\", []) else Status.INACTIVE\n\n        description_parts = [\n            f\"{vcpus} vCPUs\",\n            f\"{memory_size_gb} GiB RAM\",\n            f\"{storage_size} GB {('NVMe' if has_nvme else 'SSD')} storage\",\n            (\n                f\"{gpu_count}x{gpu_model} {int(gpu_memory_per_gpu / MIB_PER_GIB)} GiB VRAM\"\n                if gpu_count and gpu_model\n                else None\n            ),\n        ]\n        description = f\"{family} ({', '.join(filter(None, description_parts))})\"\n\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"server_id\": server_id,\n                \"name\": server_id,\n                \"api_reference\": server_id,\n                \"display_name\": name,\n                \"description\": description,\n                \"family\": family,\n                \"vcpus\": vcpus,\n                # as per OVH FAQ: https://www.ovhcloud.com/en/public-cloud/virtual-instances/\n                # alsoverified from lscpu on B3-8 instance (2025-11-17)\n                \"hypervisor\": \"KVM\",\n                \"cpu_allocation\": cpu_allocation,\n                \"cpu_cores\": None,\n                \"cpu_speed\": technical.get(\"cpu\", {}).get(\"frequency\"),\n                \"cpu_architecture\": CpuArchitecture.X86_64,  # All OVHcloud instances use x86_64\n                \"cpu_manufacturer\": None,\n                \"cpu_family\": None,\n                \"cpu_model\": None,\n                \"cpu_l1_cache\": None,\n                \"cpu_l2_cache\": None,\n                \"cpu_l3_cache\": None,\n                \"cpu_flags\": [],\n                \"cpus\": [],\n                \"memory_amount\": memory_size,\n                \"memory_generation\": None,\n                \"memory_speed\": None,\n                \"memory_ecc\": None,\n                \"gpu_count\": gpu_count,\n                \"gpu_memory_min\": gpu_memory_per_gpu,\n                \"gpu_memory_total\": gpu_memory_total,\n                \"gpu_manufacturer\": gpu_manufacturer,\n                \"gpu_family\": gpu_family,\n                \"gpu_model\": gpu_model,\n                \"gpus\": [],  # TODO fill this array\n                \"storage_size\": storage_size,\n                \"storage_type\": storage_type,\n                \"storages\": [],\n                \"network_speed\": technical.get(\"bandwidth\", {}).get(\"level\", None),\n                # no bundled free traffic as all traffic is unmetered\n                # https://www.ovhcloud.com/en-ie/public-cloud/prices/\n                \"inbound_traffic\": 0,\n                \"outbound_traffic\": 0,\n                \"ipv4\": 1,  # each instance gets one IPv4\n                \"status\": status,\n            }\n        )\n\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>Fetch server pricing and regional availability.</p> <p>Region availability information is fetched from the <code>/cloud/project/{serviceName}/flavor</code> API endpoint, then the related prices are fetched from the <code>/order/catalog/public/cloud</code> API endpoint.</p> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_server_prices(vendor) -&gt; list[dict]:\n    \"\"\"Fetch server pricing and regional availability.\n\n    Region availability information is fetched from the\n    `/cloud/project/{serviceName}/flavor` API endpoint, then the related prices\n    are fetched from the `/order/catalog/public/cloud` API endpoint.\n    \"\"\"\n    regions = scmodels_to_dict(vendor.regions, keys=[\"api_reference\"])\n    # list all addon prices and convert to a lookup dict\n    catalog = _get_catalog()\n    addons = {addon[\"planCode\"]: addon for addon in catalog[\"addons\"]}\n    # list all server &lt;&gt; region offers with a link to the price list\n    offers = _client().get(f\"/cloud/project/{_get_project_id()}/flavor\")\n    offers = [o for o in offers if o[\"osType\"] == \"linux\"]\n    items = []\n    vendor.progress_tracker.start_task(name=\"Fetching server offers\", total=len(offers))\n    for offer in offers:\n        region = regions.get(offer[\"region\"])\n        addon = addons[offer[\"planCodes\"][\"hourly\"]]\n        if region is None:\n            vendor.log(\n                f\"Excluding offer for {addon['invoiceName']} from unknown region: {offer['region']}\"\n            )\n            continue\n        # TODO check if server id is known for this vendor?\n        for zone in region.zones:\n            if zone.status != Status.ACTIVE:\n                continue\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"zone_id\": zone.zone_id,\n                    \"server_id\": addon[\"invoiceName\"],\n                    \"operating_system\": addon[\"blobs\"][\"technical\"][\"os\"][\"family\"],\n                    \"allocation\": Allocation.ONDEMAND,\n                    # we already filtered for hourly plan\n                    \"unit\": PriceUnit.HOUR,\n                    \"price\": (\n                        addon[\"pricings\"][0][\"price\"] / MICROCENTS_PER_CURRENCY_UNIT\n                    ),\n                    \"price_upfront\": 0,\n                    \"price_tiered\": [],\n                    \"currency\": catalog[\"locale\"][\"currencyCode\"],\n                    \"status\": Status.ACTIVE,\n                }\n            )\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>There are no spot instances in OVHcloud Public Cloud.</p> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_server_prices_spot(vendor) -&gt; list[dict]:\n    \"\"\"There are no spot instances in OVHcloud Public Cloud.\"\"\"\n    return []\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all block storage offerings.</p> <p>Data sources:</p> <ul> <li>https://www.ovhcloud.com/en-ie/public-cloud/block-storage/</li> <li>API endpoint: <code>/order/catalog/public/cloud</code> with <code>publiccloud-volume-classic</code> product name</li> </ul> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_storages(vendor) -&gt; list[dict]:\n    \"\"\"List all block storage offerings.\n\n    Data sources:\n\n    - &lt;https://www.ovhcloud.com/en-ie/public-cloud/block-storage/&gt;\n    - API endpoint: `/order/catalog/public/cloud` with `publiccloud-volume-classic` product name\n    \"\"\"\n    items = [\n        {\n            \"storage_id\": \"classic\",\n            \"vendor_id\": vendor.vendor_id,\n            \"name\": \"Classic Volume\",\n            # quote from homepage\n            \"description\": \"Perfect for the daily application needs of databases, virtual machines, and backups.\",\n            \"storage_type\": StorageType.NETWORK,\n            \"max_iops\": 500,\n            \"max_throughput\": 64,\n            \"min_size\": 10,\n            \"max_size\": 12_288,\n        },\n        {\n            \"storage_id\": \"high-speed\",\n            \"vendor_id\": vendor.vendor_id,\n            \"name\": \"High Speed Volume Gen 1\",\n            # quote from homepage\n            \"description\": \"Offers optimised and scalable performance, and is recommended for intensive workloads.\",\n            \"storage_type\": StorageType.NETWORK,\n            \"max_iops\": 3_000,\n            \"max_throughput\": 128,\n            \"min_size\": 10,\n            \"max_size\": 12_288,\n        },\n        {\n            \"storage_id\": \"high-speed-gen2\",\n            \"vendor_id\": vendor.vendor_id,\n            \"name\": \"High Speed Volume Gen 2\",\n            # quote from homepage\n            \"description\": \"Offers optimised and scalable performance, and is recommended for intensive workloads.\",\n            \"storage_type\": StorageType.NETWORK,\n            \"max_iops\": 20_000,\n            \"max_throughput\": 320,\n            \"min_size\": 10,\n            \"max_size\": 12_288,\n        },\n    ]\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>Extract storage prices from OVHCloud catalog.</p> <p>The catalog does not provide a detailed price list, only differentiates the prices of the known 3 storage types between regions with a single or three zones, so we assume all storage types are available in all regions.</p> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_storage_prices(vendor) -&gt; list[dict]:\n    \"\"\"Extract storage prices from OVHCloud catalog.\n\n    The catalog does not provide a detailed price list, only differentiates the\n    prices of the known 3 storage types between regions with a single or three\n    zones, so we assume all storage types are available in all regions.\n    \"\"\"\n    catalog = _get_catalog()\n    addons = {addon[\"planCode\"]: addon for addon in catalog[\"addons\"]}\n\n    items = []\n    for storage in vendor.storages:\n        for region in vendor.regions:\n            addon_name = f\"volume.{storage.storage_id}.consumption\"\n            if len(region.zones) &gt; 1:\n                addon_name += \".3AZ\"\n            addon = addons[addon_name]\n            price = addon[\"pricings\"][0][\"price\"] / MICROCENTS_PER_CURRENCY_UNIT\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"storage_id\": storage.storage_id,\n                    \"unit\": PriceUnit.GB_MONTH,\n                    \"price\": price * HOURS_PER_MONTH,\n                    \"currency\": catalog[\"locale\"][\"currencyCode\"],\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>OVHcloud Public Cloud bandwidth pricing.</p> <p>As per https://www.ovhcloud.com/en/public-cloud/prices:</p> <p>Outbound public network traffic is included in the price of instances on all locations, except the Asia-Pacific region (Singapore, Sydney and Mumbai). In the tree regions, 1 TB/month of outbound public traffic is included for each Public Cloud project. Beyond this quota, each additional GB of traffic is charged. Inbound network traffic from the public network is included in all cases and in all regions.</p> <p>The overage traffic priced at \u20ac0.01 ex. VAT/GB (see on the homepage after selecting one of the Asia-Pacific regions).</p> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_traffic_prices(vendor) -&gt; list[dict]:\n    \"\"\"OVHcloud Public Cloud bandwidth pricing.\n\n    As per &lt;https://www.ovhcloud.com/en/public-cloud/prices&gt;:\n\n    &gt; Outbound public network traffic is included in the price of instances on\n    &gt; all locations, except the Asia-Pacific region (Singapore, Sydney and\n    &gt; Mumbai). In the tree regions, 1 TB/month of outbound public traffic is\n    &gt; included for each Public Cloud project. Beyond this quota, each additional\n    &gt; GB of traffic is charged. Inbound network traffic from the public network\n    &gt; is included in all cases and in all regions.\n\n    The overage traffic priced at \u20ac0.01 ex. VAT/GB (see on the homepage after\n    selecting one of the Asia-Pacific regions).\n    \"\"\"\n    # Outbound traffic pricing for Asia-Pacific regions (Singapore, Sydney, Mumbai)\n    # Tier 1: 1-1024 GiB = Free (included in project quota)\n    # Tier 2: 1025+ GiB = $0.0109/GB\n    outbound_SYD_SGP_MUM_tiers = [\n        {\n            \"lower\": 1,\n            \"upper\": 1024,\n            \"price\": 0,\n        },\n        {\n            \"lower\": 1025,\n            \"upper\": \"Infinity\",\n            \"price\": 0.01,\n        },\n    ]\n\n    items = []\n    for region in vendor.regions:\n        # Incoming public traffic\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0,\n                \"price_tiered\": [],\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.IN,\n            }\n        )\n        # Outgoing public traffic\n        datacenter = _get_region(region.region_id)[\"datacenterLocation\"]\n        # Asia-Pacific region (Singapore, Sydney and Mumbai)\n        is_apac = datacenter in [\"SGP\", \"SYD\", \"YNM\"]\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0.01 if is_apac else 0,  # max tier price\n                \"price_tiered\": outbound_SYD_SGP_MUM_tiers if is_apac else [],\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.OUT,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_ovh/#sc_crawler.vendors._ovh.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>OVHcloud Public Cloud IPv4 pricing.</p> <p>Note that the API catalog endpoint states the \"publiccloud-publicip-ip\" product to be free on the single-AZ and 3AZ regions, but it's listed at 1.5 EUR/month in the control panel for any additional public IPv4 address, so we use that value for now.</p> <p>Data sources:</p> <ul> <li>https://www.ovhcloud.com/en/public-cloud/prices</li> <li>OVH Control Manager</li> </ul> Source code in <code>sc_crawler/vendors/_ovh.py</code> <pre><code>def inventory_ipv4_prices(vendor) -&gt; list[dict]:\n    \"\"\"OVHcloud Public Cloud IPv4 pricing.\n\n    Note that the API catalog endpoint states the \"publiccloud-publicip-ip\"\n    product to be free on the single-AZ and 3AZ regions, but it's listed at 1.5\n    EUR/month in the control panel for any additional public IPv4 address, so we\n    use that value for now.\n\n    Data sources:\n\n    - &lt;https://www.ovhcloud.com/en/public-cloud/prices&gt;\n    - OVH Control Manager\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        # NOTE local zone prices are different, but these are skipped for now\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 1.5,\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.MONTH,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_upcloud/","title":"_upcloud","text":""},{"location":"reference/sc_crawler/vendors/_upcloud/#sc_crawler.vendors._upcloud","title":"sc_crawler.vendors._upcloud","text":"<p>Functions:</p> Name Description <code>inventory_compliance_frameworks</code> <p>Manual list of known compliance frameworks at UpCloud.</p> <code>inventory_regions</code> <p>List all regions via API call.</p> <code>inventory_zones</code> <p>List all regions as availability zones.</p>"},{"location":"reference/sc_crawler/vendors/_upcloud/#sc_crawler.vendors._upcloud.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of known compliance frameworks at UpCloud.</p> <p>Data collected from their Security and Standards docs at https://upcloud.com/security-privacy.</p> Source code in <code>sc_crawler/vendors/_upcloud.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of known compliance frameworks at UpCloud.\n\n    Data collected from their Security and Standards docs at\n    &lt;https://upcloud.com/security-privacy&gt;.\"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id,\n        [\"iso27001\"],\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_upcloud/#sc_crawler.vendors._upcloud.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all regions via API call.</p> <p>Data manually enriched from https://upcloud.com/data-centres.</p> Source code in <code>sc_crawler/vendors/_upcloud.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all regions via API call.\n\n    Data manually enriched from &lt;https://upcloud.com/data-centres&gt;.\"\"\"\n    manual_data = {\n        \"au-syd1\": {\n            \"country_id\": \"AU\",\n            \"state\": \"New South Wales\",\n            \"city\": \"Sydney\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            \"lon\": 151.189377,\n            \"lat\": -33.918251,\n        },\n        \"de-fra1\": {\n            \"country_id\": \"DE\",\n            \"state\": \"Hesse\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2015,\n            \"green_energy\": True,\n            \"lon\": 8.735120,\n            \"lat\": 50.119190,\n        },\n        \"dk-cph1\": {\n            \"country_id\": \"DK\",\n            \"city\": \"Copenhagen\",\n            \"founding_year\": 2026,\n            \"green_energy\": True,\n            # approximation based on city as the datacenter is not listed on homepage yet\n            \"lon\": 12.57,\n            \"lat\": 55.68,\n        },\n        \"fi-hel1\": {\n            \"country_id\": \"FI\",\n            \"state\": \"Uusimaa\",\n            \"city\": \"Helsinki\",\n            \"founding_year\": 2011,\n            \"green_energy\": True,\n            \"lon\": 24.778570,\n            \"lat\": 60.20323,\n        },\n        \"fi-hel2\": {\n            \"country_id\": \"FI\",\n            \"state\": \"Uusimaa\",\n            \"city\": \"Helsinki\",\n            \"founding_year\": 2018,\n            \"green_energy\": True,\n            \"lon\": 24.876350,\n            \"lat\": 60.216209,\n        },\n        \"es-mad1\": {\n            \"country_id\": \"ES\",\n            \"state\": \"Madrid\",\n            \"city\": \"Madrid\",\n            \"founding_year\": 2020,\n            \"green_energy\": True,\n            \"lon\": -3.6239873,\n            \"lat\": 40.4395019,\n        },\n        \"nl-ams1\": {\n            \"country_id\": \"NL\",\n            \"state\": \"Noord Holland\",\n            \"city\": \"Amsterdam\",\n            \"founding_year\": 2017,\n            \"green_energy\": True,\n            \"lon\": 4.8400019,\n            \"lat\": 52.3998291,\n        },\n        \"no-svg1\": {\n            \"country_id\": \"NO\",\n            \"state\": \"Rogaland\",\n            \"city\": \"Stavanger\",\n            \"founding_year\": 2025,\n            # TODO update when data shared on homepage\n            \"green_energy\": False,\n            # approximation based on city - TODO update when info becomes available on the homepage\n            \"lon\": 5.5979374,\n            \"lat\": 58.9487157,\n        },\n        \"pl-waw1\": {\n            \"country_id\": \"PL\",\n            \"state\": \"Mazowieckie\",\n            \"city\": \"Warsaw\",\n            \"founding_year\": 2020,\n            \"green_energy\": True,\n            \"lon\": 20.9192823,\n            \"lat\": 52.1905901,\n        },\n        \"se-sto1\": {\n            \"country_id\": \"SE\",\n            \"state\": \"Stockholm\",\n            \"city\": \"Stockholm\",\n            \"founding_year\": 2015,\n            \"green_energy\": True,\n            \"lon\": 18.102788,\n            \"lat\": 59.2636708,\n        },\n        \"sg-sin1\": {\n            \"country_id\": \"SG\",\n            \"state\": \"Singapore\",\n            \"city\": \"Singapore\",\n            \"founding_year\": 2017,\n            \"green_energy\": True,\n            \"lon\": 103.7022636,\n            \"lat\": 1.3172304,\n        },\n        \"uk-lon1\": {\n            \"country_id\": \"GB\",\n            \"state\": \"London\",\n            \"city\": \"London\",\n            \"founding_year\": 2012,\n            \"green_energy\": True,\n            # approximate .. probably business address\n            \"lon\": -0.1037341,\n            \"lat\": 51.5232232,\n        },\n        \"us-chi1\": {\n            \"country_id\": \"US\",\n            \"state\": \"Illinois\",\n            \"city\": \"Chicago\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n            \"lon\": -87.6342056,\n            \"lat\": 41.8761287,\n        },\n        \"us-nyc1\": {\n            \"country_id\": \"US\",\n            \"state\": \"New York\",\n            \"city\": \"New York\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            \"lon\": -74.0645536,\n            \"lat\": 40.7834325,\n        },\n        \"us-sjo1\": {\n            \"country_id\": \"US\",\n            \"state\": \"California\",\n            \"city\": \"San Jose\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            \"lon\": -121.9754458,\n            \"lat\": 37.3764769,\n        },\n    }\n    items = []\n    regions = _client().get_zones()[\"zones\"][\"zone\"]\n    for region in regions:\n        if region[\"public\"] == \"yes\":\n            if region[\"id\"] not in manual_data:\n                raise ValueError(f\"Missing manual data for {region['id']}\")\n            region_data = manual_data[region[\"id\"]]\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region[\"id\"],\n                    \"name\": region[\"description\"],\n                    \"api_reference\": region[\"id\"],\n                    \"display_name\": (\n                        region[\"description\"] + f\" ({region_data['country_id']})\"\n                    ),\n                    \"aliases\": [],\n                    \"country_id\": region_data[\"country_id\"],\n                    \"state\": region_data.get(\"state\"),\n                    \"city\": region_data[\"city\"],\n                    \"address_line\": None,\n                    \"zip_code\": None,\n                    \"lon\": region_data[\"lon\"],\n                    \"lat\": region_data[\"lat\"],\n                    \"founding_year\": region_data[\"founding_year\"],\n                    \"green_energy\": region_data[\"green_energy\"],\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/_upcloud/#sc_crawler.vendors._upcloud.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all regions as availability zones.</p> <p>There is no concept of having multiple availability zones withing a region (virtual datacenter) at UpCloud, so creating 1-1 dummy Zones reusing the Region id and name.</p> Source code in <code>sc_crawler/vendors/_upcloud.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all regions as availability zones.\n\n    There is no concept of having multiple availability zones withing\n    a region (virtual datacenter) at UpCloud, so creating 1-1\n    dummy Zones reusing the Region id and name.\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"zone_id\": region.region_id,\n                \"name\": region.name,\n                \"api_reference\": region.region_id,\n                \"display_name\": region.name,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/vendors/","title":"vendors","text":""},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors","title":"sc_crawler.vendors.vendors","text":"<p>Supported cloud and VPS provider vendors.</p> <p>For logos, see e.g. https://iconduck.com/sets/svg-logos, and edit to square e.g. via https://boxy-svg.com.</p> <p>Attributes:</p> Name Type Description <code>aws</code> <p>Amazon Web Services.</p> <code>gcp</code> <p>Google Cloud Platform.</p> <code>hcloud</code> <p>Hetzner Cloud.</p> <code>azure</code> <p>Microsoft Azure.</p> <code>upcloud</code> <p>UpCloud.</p> <code>alicloud</code> <p>Alibaba Cloud.</p> <code>ovh</code> <p>OVHcloud.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.aws","title":"aws  <code>module-attribute</code>","text":"<pre><code>aws = Vendor(vendor_id='aws', name='Amazon Web Services', logo='https://sparecores.com/assets/images/vendors/aws.svg', homepage='https://aws.amazon.com', country=countries['US'], state='Washington', city='Seattle', address_line='410 Terry Ave N', zip_code='98109', founding_year=2002, status_page='https://health.aws.amazon.com/health/status')\n</code></pre> <p>Amazon Web Services.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.gcp","title":"gcp  <code>module-attribute</code>","text":"<pre><code>gcp = Vendor(vendor_id='gcp', name='Google Cloud Platform', logo='https://sparecores.com/assets/images/vendors/gcp.svg', homepage='https://cloud.google.com', country=countries['US'], state='California', city='Mountain View', address_line='1600 Amphitheatre Pkwy', zip_code='94043', founding_year=2008, status_page='https://status.cloud.google.com/')\n</code></pre> <p>Google Cloud Platform.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.hcloud","title":"hcloud  <code>module-attribute</code>","text":"<pre><code>hcloud = Vendor(vendor_id='hcloud', name='Hetzner Cloud', logo='https://sparecores.com/assets/images/vendors/hcloud.svg', homepage='https://www.hetzner.com/cloud/', country=countries['DE'], state='Bavaria', city='Gunzenhausen', address_line='Industriestr. 25', zip_code='91710', founding_year=2018, status_page='https://status.hetzner.com/')\n</code></pre> <p>Hetzner Cloud.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.azure","title":"azure  <code>module-attribute</code>","text":"<pre><code>azure = Vendor(vendor_id='azure', name='Microsoft Azure', logo='https://sparecores.com/assets/images/vendors/azure.svg', homepage='https://azure.microsoft.com', country=countries['US'], state='Washington', city='Redmond', address_line='One Microsoft Way', zip_code='98052', founding_year=2010, status_page='https://azure.status.microsoft.com')\n</code></pre> <p>Microsoft Azure.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.upcloud","title":"upcloud  <code>module-attribute</code>","text":"<pre><code>upcloud = Vendor(vendor_id='upcloud', name='UpCloud', logo='https://sparecores.com/assets/images/vendors/upcloud.svg', homepage='https://upcloud.com', country=countries['FI'], state='Uusimaa', city='Helsinki', address_line='Aleksanterinkatu 15 B, 7th floor', zip_code='00100', founding_year=2012, status_page='https://status.upcloud.com')\n</code></pre> <p>UpCloud.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.alicloud","title":"alicloud  <code>module-attribute</code>","text":"<pre><code>alicloud = Vendor(vendor_id='alicloud', name='Alibaba Cloud', logo='https://sparecores.com/assets/images/vendors/alicloud.svg', homepage='https://www.alibabacloud.com/', country=countries['CN'], state='Zhejiang', city='Hangzhou', address_line='969 West Wen Yi Road', zip_code='311121', founding_year=2009, status_page='https://status.alibabacloud.com/')\n</code></pre> <p>Alibaba Cloud.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.ovh","title":"ovh  <code>module-attribute</code>","text":"<pre><code>ovh = Vendor(vendor_id='ovh', name='OVHcloud', logo='https://sparecores.com/assets/images/vendors/ovh.svg', homepage='https://www.ovhcloud.com', country=countries['FR'], state='Hauts-de-France', city='Roubaix', address_line='2 rue Kellermann', zip_code='59100', founding_year=1999, status_page='https://www.status-ovhcloud.com')\n</code></pre> <p>OVHcloud.</p>"}]}