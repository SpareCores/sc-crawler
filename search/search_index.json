{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#spare-cores-crawler","title":"Spare Cores Crawler","text":"<p>SC Crawler is a Python package to pull and standardize data on cloud compute resources, with tooling to help organize and update the collected data into databases.</p>"},{"location":"#database-schemas","title":"Database schemas","text":"<p>The database schemas and relationships are visualized and documented at https://dbdocs.io/spare-cores/sc-crawler.</p>"},{"location":"#usage","title":"Usage","text":"<p>The package provides a CLI tool:</p> <pre><code>sc-crawler --help\n</code></pre>"},{"location":"#collect-data","title":"Collect data","text":"<p>Note that you need specific IAM permissions to be able to run <code>sc-crawler</code> at the below vendors:</p> Amazon Web Services (AWS) <p>AWS supports different options for Authentication and access for interacting with their APIs. This is usually an AWS access key stored in <code>~/.aws/credentials</code> or in environment variables, or an attached IAM role.</p> <p>The related user or role requires the below minimum IAM policy:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AllowCrawler\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"pricing:ListPriceLists\",\n                \"pricing:GetPriceListFileUrl\",\n                \"pricing:GetProducts\",\n                \"ec2:DescribeRegions\",\n                \"ec2:DescribeAvailabilityZones\",\n                \"ec2:DescribeInstanceTypes\",\n                \"ec2:DescribeSpotPriceHistory\",\n                \"ec2:DescribeInstanceTypeOfferings\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre> Google Cloud Platform (GCP) <p>Using the Application Default Credentials for interacting with GCP APIs. This is usually the path to a credential configuration file (created at https://developers.google.com/workspace/guides/create-credentials#service-account) stored in the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable, but could be an attached service account, Workload Identity Federation etc.</p> <p>The related user or service account requires the below minimum roles:</p> <ul> <li>Commerce Price Management Viewer</li> <li>Compute Viewer</li> </ul> <p>List of APIs required to be enabled in the project:</p> <ul> <li>Cloud Billing API</li> <li>Compute Engine API</li> </ul> Hetzner Cloud <p>Generate token at your Hetzner Cloud project and store it in the <code>HCLOUD_TOKEN</code> environment variable.</p> Microsoft Azure <p>Authentication is handled via the <code>DefaultAzureCredential</code>, so you can use either secrets or certificates.</p> <p>The following environment variables are required:</p> <ul> <li><code>AZURE_CLIENT_ID</code> (application client ID)</li> <li><code>AZURE_TENANT_ID</code></li> </ul> <p>To authenticate with secret:</p> <ul> <li><code>AZURE_CLIENT_SECRET</code> (secret value)</li> </ul> <p>To authenticate with certificate:</p> <ul> <li><code>AZURE_CLIENT_CERTIFICATE_PATH</code></li> <li><code>AZURE_CLIENT_CERTIFICATE_PASSWORD</code> (optional)</li> </ul> <p>For further options, consult the <code>EnvironmentCredential</code> docs.</p> <p>Optionally, you can also specify the Subscription (otherwise the first one found in the account will be used):</p> <ul> <li><code>AZURE_SUBSCRIPTION_ID</code></li> </ul> <p>The related Service Principal requires either the global \"Reader\" role, or the following list of (more restrictive) permissions:</p> <ul> <li><code>Microsoft.Resources/subscriptions/locations/read</code></li> </ul> <p>To create the Service Principal, go to App registrations, and then assign the role at the Subscription's Access control page.</p> <p>Fetch and standardize datacenter, zone, servers, traffic, storage etc data from AWS into a single SQLite file:</p> <pre><code>sc-crawler pull --connection-string sqlite:///sc-data-all.db --include-vendor aws\n</code></pre> <p>Such an up-to-date SQLite database is managed by the Spare Cores team in the SC Data repository, or you can also find it at https://sc-data-public-40e9d310.s3.amazonaws.com/sc-data-all.db.bz2.</p> <p>Example run:</p>"},{"location":"#hash-data","title":"Hash data","text":"<p>Database content can be hashed via the <code>sc-crawler hash</code> command. It will provide a single SHA1 hash value based on all records of all SC Crawler tables, which is useful to track if database content has changed.</p> <pre><code>$ sc-crawler hash --connection-string sqlite:///sc-data-all.db\nb13b9b06cfb917b591851d18c824037914564418\n</code></pre> <p>For advanced usage, check sc_crawler.utils.hash_database to hash tables or rows.</p>"},{"location":"#copy-and-sync-data","title":"Copy and sync data","text":"<p>To copy data from a database to another one or sync data between two databases, you can use the <code>copy</code> and <code>sync</code> subcommands, which also support feeding SCD tables.</p>"},{"location":"#database-migrations","title":"Database migrations","text":"<p>To generate <code>CREATE TABLE</code> statements using the current version of the Crawler schemas, e.g. for a MySQL database:</p> <pre><code>sc-crawler schemas create --dialect mysql\n</code></pre> <p>See <code>sc-crawler schemas create --help</code> for all supported database engines (mainly thanks to SQLAlchemy), and other options.</p> <p><code>sc-crawler schemas</code> also supports many other subcommands based on Alembic, e.g. <code>upgrade</code> or <code>downgrade</code> schemas in a database (either just printing the related SQL commands via the <code>--sql</code> flag), printing the current version, setting a database version to a specific revision, or auto-generating migration scripts (for SC Crawler developers).</p>"},{"location":"#orm","title":"ORM","text":"<p>SC Crawler is using SQLModel / SQLAlchemy as the ORM to interact with the underlying database, and you can also use the defined schemas and models to actually read/filter a previously pulled DB. Quick examples:</p> <pre><code>from sc_crawler.tables import Server\nfrom sqlmodel import create_engine, Session, select\n\nengine = create_engine(\"sqlite:///sc-data-all.db\") # (1)!\nsession = Session(engine) # (2)!\nserver = session.exec(select(Server).where(Server.server_id == 'trn1.32xlarge')).one() # (3)!\n\nfrom rich import print as pp # (4)!\npp(server)\npp(server.vendor) # (5)!\n</code></pre> <ol> <li>Creating a connection (pool) to the SQLite database.</li> <li>Define an in-memory representation of the database for the ORM objects.</li> <li>Query the database for the Server with the <code>trn1.32xlarge</code> id.</li> <li>Use <code>rich</code> to pretty-print the objects.</li> <li>The <code>vendor</code> is a Vendor relationship of the Server, in this case being aws.</li> </ol>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#v03x-development-version","title":"v0.3.x (development version)","text":"<p>New vendor(s):</p> <ul> <li>UpCloud</li> </ul> <p>New benchmark(s):</p> <ul> <li>PassMark.</li> </ul>"},{"location":"CHANGELOG/#v031-oct-25-2024","title":"v0.3.1 (Oct 25, 2024)","text":"<p>New benchmark(s):</p> <ul> <li>Static HTTP server.</li> <li>Redis.</li> <li>stress-ng's div16 run on all vCPUs.</li> </ul> <p>New feature(s):</p> <ul> <li>Optional list of tables to be synced in the CLI tool.</li> <li>Standardized CPU and GPU manufacturer, family, and model name.</li> <li>Optional description for Disks.</li> </ul> <p>Fix(es):</p> <ul> <li>Better support for long-running DB syncs.</li> <li>Exlude dummy \"2 Ghz\" CPU speed reported by GCP.</li> <li>Improved physical CPU cores lookup.</li> <li>Improved performance for interactive bulk inserts.</li> <li>Review how vendors reports on storage size using base 2 or 10.</li> <li>Update from Azure's deprecated API endpoint, fix ingesting NVMe drives.</li> <li>Better support for Azure API rate limits.</li> </ul>"},{"location":"CHANGELOG/#v030-aug-20-2024","title":"v0.3.0 (Aug 20, 2024)","text":"<p>New vendor(s):</p> <ul> <li>Microsoft Azure</li> </ul> <p>New feature(s):</p> <ul> <li>Support for new <code>hcloud</code> CX server types.</li> <li>Support for new <code>hcloud</code> region (Singapore).</li> <li>Improved caching.</li> </ul> <p>Fix(es):</p> <ul> <li>Join references pointing to the right tables.</li> <li>Count CPU cores in all physical CPUs.</li> <li>Improve the standardization and cleanup of the CPU manufacturer, family, and model.</li> <li>Extract speed from CPU description when available instead of unreliable <code>dmidecode</code> data.</li> <li>Update included outbound network extractor at <code>hcloud</code> due to API change.</li> <li>Check if a server is available in a <code>gcp</code> zone even though a related price is known.</li> <li>Silence <code>SAWarning</code> on multiple relationships using overlapping compound foreign keys.</li> <li>Fix manually collected geolocation of 3 <code>gcp</code> regions.</li> <li>Fix spelling issues in benchmark and table column descriptions.</li> </ul> <p>\u203c Breaking changes:</p> <ul> <li>Complex queries with joins relying on the foreign keys of the table   definitions are now using the right references. This might result in   different (but correct) results than before.</li> </ul>"},{"location":"CHANGELOG/#v021-june-4-2024","title":"v0.2.1 (June 4, 2024)","text":"<p>Fix(es):</p> <ul> <li>Sort <code>dict</code> by its keys before passing as JSON to the database engine.</li> </ul>"},{"location":"CHANGELOG/#v020-june-4-2024","title":"v0.2.0 (June 4, 2024)","text":"<p>Database migrations:</p> <ul> <li>Name all constraints for easier management in the future.</li> <li>Rename the <code>datacenter</code> table to <code>region</code>, and the <code>datacenter_id</code>   column to <code>region_id</code> in the <code>zone</code>, <code>server_price</code>,   <code>storage_price</code>, <code>traffic_price</code> and <code>ipv4_price</code> tables.</li> </ul> <p>\u203c Breaking changes:</p> <ul> <li>Renamed Datacenter to Region in all tables and across the codebase.</li> </ul>"},{"location":"CHANGELOG/#v014-june-2-2024","title":"v0.1.4 (June 2, 2024)","text":"<p>New feature(s):</p> <ul> <li>Documented <code>benchmark</code> workloads and actual <code>benchmark_score</code> records loaded from <code>sparecores-inspector-data</code>.</li> <li>Enriched <code>server</code> details loaded from <code>sparecores-inspector-data</code>.</li> </ul> <p>Database migrations:</p> <ul> <li>Add <code>benchmark</code> and <code>benchmark_score</code> tables.</li> <li>Add 8 new columns to the <code>server</code> table.</li> </ul> <p>\u203c Breaking changes:</p> <ul> <li>Renamed the <code>memory</code> column to <code>memory_amount</code> in the <code>server</code> table.</li> </ul>"},{"location":"CHANGELOG/#v013-may-7-2024","title":"v0.1.3 (May 7, 2024)","text":"<p>New feature(s):</p> <ul> <li>Add <code>api_reference</code> and <code>display_name</code> to <code>Datacenter</code>, <code>Zone</code>, and <code>Server</code>.</li> <li>Add latitude and longitude coordinates to <code>Datacenter</code>.</li> <li>Add <code>family</code> to <code>Server</code>.</li> </ul>"},{"location":"CHANGELOG/#v012-apr-24-2024","title":"v0.1.2 (Apr 24, 2024)","text":"<p>New vendor(s):</p> <ul> <li>Google Cloud Platform (GCP)</li> </ul> <p>New feature(s):</p> <ul> <li>SVG logo for all supported vendors.</li> </ul> <p>Fix(es):</p> <ul> <li>Amazon Web Services' missed outbound traffic prices</li> <li>Hetzner Cloud's outbound traffic price per GB instead of TB</li> <li>Hetzner Cloud's <code>datacenter_id</code> reference in the server prices table</li> </ul>"},{"location":"CHANGELOG/#v011-apr-12-2024","title":"v0.1.1 (Apr 12, 2024)","text":"<p>New vendors:</p> <ul> <li>Hetzner Cloud</li> </ul> <p>Infrastructure:</p> <ul> <li>Use Alembic for database migrations.</li> </ul> <p>CLI tools:</p> <ul> <li>Database migration helpers.</li> <li>Moved CREATE TABLE generator subcommand under <code>schemas create</code>.</li> </ul> <p>Database migrations:</p> <ul> <li>Add <code>description</code> field to <code>Server</code>.</li> <li>Update <code>Server.cpu_cores</code> to be optional.</li> </ul> <p>\u203c Breaking changes:</p> <p>As the database migration tool was just introduced, if you have been already using SC Crawler to initialize a database and collect data (e.g. in SCD tables), you will need to let Alembic know that you are already on v0.1.0 via the below command:</p> <pre><code>sc-crawler schemas stamp --revision 98894dffd37c\n</code></pre>"},{"location":"CHANGELOG/#v010-apr-05-2024","title":"v0.1.0 (Apr 05, 2024)","text":"<p>Initial PyPI release of <code>sparecores-crawler</code>.</p> <p>CLI tools:</p> <ul> <li>Generate database schema for standard and SCD tables of the   supported records in various SQL dialects.</li> <li>Pull records from vendor APIs and update a database with the fetched   records.</li> <li>Copy all supported tables from a database into another one.</li> <li>Sync records of a database into another database's standard or SCD   tables, with optional logging of the changes.</li> <li>Hash database content.</li> </ul> <p>Supported vendors:</p> <ul> <li>Amazon Web Services (AWS)</li> </ul> <p>Supported records:</p> <ul> <li>country</li> <li>compliance_framework</li> <li>vendor</li> <li>vendor_compliance_link</li> <li>datacenter</li> <li>zone</li> <li>server</li> <li>server_price</li> <li>storage</li> <li>storage_price</li> <li>traffic_price</li> <li>ipv4_price</li> </ul> <p>Infrastructure:</p> <ul> <li>Package documentation via MkDocs, Material for MkDocs,   <code>mkdocstrings</code>, and bunch of other MkDocs plugins.</li> <li>Database documentation on table schemas, relations and column   comments via DBML and dbdocs.</li> <li>Unit tests via <code>pytest</code>.</li> <li>Linting via <code>ruff</code>.</li> </ul>"},{"location":"add_vendor/","title":"Vendor support","text":"<p>Each file in the <code>src/sc_crawler/vendors</code> folder provides the required helpers for a given Vendor, named as the <code>id</code> of the vendor. For example, <code>aws.py</code> provides functions to be used by its Vendor instance, called <code>aws</code>.</p>"},{"location":"add_vendor/#first-steps","title":"First steps","text":"<ol> <li>Define the new Vendor instance in <code>src/sc_crawler/vendors/vendors.py</code>.</li> <li>Copy the below template file as a starting point to <code>src/sc_crawler/vendors/{vendor_id}.py</code>.</li> <li>Update <code>src/sc_crawler/vendors/__init__.py</code> to include the new vendor.</li> <li>Update <code>docs/add_vendor.md</code> with the credential requirements for the new vendor.</li> <li>Implement the <code>inventory</code> methods.</li> </ol>"},{"location":"add_vendor/#inventory-methods","title":"Inventory methods","text":"<p>Each vendor module should provide the below functions:</p> <ul> <li><code>inventory_compliance_frameworks</code>: Define <code>VendorComplianceLink</code> instances to describe which frameworks the vendor complies with. Optionally include references in the <code>comment</code> field. To avoid duplicating <code>ComplianceFramework</code> instances, easiest is to use the <code>compliance_framework_id</code> field instead of the <code>compliance_framework</code> relationship, preferably via sc_crawler.lookup.map_compliance_frameworks_to_vendor.</li> <li><code>inventory_regions</code>: Define <code>Region</code> instances with location, energy source etc for each region the vendor has.</li> <li><code>inventory_zones</code>: Define a <code>Zone</code> instance for each availability zone of the vendor in each region.</li> <li><code>inventory_servers</code>: Define <code>Server</code> instances for the vendor's server/instance types.</li> <li><code>inventory_server_prices</code>: Define the <code>ServerPrice</code> instances for the standard/ondemand (or optionally also for the reserved) pricing of the instance types per region and zone.</li> <li><code>inventory_server_prices_spot</code>: Similar to the above, define <code>ServerPrice</code> instances but the <code>allocation</code> field set to <code>Allocation.SPOT</code>. Very likely to see different spot prices per region/zone.</li> <li><code>inventory_storage_prices</code>: Define <code>StoragePrice</code> instances to describe the available storage options that can be attached to the servers.</li> <li><code>inventory_traffic_prices</code>: Define <code>TrafficPrice</code> instances to describe the pricing of ingress/egress traffic.</li> <li><code>inventory_ipv4_prices</code>: Define <code>Ipv4Price</code> instances on the price of an IPv4 address.</li> </ul> <p>Each function will be picked up as the related Vendor instance's instance methods, so each function should take a single argument, that is the Vendor instance. E.g. sc_crawler.vendors.aws.inventory_regions is called by sc_crawler.tables.Vendor.inventory_regions.</p> <p>The functions should return an array of dict representing the related objects. The vendor's <code>inventory</code> method will pass the array to sc_crawler.insert.insert_items along with the table object.</p> <p>Other functions and variables must be prefixed with an underscore to suggest those are internal tools.</p>"},{"location":"add_vendor/#progress-bars","title":"Progress bars","text":"<p>To create progress bars, you can use the Vendor's progress_tracker attribute with the below methods:</p> <ul> <li>start_task</li> <li>advance_task</li> <li>hide_task</li> </ul> <p>The start_task will register a task in the \"Current tasks\" progress bar list with the provided name automatically prefixed by the vendor name, and the provided number of expected steps. You should call advance_task after each step finished, which will by default update the most recently created task's progress bar. If making updates in parallel, store the [rich.progress.TaskID][] returned by start_task and pass to advance_task and hide_task explicitly. Make sure to call <code>hide_task</code> when the progress bar is not to be shown anymore. It's a good practice to log the number of fetched/synced objects afterwards with <code>logger.info.</code> See the manual of <code>VendorProgressTracker</code> for more details.</p> <p>Basic example:</p> <pre><code>def inventory_zones(vendor):\n    zones = range(5)\n    vendor.progress_tracker.start_task(name=\"Searching zones\", total=len(zones))\n    for zone in zones:\n        # do something\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return zones\n</code></pre>"},{"location":"add_vendor/#template-file-for-new-vendors","title":"Template file for new vendors","text":"<pre><code>def inventory_compliance_frameworks(vendor):\n    return map_compliance_frameworks_to_vendor(vendor.vendor_id, [\n    #    \"hipaa\",\n    #    \"soc2t2\",\n    #    \"iso27001\",\n    ])\n\n\ndef inventory_regions(vendor):\n    items = []\n    # for region in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": \"\",\n    #             \"name\": \"\",\n    #             \"api_reference\": \"\",\n    #             \"display_name\": \"\",\n    #             \"aliases\": [],\n    #             \"country_id\": \"\",\n    #             \"state\": None,\n    #             \"city\": None,\n    #             \"address_line\": None,\n    #             \"zip_code\": None,\n    #             \"lon\": None,\n    #             \"lat\": None,\n    #             \"founding_year\": None,\n    #             \"green_energy\": None,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_zones(vendor):\n    items =[]\n    # for zone in []:\n    #     items.append({\n    #         \"vendor_id\": vendor.vendor_id,\n    #         \"region_id\": \"\",\n    #         \"zone_id\": \"\",\n    #         \"name\": \"\",\n    #         \"api_reference\": \"\",\n    #         \"display_name\": \"\",\n    #     })\n    return items\n\n\ndef inventory_servers(vendor):\n    items = []\n    # for server in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"server_id\": ,\n    #             \"name\": ,\n    #             \"api_reference\": ,\n    #             \"display_name\": ,\n    #             \"description\": None,\n    #             \"family\": None,\n    #             \"vcpus\": ,\n    #             \"hypervisor\": None,\n    #             \"cpu_allocation\": CpuAllocation....,\n    #             \"cpu_cores\": None,\n    #             \"cpu_speed\": None,\n    #             \"cpu_architecture\": CpuArchitecture....,\n    #             \"cpu_manufacturer\": None,\n    #             \"cpu_family\": None,\n    #             \"cpu_model\": None,\n    #             \"cpu_l1_cache\": None,\n    #             \"cpu_l2_cache\": None,\n    #             \"cpu_l3_cache\": None,\n    #             \"cpu_flags\": [],\n    #             \"cpus\": [],\n    #             \"memory_amount\": ,\n    #             \"memory_generation\": None,\n    #             \"memory_speed\": None,\n    #             \"memory_ecc\": None,\n    #             \"gpu_count\": 0,\n    #             \"gpu_memory_min\": None,\n    #             \"gpu_memory_total\": None,\n    #             \"gpu_manufacturer\": None,\n    #             \"gpu_family\": None,\n    #             \"gpu_model\": None,\n    #             \"gpus\": [],\n    #             \"storage_size\": 0,\n    #             \"storage_type\": None,\n    #             \"storages\": [],\n    #             \"network_speed\": None,\n    #             \"inbound_traffic\": 0,\n    #             \"outbound_traffic\": 0,\n    #             \"ipv4\": 0,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_server_prices(vendor):\n    items = []\n    # for server in []:\n    #     items.append({\n    #         \"vendor_id\": ,\n    #         \"region_id\": ,\n    #         \"zone_id\": ,\n    #         \"server_id\": ,\n    #         \"operating_system\": ,\n    #         \"allocation\": Allocation....,\n    #         \"unit\": PriceUnit.HOUR,\n    #         \"price\": ,\n    #         \"price_upfront\": 0,\n    #         \"price_tiered\": [],\n    #         \"currency\": \"USD\",\n    #     })\n    return items\n\n\ndef inventory_server_prices_spot(vendor):\n    return []\n\n\ndef inventory_storages(vendor):\n    items = []\n    # for storage in []:\n    #     items.append(\n    #         {\n    #             \"storage_id\": ,\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"name\": ,\n    #             \"description\": None,\n    #             \"storage_type\": StorageType....,\n    #             \"max_iops\": None,\n    #             \"max_throughput\": None,\n    #             \"min_size\": None,\n    #             \"max_size\": None,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_storage_prices(vendor):\n    items = []\n    # for price in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": ,\n    #             \"storage_id\": ,\n    #             \"unit\": PriceUnit.GB_MONTH,\n    #             \"price\": ,\n    #             \"currency\": \"USD\",\n    #         }\n    #     )\n    return items\n\n\ndef inventory_traffic_prices(vendor):\n    items = []\n    # for price in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": ,\n    #             \"price\": ,\n    #             \"price_tiered\": [],\n    #             \"currency\": \"USD\",\n    #             \"unit\": PriceUnit.GB_MONTH,\n    #             \"direction\": TrafficDirection....,\n    #         }\n    #     )\n    return items\n\n\ndef inventory_ipv4_prices(vendor):\n    items = []\n    # for price in []:\n    #     items.append(\n    #         {\n    #             \"vendor_id\": vendor.vendor_id,\n    #             \"region_id\": ,\n    #             \"price\": ,\n    #             \"currency\": \"USD\",\n    #             \"unit\": PriceUnit.MONTH,\n    #         }\n    #     )\n    return items\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>sc_crawler<ul> <li>alembic_helpers</li> <li>cli</li> <li>insert</li> <li>inspector</li> <li>logger</li> <li>lookup</li> <li>str_utils</li> <li>table_bases</li> <li>table_fields</li> <li>tables</li> <li>tables_scd</li> <li>utils</li> <li>vendor_helpers</li> <li>vendors<ul> <li>aws</li> <li>azure</li> <li>gcp</li> <li>hcloud</li> <li>upcloud</li> <li>vendors</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/sc_crawler/","title":"sc_crawler","text":""},{"location":"reference/sc_crawler/#sc_crawler","title":"sc_crawler","text":""},{"location":"reference/sc_crawler/alembic_helpers/","title":"alembic_helpers","text":""},{"location":"reference/sc_crawler/alembic_helpers/#sc_crawler.alembic_helpers","title":"sc_crawler.alembic_helpers","text":""},{"location":"reference/sc_crawler/alembic_helpers/#sc_crawler.alembic_helpers.alembic_cfg","title":"alembic_cfg","text":"<pre><code>alembic_cfg(connection, scd=None, force_logging=True)\n</code></pre> <p>Loads the Alembic config and sets some dynamic attributes.</p> Source code in <code>sc_crawler/alembic_helpers.py</code> <pre><code>def alembic_cfg(\n    connection, scd: Optional[bool] = None, force_logging: bool = True\n) -&gt; Config:\n    \"\"\"Loads the Alembic config and sets some dynamic attributes.\"\"\"\n    alembic_cfg = Config(join(pkg_folder, \"alembic.ini\"))\n    alembic_cfg.attributes[\"force_logging\"] = force_logging\n    if scd is not None:\n        alembic_cfg.attributes[\"scd\"] = scd\n    alembic_cfg.attributes[\"connection\"] = connection\n    alembic_cfg.set_main_option(\"script_location\", join(pkg_folder, \"alembic\"))\n    return alembic_cfg\n</code></pre>"},{"location":"reference/sc_crawler/alembic_helpers/#sc_crawler.alembic_helpers.get_revision","title":"get_revision","text":"<pre><code>get_revision(connection, version_table='zzz_alembic_version')\n</code></pre> <p>Get current revision of alembic in a database connection.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>SQLAlchemy connection to look up revision in <code>version_table</code></p> required <code>version_table</code> <code>str</code> <p>name of the table storing revision</p> <code>'zzz_alembic_version'</code> Source code in <code>sc_crawler/alembic_helpers.py</code> <pre><code>def get_revision(\n    connection: Connection, version_table: str = \"zzz_alembic_version\"\n) -&gt; str:\n    \"\"\"Get current revision of alembic in a database connection.\n\n    Args:\n        connection: SQLAlchemy connection to look up revision in `version_table`\n        version_table: name of the table storing revision\"\"\"\n    return MigrationContext.configure(\n        connection, opts={\"version_table\": version_table}\n    ).get_current_revision()\n</code></pre>"},{"location":"reference/sc_crawler/cli/","title":"cli","text":""},{"location":"reference/sc_crawler/cli/#sc_crawler.cli","title":"sc_crawler.cli","text":"<p>The Spare Cores (SC) Crawler CLI functions.</p> <p>Check <code>sc-crawler --help</code> for more details.</p>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.create","title":"create","text":"<pre><code>create(connection_string=None, dialect=None, scd=False)\n</code></pre> <p>Print the database schema in a SQL dialect.</p> <p>Either <code>connection_string</code> or <code>dialect</code> is to be provided to decide what SQL dialect to use to generate the CREATE TABLE (and related) SQL statements.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef create(\n    connection_string: Annotated[\n        Optional[str], typer.Option(help=\"Database URL with SQLAlchemy dialect.\")\n    ] = None,\n    dialect: Annotated[\n        Optional[Engines],\n        typer.Option(\n            help=\"SQLAlchemy dialect to use for generating CREATE TABLE statements.\"\n        ),\n    ] = None,\n    scd: Annotated[\n        bool, typer.Option(help=\"If SCD Type 2 tables should be also created.\")\n    ] = False,\n):\n    \"\"\"\n    Print the database schema in a SQL dialect.\n\n    Either `connection_string` or `dialect` is to be provided to decide\n    what SQL dialect to use to generate the CREATE TABLE (and related)\n    SQL statements.\n    \"\"\"\n    if connection_string is None and dialect is None:\n        print(\"Either connection_string or dialect parameters needs to be provided!\")\n        raise typer.Exit(code=1)\n    if dialect:\n        url = engine_to_dialect[dialect.value]\n    else:\n        url = connection_string\n\n    def metadata_dump(sql, *_args, **_kwargs):\n        typer.echo(str(sql.compile(dialect=engine.dialect)) + \";\")\n\n    engine = create_engine(url, strategy=\"mock\", executor=metadata_dump)\n    for table in tables:\n        table.__table__.create(engine)\n    if scd:\n        for table in tables_scd:\n            table.__table__.create(engine)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.current","title":"current","text":"<pre><code>current(connection_string='sqlite:///sc-data-all.db', scd=False)\n</code></pre> <p>Show current database revision.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef current(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    scd: options.scd = False,\n):\n    \"\"\"\n    Show current database revision.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.current(alembic_cfg(connection, scd))\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.upgrade","title":"upgrade","text":"<pre><code>upgrade(connection_string='sqlite:///sc-data-all.db', revision='heads', scd=False, sql=False)\n</code></pre> <p>Upgrade the database schema to a given (default: most recent) revision.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef upgrade(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    revision: options.revision = \"heads\",\n    scd: options.scd = False,\n    sql: options.sql = False,\n):\n    \"\"\"\n    Upgrade the database schema to a given (default: most recent) revision.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.upgrade(alembic_cfg(connection, scd), revision, sql)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.downgrade","title":"downgrade","text":"<pre><code>downgrade(connection_string='sqlite:///sc-data-all.db', revision='-1', scd=False, sql=False)\n</code></pre> <p>Downgrade the database schema to a given (default: previous) revision.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef downgrade(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    revision: options.revision = \"-1\",\n    scd: options.scd = False,\n    sql: options.sql = False,\n):\n    \"\"\"\n    Downgrade the database schema to a given (default: previous) revision.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.downgrade(alembic_cfg(connection, scd), revision, sql)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.stamp","title":"stamp","text":"<pre><code>stamp(connection_string='sqlite:///sc-data-all.db', revision='heads', scd=False, sql=False)\n</code></pre> <p>Set the migration revision mark in the database to a specified revision. Set to \"heads\" if the database schema is up-to-date.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef stamp(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    revision: options.revision = \"heads\",\n    scd: options.scd = False,\n    sql: options.sql = False,\n):\n    \"\"\"\n    Set the migration revision mark in the database to a specified revision. Set to \"heads\" if the database schema is up-to-date.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.stamp(alembic_cfg(connection, scd), revision, sql)\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.autogenerate","title":"autogenerate","text":"<pre><code>autogenerate(connection_string='sqlite:///sc-data-all.db', message='empty message')\n</code></pre> <p>Autogenerate a migrations script based on the current state of a database.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@alembic_app.command()\ndef autogenerate(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    message: Annotated[\n        str,\n        typer.Option(help=\"Revision message, e.g. SC Crawler version number.\"),\n    ] = \"empty message\",\n):\n    \"\"\"\n    Autogenerate a migrations script based on the current state of a database.\n    \"\"\"\n    engine = create_engine(connection_string)\n    with engine.begin() as connection:\n        command.revision(\n            alembic_cfg(connection=connection), autogenerate=True, message=message\n        )\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.hash_command","title":"hash_command","text":"<pre><code>hash_command(connection_string='sqlite:///sc-data-all.db')\n</code></pre> <p>Print the hash of the content of a database.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command(name=\"hash\")\ndef hash_command(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n):\n    \"\"\"Print the hash of the content of a database.\"\"\"\n    print(hash_database(connection_string))\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.copy","title":"copy","text":"<pre><code>copy(source, target)\n</code></pre> <p>Copy the standard SC Crawler tables of a database into a blank database.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command()\ndef copy(\n    source: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) that is to be copied to `target`.\"\n        ),\n    ],\n    target: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) that is to be populated with the content of `source`.\"\n        ),\n    ],\n):\n    \"\"\"Copy the standard SC Crawler tables of a database into a blank database.\"\"\"\n\n    source_engine = create_engine(source, pool_pre_ping=True)\n    target_engine = create_engine(target, pool_pre_ping=True)\n\n    for table in tables:\n        table.__table__.create(target_engine)\n\n    progress = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    panel = Panel(progress, title=\"Copying tables\", expand=False)\n\n    with Live(panel):\n        for table in tables:\n            with Session(source_engine) as source_session:\n                rows = source_session.exec(statement=select(table))\n                items = [row.model_dump() for row in rows]\n            with Session(target_engine) as target_session:\n                insert_items(table, items, session=target_session, progress=progress)\n                target_session.commit()\n    with target_engine.begin() as connection:\n        command.stamp(alembic_cfg(connection), \"heads\")\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.sync","title":"sync","text":"<pre><code>sync(source, target, dry_run=False, scd=False, sync_tables=table_names, log_changes_path=None, log_changes_tables=table_names)\n</code></pre> <p>Sync a database to another one.</p> <p>Hashing both the <code>source</code> and the <code>target</code> databases, then comparing hashes and marking for syncing the following records:</p> <ul> <li> <p>new (rows with primary keys found in <code>source</code>, but not found in <code>target</code>)</p> </li> <li> <p>update (rows with different values in <code>source</code> and in <code>target</code>).</p> </li> <li> <p>inactive (rows with primary keys found in <code>target</code>, but not found in <code>source</code>).</p> </li> </ul> <p>The records marked for syncing are written to the <code>target</code> database's standard or SCD tables. When updating the SCD tables, the hashing still happens on the standard tables/views, which are probably based on the most recent records of the SCD tables.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command()\ndef sync(\n    source: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) to sync to `update` based on `target`.\"\n        ),\n    ],\n    target: Annotated[\n        str,\n        typer.Option(\n            help=\"Database URL (SQLAlchemy connection string) to compare with `source`.\"\n        ),\n    ],\n    dry_run: Annotated[\n        bool,\n        typer.Option(help=\"Stop after comparing the databases, do NOT insert rows.\"),\n    ] = False,\n    scd: Annotated[\n        bool,\n        typer.Option(help=\"Sync the changes to the SCD tables.\"),\n    ] = False,\n    sync_tables: Annotated[\n        List[Tables],\n        typer.Option(help=\"Tables to be synced. Can be specified multiple times.\"),\n    ] = table_names,\n    log_changes_path: Annotated[\n        Path,\n        typer.Option(\n            help=\"Optional file path to log the list of new/updated/deleted records.\"\n        ),\n    ] = None,\n    log_changes_tables: Annotated[\n        List[Tables],\n        typer.Option(\n            help=\"New/updated/deleted rows of a table to be logged. Can be specified multiple times.\"\n        ),\n    ] = table_names,\n):\n    \"\"\"Sync a database to another one.\n\n    Hashing both the `source` and the `target` databases, then\n    comparing hashes and marking for syncing the following records:\n\n    - new (rows with primary keys found in `source`, but not found in `target`)\n\n    - update (rows with different values in `source` and in `target`).\n\n    - inactive (rows with primary keys found in `target`, but not found in `source`).\n\n    The records marked for syncing are written to the `target` database's\n    standard or SCD tables. When updating the SCD tables, the hashing still\n    happens on the standard tables/views, which are probably based on the\n    most recent records of the SCD tables.\n    \"\"\"\n\n    source_engine = create_engine(source, pool_pre_ping=True)\n    target_engine = create_engine(target, pool_pre_ping=True)\n\n    # compare source and target database revisions, halt if not matching\n    with source_engine.connect() as connection:\n        current_rev = get_revision(connection)\n    with target_engine.begin() as connection:\n        target_rev = get_revision(connection)\n    if current_rev != target_rev:\n        print(\n            \"Database revisions do NOT match, so not risking the sync. \"\n            \"Upgrade the database(s) before trying again!\"\n        )\n        raise typer.Exit(code=1)\n\n    ps = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    pt = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    g = Table.grid(padding=1)\n    g.add_row(\n        Panel(ps, title=\"Hashing source database\"),\n        Panel(pt, title=\"Hashing target database\"),\n    )\n\n    exclude_tables = [\n        t for t in tables if t.get_table_name() not in [t.value for t in sync_tables]\n    ]\n    with Live(g):\n        source_hash = hash_database(\n            source, level=HashLevels.ROW, progress=ps, exclude_tables=exclude_tables\n        )\n        target_hash = hash_database(\n            target, level=HashLevels.ROW, progress=pt, exclude_tables=exclude_tables\n        )\n    actions = {\n        k: {table: [] for table in source_hash.keys()}\n        for k in [\"update\", \"new\", \"deleted\"]\n    }\n\n    # enable logging\n    channel = ScRichHandler()\n    formatter = logging.Formatter(\"%(message)s\")\n    channel.setFormatter(formatter)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(channel)\n\n    ps = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    pt = Progress(\n        TimeElapsedColumn(),\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n    )\n    g = Table.grid(padding=1)\n    g.add_row(\n        Panel(ps, title=\"Comparing source database with target\"),\n        Panel(pt, title=\"Comparing target database with source\"),\n    )\n    with Live(g):\n        # compare new records with old\n        with Session(source_engine) as session:\n            tables_task_id = ps.add_task(\"Comparing tables\", total=len(source_hash))\n            for table_name, items in source_hash.items():\n                table_task_id = ps.add_task(table_name, total=len(items))\n                model = table_name_to_model(table_name)\n                for pks_json, item in items.items():\n                    action = None\n                    try:\n                        if item != target_hash[table_name][pks_json]:\n                            action = \"update\"\n                    except KeyError:\n                        action = \"new\"\n                    if action:\n                        # get the new version of the record from the\n                        # source database and store as JSON for future update\n                        obj = get_row_by_pk(session, model, loads(pks_json))\n                        actions[action][table_name].append(obj.model_dump())\n                    ps.update(table_task_id, advance=1)\n                ps.update(tables_task_id, advance=1)\n\n        # compare old records with new\n        with Session(target_engine) as session:\n            tables_task_id = pt.add_task(\"Comparing tables\", total=len(target_hash))\n            for table_name, items in target_hash.items():\n                table_task_id = pt.add_task(table_name, total=len(items))\n                model = table_name_to_model(table_name)\n                for key, _ in items.items():\n                    if key not in source_hash[table_name]:\n                        # check if the row was already set to INACTIVE\n                        obj = get_row_by_pk(session, model, loads(key)).model_dump()\n                        if obj[\"status\"] != Status.INACTIVE:\n                            obj[\"status\"] = Status.INACTIVE\n                            obj[\"observed_at\"] = datetime.utcnow()\n                            actions[\"deleted\"][table_name].append(obj)\n                    pt.update(table_task_id, advance=1)\n                pt.update(tables_task_id, advance=1)\n\n    stats = {ka: {ki: len(vi) for ki, vi in va.items()} for ka, va in actions.items()}\n    table = Table(title=\"Sync results\")\n    table.add_column(\"Table\", no_wrap=True)\n    table.add_column(\"New rows\", justify=\"right\")\n    table.add_column(\"Updated rows\", justify=\"right\")\n    table.add_column(\"Deleted rows\", justify=\"right\")\n    for table_name in source_hash.keys():\n        table.add_row(\n            table_name,\n            str(stats[\"new\"][table_name]),\n            str(stats[\"update\"][table_name]),\n            str(stats[\"deleted\"][table_name]),\n        )\n    console = Console()\n    console.print(table)\n\n    # log changes\n    if log_changes_path:\n        with open(log_changes_path, \"w\") as log_file:\n            for table_name, _ in source_hash.items():\n                if table_name in [t.value for t in log_changes_tables]:\n                    if (\n                        actions[\"new\"][table_name]\n                        or actions[\"update\"][table_name]\n                        or actions[\"deleted\"][table_name]\n                    ):\n                        model = table_name_to_model(table_name)\n                        pks = model.get_columns()[\"primary_keys\"]\n                        log_file.write(f\"\\n### {table_name}\\n\\n\")\n                        for action_types in [\"new\", \"update\", \"deleted\"]:\n                            for item in actions[action_types][table_name]:\n                                identifier = \"/\".join([item[key] for key in pks])\n                                log_file.write(\n                                    f\"- {action_types.title()}: {identifier}\\n\"\n                                )\n\n    if not dry_run:\n        progress = Progress(\n            TimeElapsedColumn(),\n            TextColumn(\"{task.description}\"),\n            BarColumn(),\n            MofNCompleteColumn(),\n        )\n        panel = Panel(progress, title=\"Updating target\", expand=False)\n        with Live(panel), Session(target_engine) as session:\n            for table_name, _ in source_hash.items():\n                model = table_name_to_model(table_name)\n                if scd:\n                    model = model.get_scd()\n                items = (\n                    actions[\"new\"][table_name]\n                    + actions[\"update\"][table_name]\n                    + actions[\"deleted\"][table_name]\n                )\n                if len(items):\n                    insert_items(model, items, session=session, progress=progress)\n                    logger.info(\"Updated %d %s(s) rows\" % (len(items), table_name))\n            session.commit()\n</code></pre>"},{"location":"reference/sc_crawler/cli/#sc_crawler.cli.pull","title":"pull","text":"<pre><code>pull(connection_string='sqlite:///sc-data-all.db', include_vendor=[v.vendor_id for v in supported_vendors], exclude_vendor=[], include_records=supported_records, exclude_records=[], log_level=LogLevels.INFO.value, cache=False, cache_ttl=60 * 24)\n</code></pre> <p>Pull data from available vendor APIs and store in a database.</p> <p>Vendor API calls are optionally cached as Pickle objects in <code>~/.cachier</code>.</p> Source code in <code>sc_crawler/cli.py</code> <pre><code>@cli.command()\ndef pull(\n    connection_string: options.connection_string = \"sqlite:///sc-data-all.db\",\n    include_vendor: Annotated[\n        List[Vendors],\n        typer.Option(help=\"Enabled data sources. Can be specified multiple times.\"),\n    ] = [v.vendor_id for v in supported_vendors],\n    exclude_vendor: Annotated[\n        List[Vendors],\n        typer.Option(help=\"Disabled data sources. Can be specified multiple times.\"),\n    ] = [],\n    include_records: Annotated[\n        List[Records],\n        typer.Option(\n            help=\"Database records to be updated. Can be specified multiple times.\"\n        ),\n    ] = supported_records,\n    exclude_records: Annotated[\n        List[Records],\n        typer.Option(\n            help=\"Database records NOT to be updated. Can be specified multiple times.\"\n        ),\n    ] = [],\n    log_level: Annotated[\n        LogLevels, typer.Option(help=\"Log level threshold.\")\n    ] = LogLevels.INFO.value,  # TODO drop .value after updating Enum to StrEnum in Python3.11\n    cache: Annotated[\n        bool,\n        typer.Option(help=\"Enable or disable caching of all vendor API calls on disk.\"),\n    ] = False,\n    cache_ttl: Annotated[\n        int,\n        typer.Option(help=\"Cache Time-to-live in minutes. Defaults to one day.\"),\n    ] = 60 * 24,  # 1 day\n):\n    \"\"\"\n    Pull data from available vendor APIs and store in a database.\n\n    Vendor API calls are optionally cached as Pickle objects in `~/.cachier`.\n    \"\"\"\n\n    def custom_serializer(x):\n        \"\"\"Use JSON serializer defined in custom objects.\"\"\"\n        return dumps(x, default=lambda x: x.__json__(), allow_nan=False)\n\n    # enable caching\n    if cache:\n        set_global_params(\n            caching_enabled=True,\n            stale_after=timedelta(minutes=cache_ttl),\n        )\n\n    # enable logging\n    channel = ScRichHandler()\n    formatter = logging.Formatter(\"%(message)s\")\n    channel.setFormatter(formatter)\n    logger.setLevel(log_level.value)\n    logger.addHandler(channel)\n\n    # filter vendors\n    vendors = [\n        vendor\n        for vendor in supported_vendors\n        if (\n            vendor.vendor_id in [iv.value for iv in include_vendor]\n            and vendor.vendor_id not in [ev.value for ev in exclude_vendor]\n        )\n    ]\n\n    # filter reocrds\n    records = [r for r in include_records if r not in exclude_records]\n\n    pbars = ProgressPanel()\n    with Live(pbars.panels):\n        # show CLI arguments in the Metadata panel\n        pbars.metadata.append(Text(\"Data sources: \", style=\"bold\"))\n        pbars.metadata.append(Text(\", \".join([x.vendor_id for x in vendors]) + \" \"))\n        pbars.metadata.append(Text(\"Updating records: \", style=\"bold\"))\n        pbars.metadata.append(Text(\", \".join([x.value for x in records]) + \"\\n\"))\n        pbars.metadata.append(Text(\"Connection type: \", style=\"bold\"))\n        pbars.metadata.append(Text(connection_string.split(\":\")[0]))\n        pbars.metadata.append(Text(\" Cache: \", style=\"bold\"))\n        if cache:\n            pbars.metadata.append(Text(\"Enabled (\" + str(cache_ttl) + \"m)\"))\n        else:\n            pbars.metadata.append(Text(\"Disabled\"))\n        pbars.metadata.append(Text(\" Time: \", style=\"bold\"))\n        pbars.metadata.append(Text(str(datetime.now())))\n\n        # alembic upgrade to ensure using the most recent version of the schemas\n        engine = create_engine(\n            connection_string,\n            json_serializer=custom_serializer,\n            pool_pre_ping=True,\n        )\n        with engine.begin() as connection:\n            command.upgrade(alembic_cfg(connection, force_logging=False), \"heads\")\n\n        with Session(engine) as session:\n            # add/merge static objects to database\n            for compliance_framework in compliance_frameworks.values():\n                session.merge(compliance_framework)\n            logger.info(\"%d Compliance Frameworks synced.\" % len(compliance_frameworks))\n            for country in countries.values():\n                session.merge(country)\n            logger.info(\"%d Countries synced.\" % len(countries))\n            for benchmark in benchmarks:\n                session.merge(benchmark)\n            logger.info(\"%d Benchmarks synced.\" % len(benchmarks))\n            # get data for each vendor and then add/merge to database\n            # TODO each vendor should open its own session and run in parallel\n            for vendor in vendors:\n                logger.info(\"Starting to collect data from vendor: \" + vendor.vendor_id)\n                vendor = session.merge(vendor)\n                # register session to the Vendor so that dependen objects can auto-merge\n                vendor.session = session\n                # register progress bars so that helpers can update\n                vendor.progress_tracker = VendorProgressTracker(\n                    vendor=vendor, progress_panel=pbars\n                )\n                vendor.progress_tracker.start_vendor(total=len(records))\n                if Records.compliance_frameworks in records:\n                    vendor.inventory_compliance_frameworks()\n                if Records.regions in records:\n                    vendor.inventory_regions()\n                if Records.zones in records:\n                    vendor.inventory_zones()\n                if Records.servers in records:\n                    vendor.inventory_servers()\n                if Records.server_prices in records:\n                    vendor.inventory_server_prices()\n                if Records.server_prices_spot in records:\n                    vendor.inventory_server_prices_spot()\n                if Records.storages in records:\n                    vendor.inventory_storages()\n                if Records.storage_prices in records:\n                    vendor.inventory_storage_prices()\n                if Records.traffic_prices in records:\n                    vendor.inventory_traffic_prices()\n                if Records.ipv4_prices in records:\n                    vendor.inventory_ipv4_prices()\n                # reset current step name\n                vendor.progress_tracker.update_vendor(step=\"\u2714\")\n                session.merge(vendor)\n                session.commit()\n\n        pbars.metadata.append(Text(\" - \" + str(datetime.now())))\n</code></pre>"},{"location":"reference/sc_crawler/insert/","title":"insert","text":""},{"location":"reference/sc_crawler/insert/#sc_crawler.insert","title":"sc_crawler.insert","text":""},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.can_bulk_insert","title":"can_bulk_insert","text":"<pre><code>can_bulk_insert(session)\n</code></pre> <p>Checks if bulk insert is supported for the engine dialect of a SQLModel session.</p> Source code in <code>sc_crawler/insert.py</code> <pre><code>def can_bulk_insert(session: Session) -&gt; bool:\n    \"\"\"Checks if bulk insert is supported for the engine dialect of a SQLModel session.\"\"\"\n    return is_sqlite(session) or is_postgresql(session)\n</code></pre>"},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.validate_items","title":"validate_items","text":"<pre><code>validate_items(model, items, vendor=None, prefix='')\n</code></pre> <p>Validates a list of items against a pydantic.BaseModel definition.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>An SQLModel model to be used for validation.</p> required <code>items</code> <code>List[dict]</code> <p>List of dictionaries to be checked against <code>model</code>.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional Vendor instance used for logging and progress bar updates.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional extra description for the model added in front of the model name in logs and progress bar updates.</p> <code>''</code> <p>Returns:</p> Type Description <code>List[dict]</code> <p>List of validated dicts in the same order. Note that missing fields has been filled in with default values (needed for bulk inserts).</p> Source code in <code>sc_crawler/insert.py</code> <pre><code>def validate_items(\n    model: BaseModel,\n    items: List[dict],\n    vendor: Optional[\"Vendor\"] = None,\n    prefix: str = \"\",\n) -&gt; List[dict]:\n    \"\"\"Validates a list of items against a [pydantic.BaseModel][] definition.\n\n    Args:\n        model: An SQLModel model to be used for validation.\n        items: List of dictionaries to be checked against `model`.\n        vendor: Optional Vendor instance used for logging and progress bar updates.\n        prefix: Optional extra description for the model added in front of\n            the model name in logs and progress bar updates.\n\n    Returns:\n        List of validated dicts in the same order. Note that missing fields\n            has been filled in with default values (needed for bulk inserts).\n    \"\"\"\n    model_name = model.get_table_name()\n    # use the Pydantic data model for validation instead of the table definition\n    schema = model.__validator__\n    if vendor:\n        vendor.progress_tracker.start_task(\n            name=f\"Validating {space_after(prefix)}{model_name}(s)\", total=len(items)\n        )\n    for i, item in enumerate(items):\n        items[i] = schema.model_validate(item).model_dump()\n        if vendor:\n            vendor.progress_tracker.advance_task()\n    if vendor:\n        vendor.progress_tracker.hide_task()\n        vendor.log(\n            \"%d %s%s(s) objects validated\"\n            % (len(items), space_after(prefix), model_name),\n            DEBUG,\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.bulk_insert_items","title":"bulk_insert_items","text":"<pre><code>bulk_insert_items(model, items, vendor=None, session=None, progress=None, prefix='')\n</code></pre> <p>Bulk inserts items into a SQLModel table with <code>ON CONFLICT</code> update.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>SQLModel</code> <p>An SQLModel table definition with primary key(s).</p> required <code>items</code> <code>List[dict]</code> <p>List of dicts with all columns of the model.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional related Vendor instance used for logging and progress bar updates.</p> <code>None</code> <code>session</code> <code>Optional[Session]</code> <p>Optional database connections. When not provided, defaults to the <code>vendor</code>'s session.</p> <code>None</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to use instead of <code>vendor</code>'s progress bar.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional extra description for the model added in front of the model name in logs and progress bar updates.</p> <code>''</code> Source code in <code>sc_crawler/insert.py</code> <pre><code>def bulk_insert_items(\n    model: SQLModel,\n    items: List[dict],\n    vendor: Optional[\"Vendor\"] = None,\n    session: Optional[Session] = None,\n    progress: Optional[Progress] = None,\n    prefix: str = \"\",\n):\n    \"\"\"Bulk inserts items into a SQLModel table with `ON CONFLICT` update.\n\n    Args:\n        model: An SQLModel table definition with primary key(s).\n        items: List of dicts with all columns of the model.\n        vendor: Optional related Vendor instance used for logging and progress bar updates.\n        session: Optional database connections. When not provided, defaults to the `vendor`'s session.\n        progress: Optional progress bar to use instead of `vendor`'s progress bar.\n        prefix: Optional extra description for the model added in front of\n            the model name in logs and progress bar updates.\n    \"\"\"\n    if session is None:\n        if vendor is None:\n            raise TypeError(\"At least one of `session` or `vendor` is required.\")\n        session = vendor.session\n    model_name = model.get_table_name()\n    columns = model.get_columns()\n    if progress:\n        pid = progress.add_task(\n            f\"Inserting {space_after(prefix)}{model_name}(s)\", total=len(items)\n        )\n    elif vendor:\n        pid = vendor.progress_tracker.start_task(\n            name=f\"Inserting {space_after(prefix)}{model_name}(s)\", total=len(items)\n        )\n        progress = vendor.progress_tracker.tasks\n    # need to split list into smaller chunks to avoid \"too many SQL variables\"\n    for chunk in chunk_list(items, 100):\n        if is_sqlite(session):\n            query = insert_sqlite(model).values(chunk)\n        elif is_postgresql(session):\n            query = insert_postgresql(model).values(chunk)\n        else:\n            raise NotImplementedError(\n                \"Unsupported database engine dialect for bulk inserts.\"\n            )\n        query = query.on_conflict_do_update(\n            index_elements=[getattr(model, c) for c in columns[\"primary_keys\"]],\n            set_={c: query.excluded[c] for c in columns[\"attributes\"]},\n        )\n        session.execute(query)\n        if progress:\n            progress.update(pid, advance=len(chunk))\n\n    if vendor:\n        vendor.progress_tracker.hide_task()\n        vendor.log(f\"{len(items)} {space_after(prefix)}{model_name}(s) synced.\")\n</code></pre>"},{"location":"reference/sc_crawler/insert/#sc_crawler.insert.insert_items","title":"insert_items","text":"<pre><code>insert_items(model, items, vendor=None, session=None, progress=None, prefix='')\n</code></pre> <p>Insert items into the related database table using bulk or merge.</p> <p>Bulk insert is only supported with SQLite, other databases fall back to the default session.merge (slower) approach.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>SQLModel</code> <p>An SQLModel table definition with primary key(s).</p> required <code>items</code> <code>List[dict]</code> <p>List of dicts with all columns of the model.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional related Vendor instance used for database connection, logging and progress bar updates.</p> <code>None</code> <code>session</code> <code>Optional[Session]</code> <p>Optional database connections. When not provided, defaults to the <code>vendor</code>'s session.</p> <code>None</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to use instead of <code>vendor</code>'s progress bar.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional extra description for the model added in front of the model name in logs and progress bar updates.</p> <code>''</code> Source code in <code>sc_crawler/insert.py</code> <pre><code>def insert_items(\n    model: SQLModel,\n    items: List[dict],\n    vendor: Optional[\"Vendor\"] = None,\n    session: Optional[Session] = None,\n    progress: Optional[Progress] = None,\n    prefix: str = \"\",\n):\n    \"\"\"Insert items into the related database table using bulk or merge.\n\n    Bulk insert is only supported with SQLite, other databases fall back to\n    the default session.merge (slower) approach.\n\n    Args:\n        model: An SQLModel table definition with primary key(s).\n        items: List of dicts with all columns of the model.\n        vendor: Optional related Vendor instance used for database connection, logging and progress bar updates.\n        session: Optional database connections. When not provided, defaults to the `vendor`'s session.\n        progress: Optional progress bar to use instead of `vendor`'s progress bar.\n        prefix: Optional extra description for the model added in front of\n            the model name in logs and progress bar updates.\n    \"\"\"\n    if session is None:\n        if vendor is None:\n            raise TypeError(\"At least one of `session` or `vendor` is required.\")\n        session = vendor.session\n    model_name = model.get_table_name()\n    if can_bulk_insert(session):\n        items = validate_items(model, items, vendor, prefix)\n        bulk_insert_items(model, items, vendor, session, progress, prefix)\n    else:\n        if vendor:\n            vendor.progress_tracker.start_task(\n                name=f\"Syncing {space_after(prefix)}{model_name}(s)\", total=len(items)\n            )\n        if progress:\n            pid = progress.add_task(\n                f\"Inserting {space_after(prefix)}{model_name}(s)\", total=len(items)\n            )\n        for item in items:\n            # vendor's auto session.merge doesn't work due to SQLmodel bug:\n            # - https://github.com/tiangolo/sqlmodel/issues/6\n            # - https://github.com/tiangolo/sqlmodel/issues/342\n            # so need to trigger the merge manually\n            session.merge(model.model_validate(item))\n            if vendor:\n                vendor.progress_tracker.advance_task()\n            if progress:\n                progress.update(pid, advance=1)\n        if vendor:\n            vendor.progress_tracker.hide_task()\n            vendor.log(f\"{len(items)} {space_after(prefix)}{model_name}(s) synced.\")\n</code></pre>"},{"location":"reference/sc_crawler/inspector/","title":"inspector","text":""},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector","title":"sc_crawler.inspector","text":""},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector.inspector_data_path","title":"inspector_data_path  <code>cached</code>","text":"<pre><code>inspector_data_path()\n</code></pre> <p>Download current inspector data into a temp folder.</p> Source code in <code>sc_crawler/inspector.py</code> <pre><code>@cache\ndef inspector_data_path() -&gt; str | PathLike:\n    \"\"\"Download current inspector data into a temp folder.\"\"\"\n    temp_dir = mkdtemp()\n    register(rmtree, temp_dir)\n    response = get(\n        \"https://github.com/SpareCores/sc-inspector-data/archive/refs/heads/main.zip\"\n    )\n    zip_path = path.join(temp_dir, \"downloaded.zip\")\n    with open(zip_path, \"wb\") as f:\n        f.write(response.content)\n    with ZipFile(zip_path, \"r\") as zip_ref:\n        zip_ref.extractall(temp_dir)\n    remove(zip_path)\n    return path.join(temp_dir, \"sc-inspector-data-main\", \"data\")\n</code></pre>"},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector.inspect_server_benchmarks","title":"inspect_server_benchmarks","text":"<pre><code>inspect_server_benchmarks(server)\n</code></pre> <p>Generate a list of BenchmarkScore-like dicts for the Server.</p> Source code in <code>sc_crawler/inspector.py</code> <pre><code>def inspect_server_benchmarks(server: \"Server\") -&gt; List[dict]:\n    \"\"\"Generate a list of BenchmarkScore-like dicts for the Server.\"\"\"\n    benchmarks = []\n\n    framework = \"bogomips\"\n    try:\n        benchmarks.append(\n            {\n                **_benchmark_metafields(\n                    server, framework=\"lscpu\", benchmark_id=framework\n                ),\n                \"score\": round(float(_server_lscpu_field(server, \"BogoMIPS:\"))),\n            }\n        )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e)\n\n    framework = \"bw_mem\"\n    try:\n        with open(_server_framework_stdout_path(server, framework), \"r\") as lines:\n            for line in lines:\n                # filter out error messages\n                if match(r\"^(rd|wr|rdwr) \\d+(\\.\\d+) \\d+(\\.\\d+)$\", line):\n                    row = line.strip().split()\n                    benchmarks.append(\n                        {\n                            **_benchmark_metafields(server, framework=framework),\n                            \"config\": {\"operation\": row[0], \"size\": float(row[1])},\n                            \"score\": float(row[2]),\n                        }\n                    )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e)\n\n    framework = \"compression_text\"\n    try:\n        algos = _server_framework_stdout_from_json(server, framework)\n        for algo, levels in algos.items():\n            for level, datas in levels.items():\n                for data in datas:\n                    config = {\n                        \"algo\": algo,\n                        \"compression_level\": None if level == \"null\" else int(level),\n                        \"threads\": data[\"threads\"],\n                    }\n                    if data.get(\"extra_args\", {}).get(\"block_size\"):\n                        config[\"block_size\"] = data[\"extra_args\"][\"block_size\"]\n                    for measurement in [\"ratio\", \"compress\", \"decompress\"]:\n                        if data[measurement]:\n                            benchmarks.append(\n                                {\n                                    **_benchmark_metafields(\n                                        server,\n                                        benchmark_id=\":\".join([framework, measurement]),\n                                    ),\n                                    \"config\": config,\n                                    \"score\": float(data[measurement]),\n                                }\n                            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"geekbench\"\n    try:\n        with open(_server_framework_path(server, framework, \"results.json\"), \"r\") as fp:\n            scores = json.load(fp)\n        geekbench_version = _server_framework_meta(server, framework)[\"version\"]\n        for cores, workloads in scores.items():\n            for workload, values in workloads.items():\n                workload_fields = {\n                    \"config\": {\"cores\": cores, \"framework_version\": geekbench_version},\n                    \"score\": float(values[\"score\"]),\n                }\n                if values.get(\"description\"):\n                    workload_fields[\"note\"] = values[\"description\"]\n                benchmarks.append(\n                    {\n                        **_benchmark_metafields(\n                            server,\n                            benchmark_id=\":\".join(\n                                [framework, sub(r\"\\W+\", \"_\", workload.lower())]\n                            ),\n                        ),\n                        **workload_fields,\n                    }\n                )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"passmark\"\n    try:\n        with open(_server_framework_stdout_path(server, framework), \"r\") as fp:\n            scores = yaml_safe_load(fp)\n        passmark_version = \".\".join(\n            [str(scores[\"Version\"][i]) for i in [\"Major\", \"Minor\", \"Build\"]]\n        )\n        for key, name in PASSMARK_MAPS.items():\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        benchmark_id=\":\".join(\n                            [framework, sub(r\"\\W+\", \"_\", name.lower())]\n                        ),\n                    ),\n                    \"config\": {\"framework_version\": passmark_version},\n                    \"score\": float(scores[\"Results\"][key]),\n                }\n            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"openssl\"\n    try:\n        with open(_server_framework_path(server, framework, \"parsed.json\"), \"r\") as fp:\n            workloads = json.load(fp)\n        openssl_version = _server_framework_meta(server, framework)[\"version\"]\n        for workload in workloads:\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(server, framework=framework),\n                    \"config\": {\n                        \"algo\": workload[\"algo\"],\n                        \"block_size\": workload[\"block_size\"],\n                        \"framework_version\": openssl_version,\n                    },\n                    \"score\": float(workload[\"speed\"]),\n                }\n            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"stress_ng\"\n    # TODO deprecate\n    try:\n        cores_per_path = {\"stressng\": server.vcpus, \"stressngsinglecore\": 1}\n        for cores_path in cores_per_path.keys():\n            stressng_version = _server_framework_meta(server, cores_path)[\"version\"]\n            line = _extract_line_from_file(\n                _server_framework_stderr_path(server, cores_path),\n                \"bogo-ops-per-second-real-time\",\n            )\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        framework=cores_path,\n                        benchmark_id=\":\".join([framework, \"cpu_all\"]),\n                    ),\n                    \"config\": {\n                        \"cores\": cores_per_path[cores_path],\n                        \"framework_version\": stressng_version,\n                    },\n                    \"score\": float(line.split(\": \")[1]),\n                }\n            )\n    except Exception:\n        # backfill with newer method - can be dropped once we deprecate stress_ng:cpu_all\n        try:\n            records = []\n            with open(\n                _server_framework_stdout_path(server, \"stressngfull\"), newline=\"\"\n            ) as f:\n                rows = csv.reader(f, quoting=csv.QUOTE_NONNUMERIC)\n                for row in rows:\n                    records.append(row)\n            for i in [0, len(records) - 1]:\n                stressng_version = _server_framework_meta(server, \"stressngfull\")[\n                    \"version\"\n                ]\n                benchmarks.append(\n                    {\n                        **_benchmark_metafields(\n                            server,\n                            framework=\"stressngfull\",\n                            benchmark_id=\":\".join([framework, \"cpu_all\"]),\n                        ),\n                        \"config\": {\n                            \"cores\": records[i][0],\n                            \"framework_version\": stressng_version,\n                        },\n                        \"score\": records[i][1],\n                    }\n                )\n        except Exception as e:\n            _log_cannot_load_benchmarks(server, framework, e, True)\n\n    workload = \"div16\"\n    try:\n        records = []\n        with open(\n            _server_framework_stdout_path(server, \"stressngfull\"), newline=\"\"\n        ) as f:\n            rows = csv.reader(f, quoting=csv.QUOTE_NONNUMERIC)\n            for row in rows:\n                records.append(row)\n        for record in records:\n            stressng_version = _server_framework_meta(server, \"stressngfull\")[\"version\"]\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        framework=\"stressngfull\",\n                        benchmark_id=\":\".join([framework, workload]),\n                    ),\n                    \"config\": {\n                        \"cores\": record[0],\n                        \"framework_version\": stressng_version,\n                    },\n                    \"score\": record[1],\n                }\n            )\n        # best single and multi core performance\n        bests = {\"best1\": records[0][1], \"bestn\": max([r[1] for r in records])}\n        for k, v in bests.items():\n            benchmarks.append(\n                {\n                    **_benchmark_metafields(\n                        server,\n                        framework=\"stressngfull\",\n                        benchmark_id=\":\".join([framework, k]),\n                    ),\n                    \"config\": {\n                        \"framework_version\": stressng_version,\n                    },\n                    \"score\": v,\n                }\n            )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    for framework in SERVER_CLIENT_FRAMEWORK_MAPS.keys():\n        try:\n            versions = _server_framework_meta(server, framework)[\"version\"]\n            # drop the build number at the end of the redis server version\n            if framework == \"redis\":\n                versions = sub(r\" build=[a-zA-Z0-9]+\", \"\", versions)\n\n            records = []\n            with open(\n                _server_framework_stdout_path(server, framework), newline=\"\"\n            ) as f:\n                rows = csv.DictReader(f, quoting=csv.QUOTE_NONNUMERIC)\n                for row in rows:\n                    if \"connections\" in row.keys():\n                        row[\"connections_per_vcpus\"] = row[\"connections\"] / server.vcpus\n                    records.append(row)\n\n            framework_config = SERVER_CLIENT_FRAMEWORK_MAPS[framework]\n            keys = framework_config[\"keys\"]\n            measurements = framework_config[\"measurements\"]\n\n            # don't care about threads, keep the records with the highest rps\n            records = sorted(records, key=lambda x: (*[x[k] for k in keys], -x[\"rps\"]))\n            records = groupby(records, key=itemgetter(*keys))\n            records = [next(group) for _, group in records]\n\n            for record in records:\n                for measurement in measurements:\n                    score_field = measurement.split(\"-\")[0]\n                    if score_field == \"throughput\":\n                        score_field = \"rps\"\n                    score = record[score_field]\n                    server_usrsys = record[\"server_usr\"] + record[\"server_sys\"]\n                    client_usrsys = record[\"client_usr\"] + record[\"client_sys\"]\n                    note = (\n                        \"CPU usage (server/client usr+sys): \"\n                        f\"{round(server_usrsys, 4)}/{round(client_usrsys, 4)}.\"\n                    )\n                    if measurement.endswith(\"-extrapolated\"):\n                        note += f\" Original RPS: {score}.\"\n                        score = round(\n                            score / server_usrsys * (server_usrsys + client_usrsys), 2\n                        )\n                    if measurement.startswith(\"throughput\"):\n                        # drop the \"k\" suffix and multiply by 1024\n                        size = int(record[\"size\"][:-1]) * 1024\n                        score = score * size\n                    benchmarks.append(\n                        {\n                            **_benchmark_metafields(\n                                server,\n                                framework=framework,\n                                benchmark_id=\":\".join([framework, measurement]),\n                            ),\n                            \"config\": {\n                                **{k: record[k] for k in keys},\n                                \"framework_version\": versions,\n                            },\n                            \"score\": score,\n                            \"note\": note,\n                        }\n                    )\n        except Exception as e:\n            _log_cannot_load_benchmarks(server, framework, e, True)\n\n    framework = \"llm_speed\"\n    try:\n        assert _server_framework_meta(server, \"llm\")[\"exit_code\"] == 0\n        llm_speed_version = _server_framework_meta(server, \"llm\")[\"version\"]\n        with open(_server_framework_stdout_path(server, \"llm\"), \"r\") as fp:\n            for line in fp:\n                record = json.loads(line)\n                model_name = path.basename(record.get(\"model_filename\", \"unknown\"))\n                measurement = \"text_generation\"\n                if record.get(\"n_prompt\") != 0:\n                    measurement = \"prompt_processing\"\n                tokens = record.get(\"n_prompt\") + record.get(\"n_gen\")\n                config = {\n                    \"model\": model_name,\n                    \"tokens\": tokens,\n                    \"framework_version\": llm_speed_version,\n                }\n                benchmarks.append(\n                    {\n                        **_benchmark_metafields(\n                            server,\n                            framework=\"llm\",\n                            benchmark_id=\":\".join([framework, measurement]),\n                        ),\n                        \"config\": config,\n                        \"score\": float(record[\"avg_ts\"]),\n                    }\n                )\n    except Exception as e:\n        _log_cannot_load_benchmarks(server, framework, e, True)\n\n    return benchmarks\n</code></pre>"},{"location":"reference/sc_crawler/inspector/#sc_crawler.inspector.inspect_update_server_dict","title":"inspect_update_server_dict","text":"<pre><code>inspect_update_server_dict(server)\n</code></pre> <p>Update a Server-like dict based on inspector data.</p> Source code in <code>sc_crawler/inspector.py</code> <pre><code>def inspect_update_server_dict(server: dict) -&gt; dict:\n    \"\"\"Update a Server-like dict based on inspector data.\"\"\"\n    server_obj = ServerBase.validate(server)\n\n    lookups = {\n        \"dmidecode_cpu\": lambda: _server_dmidecode_section(\n            server_obj, \"Processor Information\"\n        ),\n        \"dmidecode_cpus\": lambda: _server_dmidecode_sections(\n            server_obj, \"Processor Information\"\n        ),\n        \"dmidecode_memory\": lambda: _server_dmidecode_section(\n            server_obj, \"Memory Device\"\n        ),\n        \"lscpu\": lambda: _server_lscpu(server_obj),\n        \"nvidiasmi\": lambda: _server_nvidiasmi(server_obj),\n        \"gpu\": lambda: lookups[\"nvidiasmi\"].find(\"gpu\"),\n        \"gpus\": lambda: lookups[\"nvidiasmi\"].findall(\"gpu\"),\n    }\n    for k, f in lookups.items():\n        try:\n            lookups[k] = f()\n        except Exception as e:\n            lookups[k] = Exception(str(e))\n\n    def lscpu_lookup(field: str):\n        return _listsearch(lookups[\"lscpu\"], \"field\", field)[\"data\"]\n\n    mappings = {\n        \"cpu_cores\": lambda: (\n            int(lscpu_lookup(\"Core(s) per socket:\")) * int(lscpu_lookup(\"Socket(s):\"))\n        ),\n        # use 1st CPU's speed, convert to Ghz\n        \"cpu_speed\": lambda: lookups[\"dmidecode_cpu\"][\"Max Speed\"] / 1e9,\n        \"cpu_manufacturer\": lambda: _standardize_manufacturer(\n            lookups[\"dmidecode_cpu\"][\"Manufacturer\"]\n        ),\n        \"cpu_family\": lambda: _standardize_cpu_family(\n            lookups[\"dmidecode_cpu\"][\"Family\"]\n        ),\n        \"cpu_model\": lambda: _standardize_cpu_model(\n            lookups[\"dmidecode_cpu\"][\"Version\"]\n        ),\n        \"cpu_l1_cache\": lambda: _l123_cache(lookups[\"lscpu\"], 1),\n        \"cpu_l2_cache\": lambda: _l123_cache(lookups[\"lscpu\"], 2),\n        \"cpu_l3_cache\": lambda: _l123_cache(lookups[\"lscpu\"], 3),\n        \"cpu_flags\": lambda: lscpu_lookup(\"Flags:\").split(\" \"),\n        \"memory_generation\": lambda: DdrGeneration[lookups[\"dmidecode_memory\"][\"Type\"]],\n        # convert to Mhz\n        \"memory_speed\": lambda: int(lookups[\"dmidecode_memory\"][\"Speed\"]) / 1e6,\n        \"gpus\": lambda: _gpus_details(lookups[\"gpus\"]),\n        \"gpu_manufacturer\": lambda: _gpu_most_common(server[\"gpus\"], \"manufacturer\"),\n        \"gpu_family\": lambda: _gpu_most_common(server[\"gpus\"], \"family\"),\n        \"gpu_model\": lambda: _gpu_most_common(server[\"gpus\"], \"model\"),\n        # skip update if there is no HW-inspected GPU info\n        \"gpu_count\": lambda: len(server[\"gpus\"]) if len(server[\"gpus\"]) else None,\n        \"gpu_memory_min\": lambda: min([gpu[\"memory\"] for gpu in server[\"gpus\"]]),\n        \"gpu_memory_total\": lambda: sum([gpu[\"memory\"] for gpu in server[\"gpus\"]]),\n    }\n    for k, f in mappings.items():\n        try:\n            newval = f()\n            if newval:\n                server[k] = newval\n        except Exception as e:\n            _log_cannot_update_server(server_obj, k, e)\n\n    # lscpu is a more reliable data source than dmidecode\n    if not isinstance(lookups[\"lscpu\"], BaseException):\n        cpu_model = lscpu_lookup(\"Model name:\")\n        # CPU speed seems to be unreliable as reported by dmidecode,\n        # e.g. it's 2Ghz in GCP for all instances\n        speed = search(r\" @ ([0-9\\.]*)GHz$\", cpu_model)\n        if speed:\n            server[\"cpu_speed\"] = speed.group(1)\n        # manufacturer data might be more likely to present in lscpu (unstructured)\n        for manufacturer in [\"Intel\", \"AMD\"]:\n            if manufacturer in cpu_model:\n                server[\"cpu_manufacturer\"] = manufacturer\n        for family in [\"Xeon\", \"EPYC\"]:\n            if family in cpu_model:\n                server[\"cpu_family\"] = family\n        model = _standardize_cpu_model(cpu_model)\n        if model:\n            server[\"cpu_model\"] = model\n\n    # 2 Ghz CPU speed at Google is a lie\n    if server[\"vendor_id\"] == \"gcp\" and server.get(\"cpu_speed\") == 2:\n        server[\"cpu_speed\"] = None\n\n    # standardize GPU model\n    if server.get(\"gpu_model\"):\n        server[\"gpu_model\"] = _standardize_gpu_model(server[\"gpu_model\"], server)\n        server[\"gpu_family\"] = _standardize_gpu_family(server)\n        if not server.get(\"gpu_manufacturer\") and server[\"gpu_model\"] == \"A100\":\n            server[\"gpu_manufacturer\"] = \"NVIDIA\"\n\n    return server\n</code></pre>"},{"location":"reference/sc_crawler/logger/","title":"logger","text":""},{"location":"reference/sc_crawler/logger/#sc_crawler.logger","title":"sc_crawler.logger","text":""},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.log_start_end","title":"log_start_end","text":"<pre><code>log_start_end(func)\n</code></pre> <p>Log the start and end of the decorated function.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def log_start_end(func):\n    \"\"\"Log the start and end of the decorated function.\"\"\"\n\n    def wrap(*args, **kwargs):\n        # log start of the step\n        try:\n            self = args[0]\n            fname = f\"{self.vendor_id}/{func.__name__}\"\n        except Exception:\n            fname = func.__name__\n        logger.debug(\"Starting %s\", fname)\n\n        # update Vendor's progress bar with the step name\n        try:\n            self.progress_tracker.update_vendor(\n                # drop `inventory_` prefix and prettify\n                step=func.__name__[10:].replace(\"_\", \" \")\n            )\n        except Exception:\n            logger.error(\"Cannot update step name in the Vendor's progress bar.\")\n\n        # actually run step\n        result = func(*args, **kwargs)\n\n        # increment Vendor's progress bar\n        self.progress_tracker.advance_vendor()\n\n        # log end of the step and return\n        logger.debug(\"Finished %s\", fname)\n        return result\n\n    return wrap\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.ScRichHandler","title":"ScRichHandler","text":"<p>               Bases: <code>RichHandler</code></p> <p>Extend RichHandler with function name logged in the right column.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>class ScRichHandler(RichHandler):\n    \"\"\"Extend RichHandler with function name logged in the right column.\"\"\"\n\n    def render(\n        self,\n        *,\n        record: logging.LogRecord,\n        traceback: Optional[Traceback],\n        message_renderable: \"ConsoleRenderable\",\n    ):\n        path = Path(record.pathname).name + \":\" + record.funcName\n        level = self.get_level_text(record)\n        time_format = None if self.formatter is None else self.formatter.datefmt\n        log_time = datetime.fromtimestamp(record.created)\n\n        log_renderable = self._log_render(\n            self.console,\n            [message_renderable] if not traceback else [message_renderable, traceback],\n            log_time=log_time,\n            time_format=time_format,\n            level=level,\n            path=path,\n            line_no=record.lineno,\n            link_path=record.pathname if self.enable_link_path else None,\n        )\n        return log_renderable\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker","title":"VendorProgressTracker","text":"<p>Tracking the progress of the vendor's inventory updates.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>class VendorProgressTracker:\n    \"\"\"Tracking the progress of the vendor's inventory updates.\"\"\"\n\n    vendor: Vendor\n    \"\"\"A [sc_crawler.tables.Vendor][] instance for which tracking progress.\"\"\"\n    progress_panel: ProgressPanel\n    \"\"\"\n    A `rich` panel including progress bars.\n    Should not be used directly, see the `vendors`, `tasks` and `metadata` attributes.\n    \"\"\"\n    # reexport Progress attributes of the ProgressPanel\n    vendors: Progress\n    \"\"\"[rich.progress.Progress][] for tracking the inventory steps of the vendor.\"\"\"\n    tasks: Progress\n    \"\"\"[rich.progress.Progress][] for tracking the lower-level tasks within each step.\"\"\"\n    metadata: Text\n    \"\"\"[rich.text.Text][] metadata, e.g. data sources and records to be udpated.\"\"\"\n    task_ids: List[TaskID] = []\n    \"\"\"List of active task ids for the current `vendor`.\"\"\"\n\n    def __init__(self, vendor: Vendor, progress_panel: ProgressPanel):\n        self.vendor = vendor\n        self.progress_panel = progress_panel\n        self.vendors = progress_panel.vendors\n        self.tasks = progress_panel.tasks\n        self.metadata = progress_panel.metadata\n\n    def start_vendor(self, total: int) -&gt; TaskID:\n        \"\"\"Starts a progress bar for the Vendor's steps.\n\n        Args:\n            total: Overall number of steps to show in the progress bar.\n\n        Returns:\n            TaskId: The progress bar's identifier to be referenced in future updates.\n        \"\"\"\n        return self.vendors.add_task(self.vendor.name, total=total, step=\"\")\n\n    def advance_vendor(self, advance: int = 1) -&gt; None:\n        \"\"\"Increment the number of finished steps.\n\n        Args:\n            advance: Number of steps to advance.\n        \"\"\"\n        self.vendors.update(self.vendors.task_ids[-1], advance=advance)\n\n    def update_vendor(self, **kwargs) -&gt; None:\n        \"\"\"Update the vendor's progress bar.\n\n        Useful fields:\n        - `step`: Name of the currently running step to be shown on the progress bar.\n        \"\"\"\n        self.vendors.update(self.vendors.task_ids[-1], **kwargs)\n\n    def start_task(self, name: str, total: int) -&gt; TaskID:\n        \"\"\"Starts a progress bar in the list of current jobs.\n\n        Besides returning the `TaskID`, it will also register in `self.tasks.task_ids`\n        as the last task, which will be the default value for future `advance_task`,\n        `hide_task` etc calls. The latter will remove the `TaskID` from the `task_ids`.\n\n        Args:\n            name: Name to show in front of the progress bar. Will be prefixed by Vendor's name.\n            total: Overall number of steps to show in the progress bar.\n\n        Returns:\n            TaskId: The progress bar's identifier to be referenced in future updates.\n        \"\"\"\n        self.task_ids.append(\n            self.tasks.add_task(self.vendor.name + \": \" + name, total=total)\n        )\n        return self.last_task()\n\n    def last_task(self) -&gt; TaskID:\n        \"\"\"Returh the last registered TaskID.\"\"\"\n        return self.task_ids[-1]\n\n    def advance_task(self, task_id: Optional[TaskID] = None, advance: int = 1):\n        \"\"\"Increment the number of finished steps.\n\n        Args:\n            task_id: The progress bar's identifier returned by `start_task`.\n                Defaults to the most recently created task.\n            advance: Number of steps to advance.\n        \"\"\"\n\n        self.tasks.update(task_id or self.last_task(), advance=advance)\n\n    def update_task(self, task_id: Optional[TaskID] = None, **kwargs) -&gt; None:\n        \"\"\"Update the task's progress bar.\n\n        Args:\n            task_id: The progress bar's identifier returned by `start_task`.\n                Defaults to the most recently created task.\n\n        Keyword Args:\n            step (str): Name of the currently running step to be shown on the progress bar.\n\n        See [`rich.progress.Progress.update`][] for further keyword arguments.\n        \"\"\"\n        self.tasks.update(task_id or self.last_task(), **kwargs)\n\n    def hide_task(self, task_id: Optional[TaskID] = None):\n        \"\"\"Hide a task from the list of progress bars.\n\n        Args:\n            task_id: The progress bar's identifier returned by `start_task`.\n                Defaults to the most recently created task.\n        \"\"\"\n        self.tasks.update(task_id or self.last_task(), visible=False)\n        self.task_ids.pop()\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.task_ids","title":"task_ids  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>task_ids = []\n</code></pre> <p>List of active task ids for the current <code>vendor</code>.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.vendor","title":"vendor  <code>instance-attribute</code>","text":"<pre><code>vendor = vendor\n</code></pre> <p>A sc_crawler.tables.Vendor instance for which tracking progress.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.progress_panel","title":"progress_panel  <code>instance-attribute</code>","text":"<pre><code>progress_panel = progress_panel\n</code></pre> <p>A <code>rich</code> panel including progress bars. Should not be used directly, see the <code>vendors</code>, <code>tasks</code> and <code>metadata</code> attributes.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.vendors","title":"vendors  <code>instance-attribute</code>","text":"<pre><code>vendors = vendors\n</code></pre> <p>rich.progress.Progress for tracking the inventory steps of the vendor.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.tasks","title":"tasks  <code>instance-attribute</code>","text":"<pre><code>tasks = tasks\n</code></pre> <p>rich.progress.Progress for tracking the lower-level tasks within each step.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata = metadata\n</code></pre> <p>rich.text.Text metadata, e.g. data sources and records to be udpated.</p>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.start_vendor","title":"start_vendor","text":"<pre><code>start_vendor(total)\n</code></pre> <p>Starts a progress bar for the Vendor's steps.</p> <p>Parameters:</p> Name Type Description Default <code>total</code> <code>int</code> <p>Overall number of steps to show in the progress bar.</p> required <p>Returns:</p> Name Type Description <code>TaskId</code> <code>TaskID</code> <p>The progress bar's identifier to be referenced in future updates.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def start_vendor(self, total: int) -&gt; TaskID:\n    \"\"\"Starts a progress bar for the Vendor's steps.\n\n    Args:\n        total: Overall number of steps to show in the progress bar.\n\n    Returns:\n        TaskId: The progress bar's identifier to be referenced in future updates.\n    \"\"\"\n    return self.vendors.add_task(self.vendor.name, total=total, step=\"\")\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.advance_vendor","title":"advance_vendor","text":"<pre><code>advance_vendor(advance=1)\n</code></pre> <p>Increment the number of finished steps.</p> <p>Parameters:</p> Name Type Description Default <code>advance</code> <code>int</code> <p>Number of steps to advance.</p> <code>1</code> Source code in <code>sc_crawler/logger.py</code> <pre><code>def advance_vendor(self, advance: int = 1) -&gt; None:\n    \"\"\"Increment the number of finished steps.\n\n    Args:\n        advance: Number of steps to advance.\n    \"\"\"\n    self.vendors.update(self.vendors.task_ids[-1], advance=advance)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.update_vendor","title":"update_vendor","text":"<pre><code>update_vendor(**kwargs)\n</code></pre> <p>Update the vendor's progress bar.</p> <p>Useful fields: - <code>step</code>: Name of the currently running step to be shown on the progress bar.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def update_vendor(self, **kwargs) -&gt; None:\n    \"\"\"Update the vendor's progress bar.\n\n    Useful fields:\n    - `step`: Name of the currently running step to be shown on the progress bar.\n    \"\"\"\n    self.vendors.update(self.vendors.task_ids[-1], **kwargs)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.start_task","title":"start_task","text":"<pre><code>start_task(name, total)\n</code></pre> <p>Starts a progress bar in the list of current jobs.</p> <p>Besides returning the <code>TaskID</code>, it will also register in <code>self.tasks.task_ids</code> as the last task, which will be the default value for future <code>advance_task</code>, <code>hide_task</code> etc calls. The latter will remove the <code>TaskID</code> from the <code>task_ids</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to show in front of the progress bar. Will be prefixed by Vendor's name.</p> required <code>total</code> <code>int</code> <p>Overall number of steps to show in the progress bar.</p> required <p>Returns:</p> Name Type Description <code>TaskId</code> <code>TaskID</code> <p>The progress bar's identifier to be referenced in future updates.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def start_task(self, name: str, total: int) -&gt; TaskID:\n    \"\"\"Starts a progress bar in the list of current jobs.\n\n    Besides returning the `TaskID`, it will also register in `self.tasks.task_ids`\n    as the last task, which will be the default value for future `advance_task`,\n    `hide_task` etc calls. The latter will remove the `TaskID` from the `task_ids`.\n\n    Args:\n        name: Name to show in front of the progress bar. Will be prefixed by Vendor's name.\n        total: Overall number of steps to show in the progress bar.\n\n    Returns:\n        TaskId: The progress bar's identifier to be referenced in future updates.\n    \"\"\"\n    self.task_ids.append(\n        self.tasks.add_task(self.vendor.name + \": \" + name, total=total)\n    )\n    return self.last_task()\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.last_task","title":"last_task","text":"<pre><code>last_task()\n</code></pre> <p>Returh the last registered TaskID.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def last_task(self) -&gt; TaskID:\n    \"\"\"Returh the last registered TaskID.\"\"\"\n    return self.task_ids[-1]\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.advance_task","title":"advance_task","text":"<pre><code>advance_task(task_id=None, advance=1)\n</code></pre> <p>Increment the number of finished steps.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>Optional[TaskID]</code> <p>The progress bar's identifier returned by <code>start_task</code>. Defaults to the most recently created task.</p> <code>None</code> <code>advance</code> <code>int</code> <p>Number of steps to advance.</p> <code>1</code> Source code in <code>sc_crawler/logger.py</code> <pre><code>def advance_task(self, task_id: Optional[TaskID] = None, advance: int = 1):\n    \"\"\"Increment the number of finished steps.\n\n    Args:\n        task_id: The progress bar's identifier returned by `start_task`.\n            Defaults to the most recently created task.\n        advance: Number of steps to advance.\n    \"\"\"\n\n    self.tasks.update(task_id or self.last_task(), advance=advance)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.update_task","title":"update_task","text":"<pre><code>update_task(task_id=None, **kwargs)\n</code></pre> <p>Update the task's progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>Optional[TaskID]</code> <p>The progress bar's identifier returned by <code>start_task</code>. Defaults to the most recently created task.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>step</code> <code>str</code> <p>Name of the currently running step to be shown on the progress bar.</p> <p>See <code>rich.progress.Progress.update</code> for further keyword arguments.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>def update_task(self, task_id: Optional[TaskID] = None, **kwargs) -&gt; None:\n    \"\"\"Update the task's progress bar.\n\n    Args:\n        task_id: The progress bar's identifier returned by `start_task`.\n            Defaults to the most recently created task.\n\n    Keyword Args:\n        step (str): Name of the currently running step to be shown on the progress bar.\n\n    See [`rich.progress.Progress.update`][] for further keyword arguments.\n    \"\"\"\n    self.tasks.update(task_id or self.last_task(), **kwargs)\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VendorProgressTracker.hide_task","title":"hide_task","text":"<pre><code>hide_task(task_id=None)\n</code></pre> <p>Hide a task from the list of progress bars.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>Optional[TaskID]</code> <p>The progress bar's identifier returned by <code>start_task</code>. Defaults to the most recently created task.</p> <code>None</code> Source code in <code>sc_crawler/logger.py</code> <pre><code>def hide_task(self, task_id: Optional[TaskID] = None):\n    \"\"\"Hide a task from the list of progress bars.\n\n    Args:\n        task_id: The progress bar's identifier returned by `start_task`.\n            Defaults to the most recently created task.\n    \"\"\"\n    self.tasks.update(task_id or self.last_task(), visible=False)\n    self.task_ids.pop()\n</code></pre>"},{"location":"reference/sc_crawler/logger/#sc_crawler.logger.VoidProgressTracker","title":"VoidProgressTracker","text":"<p>               Bases: <code>VendorProgressTracker</code></p> <p>Progress tracker reference not doing antyhing.</p> Source code in <code>sc_crawler/logger.py</code> <pre><code>class VoidProgressTracker(VendorProgressTracker):\n    \"\"\"Progress tracker reference not doing antyhing.\"\"\"\n\n    def __init__(*args, **kwargs):\n        pass\n\n    def start_vendor(self, *args, **kwargs):\n        pass\n\n    def advance_vendor(self, *args, **kwargs):\n        pass\n\n    def update_vendor(self, *args, **kwargs):\n        pass\n\n    def start_task(self, *args, **kwargs):\n        pass\n\n    def last_task(self, *args, **kwargs):\n        pass\n\n    def advance_task(self, *args, **kwargs):\n        pass\n\n    def update_task(self, *args, **kwargs):\n        pass\n\n    def hide_task(self, *args, **kwargs):\n        pass\n</code></pre>"},{"location":"reference/sc_crawler/lookup/","title":"lookup","text":""},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup","title":"sc_crawler.lookup","text":""},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup.countries","title":"countries  <code>module-attribute</code>","text":"<pre><code>countries = {k: Country(country_id=k, continent=v)for (k, v) in items()}\n</code></pre> <p>Dictionary of sc_crawler.tables.Country instances keyed by the <code>country_id</code>.</p>"},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup.compliance_frameworks","title":"compliance_frameworks  <code>module-attribute</code>","text":"<pre><code>compliance_frameworks = {'hipaa': ComplianceFramework(compliance_framework_id='hipaa', name='The Health Insurance Portability and Accountability Act', abbreviation='HIPAA', description=\"HIPAA (Health Insurance Portability and Accountability Act) is a U.S. federal law designed to safeguard the privacy and security of individuals' health information, establishing standards for its protection and regulating its use in the healthcare industry.\", homepage='https://www.cdc.gov/phlp/publications/topic/hipaa.html'), 'soc2t2': ComplianceFramework(compliance_framework_id='soc2t2', name='System and Organization Controls Level 2 Type 2', abbreviation='SOC 2 Type 2', description=\"SOC 2 Type 2 is a framework for assessing and certifying the effectiveness of a service organization's information security policies and procedures over time, emphasizing the operational aspects and ongoing monitoring of controls.\", homepage='https://www.aicpa-cima.com/topic/audit-assurance/audit-and-assurance-greater-than-soc-2'), 'iso27001': ComplianceFramework(compliance_framework_id='iso27001', name='ISO/IEC 27001', abbreviation='ISO 27001', description='ISO 27001 is standard for information security management systems.', homepage='https://www.iso.org/standard/27001')}\n</code></pre> <p>Dictionary of sc_crawler.tables.ComplianceFramework instances keyed by the <code>compliance_framework_id</code>.</p>"},{"location":"reference/sc_crawler/lookup/#sc_crawler.lookup.map_compliance_frameworks_to_vendor","title":"map_compliance_frameworks_to_vendor","text":"<pre><code>map_compliance_frameworks_to_vendor(vendor_id, compliance_framework_ids)\n</code></pre> <p>Map compliance frameworks to vendors in a dict.</p> <p>Parameters:</p> Name Type Description Default <code>vendor_id</code> <code>str</code> <p>identifier of a Vendor</p> required <code>compliance_framework_ids</code> <code>List[str]</code> <p>identifier(s) of <code>ComplianceFramework</code></p> required <p>Returns:</p> Type Description <code>dict</code> <p>Array of dictionaroes that can be passed to sc_crawler.insert.insert_items.</p> Source code in <code>sc_crawler/lookup.py</code> <pre><code>def map_compliance_frameworks_to_vendor(\n    vendor_id: str, compliance_framework_ids: List[str]\n) -&gt; dict:\n    \"\"\"Map compliance frameworks to vendors in a dict.\n\n    Args:\n        vendor_id: identifier of a [Vendor][sc_crawler.tables.Vendor]\n        compliance_framework_ids: identifier(s) of [`ComplianceFramework`][sc_crawler.tables.ComplianceFramework]\n\n    Returns:\n        Array of dictionaroes that can be passed to [sc_crawler.insert.insert_items][].\n    \"\"\"\n    items = []\n    for compliance_framework_id in compliance_framework_ids:\n        items.append(\n            {\n                \"vendor_id\": vendor_id,\n                \"compliance_framework_id\": compliance_framework_id,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/","title":"str_utils","text":""},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils","title":"sc_crawler.str_utils","text":""},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.wrap","title":"wrap","text":"<pre><code>wrap(text, before=' ', after=' ')\n</code></pre> <p>Wrap string between before/after strings (default to spaces) if not empty.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>A string.</p> required <code>before</code> <code>str</code> <p>Characters to be added before the <code>text</code>.</p> <code>' '</code> <code>after</code> <code>str</code> <p>Characters to be added after the <code>text</code>.</p> <code>' '</code> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def wrap(text: str, before: str = \" \", after: str = \" \") -&gt; str:\n    \"\"\"Wrap string between before/after strings (default to spaces) if not empty.\n\n    Args:\n        text: A string.\n        before: Characters to be added before the `text`.\n        after: Characters to be added after the `text`.\n    \"\"\"\n    return text if text == \"\" else before + text + after\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.space_after","title":"space_after","text":"<pre><code>space_after(text)\n</code></pre> <p>Add space after string if not empty.</p> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def space_after(text: str) -&gt; str:\n    \"\"\"Add space after string if not empty.\"\"\"\n    return wrap(text, before=\"\")\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.snake_case","title":"snake_case","text":"<pre><code>snake_case(text)\n</code></pre> <p>Convert CamelCase to snake_case.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>A CamelCase text.</p> required <p>Returns:</p> Type Description <code>str</code> <p>snake_case version of the text.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; snake_case('DescriptionToComment')\n'description_to_comment'\n</code></pre> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def snake_case(text: str) -&gt; str:\n    \"\"\"Convert CamelCase to snake_case.\n\n    Args:\n        text: A CamelCase text.\n\n    Returns:\n        snake_case version of the text.\n\n    Examples:\n        &gt;&gt;&gt; snake_case('DescriptionToComment')\n        'description_to_comment'\n    \"\"\"\n    return \"_\".join(sub(\"([A-Z][a-z]+)\", r\" \\1\", text).split()).lower()\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.plural","title":"plural","text":"<pre><code>plural(text)\n</code></pre> <p>Super basic implementation of pluralizing an English word.</p> <p>Note that grammar exceptions are not handled, so better to use a proper NLP method for real use-cases.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>A singular noun.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plural form of the noun.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; plural('dog')\n'dogs'\n&gt;&gt;&gt; plural('boy') # :facepalm:\n'boies'\n</code></pre> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def plural(text: str) -&gt; str:\n    \"\"\"Super basic implementation of pluralizing an English word.\n\n    Note that grammar exceptions are not handled, so better to use a\n    proper NLP method for real use-cases.\n\n    Args:\n        text: A singular noun.\n\n    Returns:\n        Plural form of the noun.\n\n    Examples:\n        &gt;&gt;&gt; plural('dog')\n        'dogs'\n        &gt;&gt;&gt; plural('boy') # :facepalm:\n        'boies'\n    \"\"\"\n    if search(\"[sxz]$\", text) or search(\"[^aeioudgkprt]h$\", text):\n        return sub(\"$\", \"es\", text)\n    if search(\"[aeiou]y$\", text):\n        return sub(\"y$\", \"ies\", text)\n    return text + \"s\"\n</code></pre>"},{"location":"reference/sc_crawler/str_utils/#sc_crawler.str_utils.extract_last_number","title":"extract_last_number","text":"<pre><code>extract_last_number(text)\n</code></pre> <p>Extract the last non-negative number from a string.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The input string from which to extract the number.</p> required <p>Returns:</p> Type Description <code>Union[float, None]</code> <p>The last non-negative number found in the string, or None if no number is found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; extract_last_number(\"foo42\")\n42.0\n&gt;&gt;&gt; extract_last_number(\"foo24.42bar\")\n24.42\n</code></pre> Source code in <code>sc_crawler/str_utils.py</code> <pre><code>def extract_last_number(text: str) -&gt; Union[float, None]:\n    \"\"\"Extract the last non-negative number from a string.\n\n    Args:\n        text: The input string from which to extract the number.\n\n    Returns:\n        The last non-negative number found in the string, or None if no number is found.\n\n    Examples:\n        &gt;&gt;&gt; extract_last_number(\"foo42\")\n        42.0\n        &gt;&gt;&gt; extract_last_number(\"foo24.42bar\")\n        24.42\n    \"\"\"\n    match = search(r\"([\\d\\.]+)[^0-9]*$\", text)\n    return float(match.group(1)) if match else None\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/","title":"table_bases","text":""},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases","title":"sc_crawler.table_bases","text":"<p>Tiny helper classes for the most commonly used fields to be inherited by sc_crawler.tables.</p>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScMetaModel","title":"ScMetaModel","text":"<p>               Bases: <code>__class__</code></p> <p>Custom class factory to auto-update table models.</p> <ul> <li> <p>Reuse description of the table and its fields as SQL comment.</p> <p>Checking if the table and its fields have explicit comment set to be shown in the <code>CREATE TABLE</code> statements, and if not, reuse the optional table and field descriptions. Table docstrings are truncated to first line.</p> </li> <li> <p>Reuse description of the fields to dynamically append to the     docstring in the Attributes section.</p> </li> <li> <p>Set <code>__validator__</code> to the parent Pydantic model without     <code>table=True</code>, which is useful for running validations.     The Pydantic model is found by the parent class' name ending in \"Base\".</p> </li> <li> <p>Auto-generate SCD table docs from the non-SCD table docs.</p> </li> </ul> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class ScMetaModel(SQLModel.__class__):\n    \"\"\"Custom class factory to auto-update table models.\n\n    - Reuse description of the table and its fields as SQL comment.\n\n        Checking if the table and its fields have explicit comment set\n        to be shown in the `CREATE TABLE` statements, and if not,\n        reuse the optional table and field descriptions. Table\n        docstrings are truncated to first line.\n\n    - Reuse description of the fields to dynamically append to the\n        docstring in the Attributes section.\n\n    - Set `__validator__` to the parent Pydantic model without\n        `table=True`, which is useful for running validations.\n        The Pydantic model is found by the parent class' name ending in \"Base\".\n\n    - Auto-generate SCD table docs from the non-SCD table docs.\n    \"\"\"\n\n    def __init__(subclass, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # early return for non-tables\n        if subclass.model_config.get(\"table\") is None:\n            return\n        satable = subclass.metadata.tables[subclass.__tablename__]\n\n        # enforce auto-naming constrains as per\n        # https://alembic.sqlalchemy.org/en/latest/naming.html\n        subclass.metadata.naming_convention = {\n            \"ix\": \"ix_%(column_0_label)s\",\n            \"uq\": \"uq_%(table_name)s_%(column_0_name)s\",\n            \"ck\": \"ck_%(table_name)s_%(constraint_name)s\",\n            \"fk\": \"fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s\",\n            \"pk\": \"pk_%(table_name)s\",\n        }\n\n        # table comment\n        if subclass.__doc__ and satable.comment is None:\n            satable.comment = subclass.__doc__.splitlines()[0]\n\n        # column comments\n        for k, v in subclass.model_fields.items():\n            comment = satable.columns[k].comment\n            if v.description and comment is None:\n                satable.columns[k].comment = v.description\n\n        # generate docstring for SCD tables\n        if subclass.__name__.endswith(\"Scd\"):\n            from .tables import tables\n\n            nonscd = [t for t in tables if t.__name__ == subclass.__name__[:-3]][0]\n            doclines = nonscd.__doc__.splitlines()\n            # drop trailing dot and append SCD\n            doclines[0] = doclines[0][:-1] + \" (SCD Type 2).\"\n            subclass.__doc__ = \"\\n\".join(doclines)\n        else:\n            # describe table columns as attributes in docstring\n            subclass.__doc__ = subclass.__doc__ + \"\\n\\nAttributes:\\n\"\n            for k, v in subclass.model_fields.items():\n                if not hasattr(v.annotation, \"__args__\"):\n                    typehint = v.annotation.__name__\n                else:\n                    typehint = str(v.annotation)\n                description = satable.columns[k].comment\n                subclass.__doc__ = (\n                    subclass.__doc__ + f\"    {k} ({typehint}): {description}\\n\"\n                )\n\n        # find Pydantic model parent to be used for validating\n        subclass.__validator__ = [\n            m for m in subclass.__bases__ if m.__name__.endswith(\"Base\")\n        ][0]\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel","title":"ScModel","text":"<p>               Bases: <code>SQLModel</code></p> <p>Custom extensions to SQLModel objects and tables.</p> <p>Extra features:</p> <ul> <li>auto-generated table names using snake_case,</li> <li>support for hashing table rows,</li> <li>reuse description field of tables/columns as SQL comment,</li> <li>reuse description field of columns to extend the <code>Attributes</code> section of the docstring.</li> </ul> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class ScModel(SQLModel, metaclass=ScMetaModel):\n    \"\"\"Custom extensions to SQLModel objects and tables.\n\n    Extra features:\n\n    - auto-generated table names using [snake_case][sc_crawler.str_utils.snake_case],\n    - support for hashing table rows,\n    - reuse description field of tables/columns as SQL comment,\n    - reuse description field of columns to extend the `Attributes` section of the docstring.\n    \"\"\"\n\n    @declared_attr  # type: ignore\n    def __tablename__(cls) -&gt; str:\n        \"\"\"Override tables names using all-lowercase [snake_case][sc_crawler.str_utils.snake_case].\"\"\"\n        return snake_case(cls.__name__)\n\n    @classmethod\n    def get_columns(cls) -&gt; List[str]:\n        \"\"\"Return the table's column names in a dict for all, primary keys, and attributes.\"\"\"\n        columns = cls.__table__.columns.keys()\n        pks = [pk.name for pk in inspect(cls).primary_key]\n        attributes = [a for a in columns if a not in set(pks)]\n        return {\"all\": columns, \"primary_keys\": pks, \"attributes\": attributes}\n\n    @classmethod\n    def get_table_name(cls) -&gt; str:\n        \"\"\"Return the SQLModel object's table name.\"\"\"\n        return str(cls.__tablename__)\n\n    @classmethod\n    def get_validator(cls) -&gt; Union[\"ScModel\", None]:\n        \"\"\"Return the parent Base Pydantic model (without a table definition).\"\"\"\n        if cls.model_config.get(\"table\") is None:\n            return None\n        return cls.__validator__\n\n    @classmethod\n    def get_scd(cls) -&gt; Union[\"ScModel\", None]:\n        \"\"\"Return the SCD version of the SQLModel table.\"\"\"\n        if cls.model_config.get(\"table\") is None:\n            return None\n        from .tables_scd import tables_scd\n\n        validator = cls.get_validator()\n        scds = [t for t in tables_scd if t.get_validator() == validator]\n        if len(scds) != 1:\n            raise ValueError(\"Not found SCD definition.\")\n        return scds[0]\n\n    @classmethod\n    def hash(\n        cls,\n        session: Session,\n        ignored: List[str] = [\"observed_at\"],\n        progress: Optional[Progress] = None,\n    ) -&gt; dict:\n        \"\"\"Hash the content of the rows.\n\n        Args:\n            session: Database connection to use for object lookups.\n            ignored: List of column names to exclude from hashing.\n            progress: Optional progress bar to track the status of the hashing.\n\n        Returns:\n            Dictionary of the row hashes keyed by the JSON dump of primary keys.\n        \"\"\"\n        pks = sorted(cls.get_columns()[\"primary_keys\"])\n        rows = session.exec(statement=select(cls))\n        row_count = session.query(cls).count()\n        if progress:\n            table_task_id = progress.add_task(\n                cls.get_table_name(),\n                total=row_count,\n            )\n        # no use of a generator as will need to serialize to JSON anyway\n        hashes = {}\n        for i, row in enumerate(rows):\n            # NOTE Pydantic is warning when read Gpu/Storage as dict\n            # https://github.com/tiangolo/sqlmodel/issues/63#issuecomment-1081555082\n            rowdict = row.model_dump(warnings=False)\n            keys = {pk: rowdict.get(pk) for pk in pks}\n            keys_id = dumps(keys, sort_keys=True)\n            for dropkey in [*ignored, *pks]:\n                rowdict.pop(dropkey, None)\n            rowhash = sha1(dumps(rowdict, sort_keys=True).encode()).hexdigest()\n            hashes[keys_id] = rowhash\n            if progress:\n                # updating the progress bar is expensive, so limit with manu iterations\n                if row_count &gt; 1e3:\n                    if (i + 1) % 1000 == 0:\n                        progress.update(table_task_id, advance=1000)\n                    if i == row_count - 1:\n                        progress.update(table_task_id, advance=row_count % 1000)\n                else:\n                    progress.update(table_task_id, advance=1)\n\n        return hashes\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.__tablename__","title":"__tablename__","text":"<pre><code>__tablename__()\n</code></pre> <p>Override tables names using all-lowercase snake_case.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@declared_attr  # type: ignore\ndef __tablename__(cls) -&gt; str:\n    \"\"\"Override tables names using all-lowercase [snake_case][sc_crawler.str_utils.snake_case].\"\"\"\n    return snake_case(cls.__name__)\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_columns","title":"get_columns  <code>classmethod</code>","text":"<pre><code>get_columns()\n</code></pre> <p>Return the table's column names in a dict for all, primary keys, and attributes.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_columns(cls) -&gt; List[str]:\n    \"\"\"Return the table's column names in a dict for all, primary keys, and attributes.\"\"\"\n    columns = cls.__table__.columns.keys()\n    pks = [pk.name for pk in inspect(cls).primary_key]\n    attributes = [a for a in columns if a not in set(pks)]\n    return {\"all\": columns, \"primary_keys\": pks, \"attributes\": attributes}\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_table_name","title":"get_table_name  <code>classmethod</code>","text":"<pre><code>get_table_name()\n</code></pre> <p>Return the SQLModel object's table name.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_table_name(cls) -&gt; str:\n    \"\"\"Return the SQLModel object's table name.\"\"\"\n    return str(cls.__tablename__)\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_validator","title":"get_validator  <code>classmethod</code>","text":"<pre><code>get_validator()\n</code></pre> <p>Return the parent Base Pydantic model (without a table definition).</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_validator(cls) -&gt; Union[\"ScModel\", None]:\n    \"\"\"Return the parent Base Pydantic model (without a table definition).\"\"\"\n    if cls.model_config.get(\"table\") is None:\n        return None\n    return cls.__validator__\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.get_scd","title":"get_scd  <code>classmethod</code>","text":"<pre><code>get_scd()\n</code></pre> <p>Return the SCD version of the SQLModel table.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef get_scd(cls) -&gt; Union[\"ScModel\", None]:\n    \"\"\"Return the SCD version of the SQLModel table.\"\"\"\n    if cls.model_config.get(\"table\") is None:\n        return None\n    from .tables_scd import tables_scd\n\n    validator = cls.get_validator()\n    scds = [t for t in tables_scd if t.get_validator() == validator]\n    if len(scds) != 1:\n        raise ValueError(\"Not found SCD definition.\")\n    return scds[0]\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.ScModel.hash","title":"hash  <code>classmethod</code>","text":"<pre><code>hash(session, ignored=['observed_at'], progress=None)\n</code></pre> <p>Hash the content of the rows.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Database connection to use for object lookups.</p> required <code>ignored</code> <code>List[str]</code> <p>List of column names to exclude from hashing.</p> <code>['observed_at']</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to track the status of the hashing.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of the row hashes keyed by the JSON dump of primary keys.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@classmethod\ndef hash(\n    cls,\n    session: Session,\n    ignored: List[str] = [\"observed_at\"],\n    progress: Optional[Progress] = None,\n) -&gt; dict:\n    \"\"\"Hash the content of the rows.\n\n    Args:\n        session: Database connection to use for object lookups.\n        ignored: List of column names to exclude from hashing.\n        progress: Optional progress bar to track the status of the hashing.\n\n    Returns:\n        Dictionary of the row hashes keyed by the JSON dump of primary keys.\n    \"\"\"\n    pks = sorted(cls.get_columns()[\"primary_keys\"])\n    rows = session.exec(statement=select(cls))\n    row_count = session.query(cls).count()\n    if progress:\n        table_task_id = progress.add_task(\n            cls.get_table_name(),\n            total=row_count,\n        )\n    # no use of a generator as will need to serialize to JSON anyway\n    hashes = {}\n    for i, row in enumerate(rows):\n        # NOTE Pydantic is warning when read Gpu/Storage as dict\n        # https://github.com/tiangolo/sqlmodel/issues/63#issuecomment-1081555082\n        rowdict = row.model_dump(warnings=False)\n        keys = {pk: rowdict.get(pk) for pk in pks}\n        keys_id = dumps(keys, sort_keys=True)\n        for dropkey in [*ignored, *pks]:\n            rowdict.pop(dropkey, None)\n        rowhash = sha1(dumps(rowdict, sort_keys=True).encode()).hexdigest()\n        hashes[keys_id] = rowhash\n        if progress:\n            # updating the progress bar is expensive, so limit with manu iterations\n            if row_count &gt; 1e3:\n                if (i + 1) % 1000 == 0:\n                    progress.update(table_task_id, advance=1000)\n                if i == row_count - 1:\n                    progress.update(table_task_id, advance=row_count % 1000)\n            else:\n                progress.update(table_task_id, advance=1)\n\n    return hashes\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.MetaColumns","title":"MetaColumns","text":"<p>               Bases: <code>ScModel</code></p> <p>Helper class to add the <code>status</code> and <code>observed_at</code> columns.</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class MetaColumns(ScModel):\n    \"\"\"Helper class to add the `status` and `observed_at` columns.\"\"\"\n\n    status: Status = Field(\n        default=Status.ACTIVE,\n        description=\"Status of the resource (active or inactive).\",\n    )\n    observed_at: datetime = Field(\n        default_factory=datetime.utcnow,\n        sa_column_kwargs={\"onupdate\": datetime.utcnow},\n        description=\"Timestamp of the last observation.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.BenchmarkScoreFields","title":"BenchmarkScoreFields","text":"<p>               Bases: <code>HasBenchmarkPKFK</code>, <code>HasServerPK</code>, <code>HasVendorPKFK</code></p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>class BenchmarkScoreFields(HasBenchmarkPKFK, HasServerPK, HasVendorPKFK):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"before\")\n    def update_config_to_hashable(cls, values):\n        \"\"\"We need a hashable column for the primary key.\n\n        Note that we also sort the keys, so that the resulting JSON\n        can be compared as text as well (as some database engines do).\n        \"\"\"\n        values[\"config\"] = HashableDict(sorted(values.get(\"config\", {}).items()))\n        return values\n\n    # use HashableDict as it's a primary key that needs to be hashable, but\n    # fall back to dict to avoid PydanticInvalidForJsonSchema\n    config: HashableDict | dict = Field(\n        default={},\n        sa_type=HashableJSON,\n        primary_key=True,\n        description='Dictionary of config parameters of the specific benchmark, e.g. {\"bandwidth\": 4096}',\n    )\n    score: float = Field(\n        description=\"The resulting score of the benchmark.\",\n    )\n    note: Optional[str] = Field(\n        default=None,\n        description=\"Optional note, comment or context on the benchmark score.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/table_bases/#sc_crawler.table_bases.BenchmarkScoreFields.update_config_to_hashable","title":"update_config_to_hashable","text":"<pre><code>update_config_to_hashable(values)\n</code></pre> <p>We need a hashable column for the primary key.</p> <p>Note that we also sort the keys, so that the resulting JSON can be compared as text as well (as some database engines do).</p> Source code in <code>sc_crawler/table_bases.py</code> <pre><code>@model_validator(mode=\"before\")\ndef update_config_to_hashable(cls, values):\n    \"\"\"We need a hashable column for the primary key.\n\n    Note that we also sort the keys, so that the resulting JSON\n    can be compared as text as well (as some database engines do).\n    \"\"\"\n    values[\"config\"] = HashableDict(sorted(values.get(\"config\", {}).items()))\n    return values\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/","title":"table_fields","text":""},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields","title":"sc_crawler.table_fields","text":"<p>Enumerations, JSON nested data objects &amp; other helper classes used in sc_crawler.tables.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.HashableDict","title":"HashableDict","text":"<p>               Bases: <code>dict</code></p> <p>A dict that can be hashed by its JSON representation.</p> <p>Useful for typehinting dict-type table columns that are primary keys (which need to be hashable for SQLAlchemy ORM). See sc_crawler.table_fields.HashableJSON class for the related <code>sa_type</code>.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class HashableDict(dict):\n    \"\"\"A dict that can be hashed by its JSON representation.\n\n    Useful for typehinting dict-type table columns that are primary\n    keys (which need to be hashable for SQLAlchemy ORM). See\n    [sc_crawler.table_fields.HashableJSON][] class for the related `sa_type`.\n    \"\"\"\n\n    def __hash__(self):\n        return hash(dumps(self, sort_keys=True))\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.HashableJSON","title":"HashableJSON","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Alternative JSON SQLAlchemy column representation, which can be hashed.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class HashableJSON(TypeDecorator):\n    \"\"\"Alternative JSON SQLAlchemy column representation, which can be hashed.\"\"\"\n\n    impl = JSON\n\n    def process_result_value(self, value: str, dialect: Any) -&gt; Any:\n        if value is None:\n            return None\n        return HashableDict(value)\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Json","title":"Json","text":"<p>               Bases: <code>BaseModel</code></p> <p>Custom base SQLModel class that supports dumping as JSON.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Json(BaseModel):\n    \"\"\"Custom base SQLModel class that supports dumping as JSON.\"\"\"\n\n    def __json__(self):\n        \"\"\"Call `self.model_dump` to serialize into JSON.\"\"\"\n        return dict(sorted(self.model_dump().items()))\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Json.__json__","title":"__json__","text":"<pre><code>__json__()\n</code></pre> <p>Call <code>self.model_dump</code> to serialize into JSON.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>def __json__(self):\n    \"\"\"Call `self.model_dump` to serialize into JSON.\"\"\"\n    return dict(sorted(self.model_dump().items()))\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Status","title":"Status","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Last known status of a resource, e.g. active or inactive.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Status(str, Enum):\n    \"\"\"Last known status of a resource, e.g. active or inactive.\"\"\"\n\n    ACTIVE = \"active\"\n    \"\"\"Active and available resource.\"\"\"\n    INACTIVE = \"inactive\"\n    \"\"\"Inactive resource that is not available anymore.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Status.ACTIVE","title":"ACTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACTIVE = 'active'\n</code></pre> <p>Active and available resource.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Status.INACTIVE","title":"INACTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INACTIVE = 'inactive'\n</code></pre> <p>Inactive resource that is not available anymore.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu","title":"Cpu","text":"<p>               Bases: <code>Json</code></p> <p>CPU details.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Cpu(Json):\n    \"\"\"CPU details.\"\"\"\n\n    manufacturer: Optional[str] = None\n    \"\"\"The manufacturer of the processor, e.g. Intel or AMD.\"\"\"\n    family: Optional[str] = None\n    \"\"\"The product line/family of the processor, e.g. Xeon, Core i7, Ryzen 9.\"\"\"\n    model: Optional[str] = None\n    \"\"\"The model number of the processor, e.g. 9750H.\"\"\"\n    cores: Optional[int] = None\n    \"\"\"Number of CPU cores.\"\"\"\n    threads: Optional[int] = None\n    \"\"\"Number of CPU threads.\"\"\"\n    l1_cache_size: Optional[int] = None\n    \"\"\"L1 cache size in bytes.\"\"\"\n    l2_cache_size: Optional[int] = None\n    \"\"\"L2 cache size in bytes.\"\"\"\n    l3_cache_size: Optional[int] = None\n    \"\"\"L3 cache size in bytes.\"\"\"\n    microcode: Optional[str] = None\n    \"\"\"Microcode version.\"\"\"\n    capabilities: List[str] = []\n    \"\"\"List of CPU flag/features/capabilities, e.g. MMX, Intel SGX etc.\"\"\"\n    bugs: List[str] = []\n    \"\"\"List of known bugs, e.g. cpu_meltdown spectre_v1.\"\"\"\n    bogomips: Optional[float] = None\n    \"\"\"BogoMips value.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.manufacturer","title":"manufacturer  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>manufacturer = None\n</code></pre> <p>The manufacturer of the processor, e.g. Intel or AMD.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.family","title":"family  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>family = None\n</code></pre> <p>The product line/family of the processor, e.g. Xeon, Core i7, Ryzen 9.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model = None\n</code></pre> <p>The model number of the processor, e.g. 9750H.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.cores","title":"cores  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cores = None\n</code></pre> <p>Number of CPU cores.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.threads","title":"threads  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>threads = None\n</code></pre> <p>Number of CPU threads.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.l1_cache_size","title":"l1_cache_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>l1_cache_size = None\n</code></pre> <p>L1 cache size in bytes.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.l2_cache_size","title":"l2_cache_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>l2_cache_size = None\n</code></pre> <p>L2 cache size in bytes.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.l3_cache_size","title":"l3_cache_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>l3_cache_size = None\n</code></pre> <p>L3 cache size in bytes.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.microcode","title":"microcode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>microcode = None\n</code></pre> <p>Microcode version.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.capabilities","title":"capabilities  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>capabilities = []\n</code></pre> <p>List of CPU flag/features/capabilities, e.g. MMX, Intel SGX etc.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.bugs","title":"bugs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bugs = []\n</code></pre> <p>List of known bugs, e.g. cpu_meltdown spectre_v1.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Cpu.bogomips","title":"bogomips  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bogomips = None\n</code></pre> <p>BogoMips value.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu","title":"Gpu","text":"<p>               Bases: <code>Json</code></p> <p>GPU accelerator details.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Gpu(Json):\n    \"\"\"GPU accelerator details.\"\"\"\n\n    manufacturer: str\n    \"\"\"The manufacturer/brand of the GPU accelerator, e.g. Nvidia or AMD.\"\"\"\n    family: Optional[str] = None\n    \"\"\"The model family/architecture of the GPU accelerator.\"\"\"\n    model: Optional[str] = None\n    \"\"\"The model number of the GPU accelerator.\"\"\"\n    memory: int\n    \"\"\"Memory (MiB) allocated to the GPU accelerator.\"\"\"\n    firmware_version: Optional[str] = None\n    \"\"\"Firmware version.\"\"\"\n    bios_version: Optional[str] = None\n    \"\"\"Video BIOS version.\"\"\"\n    graphics_clock: Optional[int] = None\n    \"\"\"GPU core clock speed (Mhz).\"\"\"\n    sm_clock: Optional[int] = None\n    \"\"\"Streaming Multiprocessor clock speed (Mhz).\"\"\"\n    mem_clock: Optional[int] = None\n    \"\"\"Memory clock speed (Mhz).\"\"\"\n    video_clock: Optional[int] = None\n    \"\"\"Video clock speed (Mhz).\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.manufacturer","title":"manufacturer  <code>instance-attribute</code>","text":"<pre><code>manufacturer\n</code></pre> <p>The manufacturer/brand of the GPU accelerator, e.g. Nvidia or AMD.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.family","title":"family  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>family = None\n</code></pre> <p>The model family/architecture of the GPU accelerator.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model = None\n</code></pre> <p>The model number of the GPU accelerator.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.memory","title":"memory  <code>instance-attribute</code>","text":"<pre><code>memory\n</code></pre> <p>Memory (MiB) allocated to the GPU accelerator.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.firmware_version","title":"firmware_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>firmware_version = None\n</code></pre> <p>Firmware version.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.bios_version","title":"bios_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bios_version = None\n</code></pre> <p>Video BIOS version.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.graphics_clock","title":"graphics_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>graphics_clock = None\n</code></pre> <p>GPU core clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.sm_clock","title":"sm_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sm_clock = None\n</code></pre> <p>Streaming Multiprocessor clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.mem_clock","title":"mem_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mem_clock = None\n</code></pre> <p>Memory clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Gpu.video_clock","title":"video_clock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>video_clock = None\n</code></pre> <p>Video clock speed (Mhz).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType","title":"StorageType","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Type of a storage, e.g. HDD or SSD.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class StorageType(str, Enum):\n    \"\"\"Type of a storage, e.g. HDD or SSD.\"\"\"\n\n    HDD = \"hdd\"\n    \"\"\"Magnetic hard disk drive.\"\"\"\n    SSD = \"ssd\"\n    \"\"\"Solid-state drive.\"\"\"\n    NVME_SSD = \"nvme ssd\"\n    \"\"\"NVMe based solid-state drive.\"\"\"\n    NETWORK = \"network\"\n    \"\"\"Storage over network, e.g. using NFS.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.HDD","title":"HDD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HDD = 'hdd'\n</code></pre> <p>Magnetic hard disk drive.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.SSD","title":"SSD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SSD = 'ssd'\n</code></pre> <p>Solid-state drive.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.NVME_SSD","title":"NVME_SSD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NVME_SSD = 'nvme ssd'\n</code></pre> <p>NVMe based solid-state drive.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.StorageType.NETWORK","title":"NETWORK  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NETWORK = 'network'\n</code></pre> <p>Storage over network, e.g. using NFS.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk","title":"Disk","text":"<p>               Bases: <code>Json</code></p> <p>Disk definition based on size and storage type.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Disk(Json):\n    \"\"\"Disk definition based on size and storage type.\"\"\"\n\n    size: int = 0\n    \"\"\"Storage size in GiB.\"\"\"\n    storage_type: StorageType\n    \"\"\"[Type][sc_crawler.table_fields.StorageType] of the storage.\"\"\"\n    description: Optional[str] = None\n    \"\"\"Optional description of the storage, e.g. temp disk.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk.size","title":"size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>size = 0\n</code></pre> <p>Storage size in GiB.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk.storage_type","title":"storage_type  <code>instance-attribute</code>","text":"<pre><code>storage_type\n</code></pre> <p>Type of the storage.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Disk.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description = None\n</code></pre> <p>Optional description of the storage, e.g. temp disk.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.TrafficDirection","title":"TrafficDirection","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Direction of the network traffic.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class TrafficDirection(str, Enum):\n    \"\"\"Direction of the network traffic.\"\"\"\n\n    IN = \"inbound\"\n    \"\"\"Inbound traffic.\"\"\"\n    OUT = \"outbound\"\n    \"\"\"Outbound traffic.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.TrafficDirection.IN","title":"IN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>IN = 'inbound'\n</code></pre> <p>Inbound traffic.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.TrafficDirection.OUT","title":"OUT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OUT = 'outbound'\n</code></pre> <p>Outbound traffic.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation","title":"CpuAllocation","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>CPU allocation methods at cloud vendors.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class CpuAllocation(str, Enum):\n    \"\"\"CPU allocation methods at cloud vendors.\"\"\"\n\n    SHARED = \"Shared\"\n    \"\"\"Shared CPU with other virtual server tenants.\"\"\"\n    BURSTABLE = \"Burstable\"\n    \"\"\"CPU that can temporarily burst above its baseline performance.\"\"\"\n    DEDICATED = \"Dedicated\"\n    \"\"\"Dedicated CPU with known performance.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation.SHARED","title":"SHARED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SHARED = 'Shared'\n</code></pre> <p>Shared CPU with other virtual server tenants.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation.BURSTABLE","title":"BURSTABLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BURSTABLE = 'Burstable'\n</code></pre> <p>CPU that can temporarily burst above its baseline performance.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuAllocation.DEDICATED","title":"DEDICATED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DEDICATED = 'Dedicated'\n</code></pre> <p>Dedicated CPU with known performance.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture","title":"CpuArchitecture","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>CPU architectures.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class CpuArchitecture(str, Enum):\n    \"\"\"CPU architectures.\"\"\"\n\n    ARM64 = \"arm64\"\n    \"\"\"64-bit ARM architecture.\"\"\"\n    ARM64_MAC = \"arm64_mac\"\n    \"\"\"Apple 64-bit ARM architecture.\"\"\"\n    I386 = \"i386\"\n    \"\"\"32-bit x86 architecture.\"\"\"\n    X86_64 = \"x86_64\"\n    \"\"\"64-bit x86 architecture.\"\"\"\n    X86_64_MAC = \"x86_64_mac\"\n    \"\"\"Apple 64-bit x86 architecture.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.ARM64","title":"ARM64  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ARM64 = 'arm64'\n</code></pre> <p>64-bit ARM architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.ARM64_MAC","title":"ARM64_MAC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ARM64_MAC = 'arm64_mac'\n</code></pre> <p>Apple 64-bit ARM architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.I386","title":"I386  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>I386 = 'i386'\n</code></pre> <p>32-bit x86 architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.X86_64","title":"X86_64  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>X86_64 = 'x86_64'\n</code></pre> <p>64-bit x86 architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.CpuArchitecture.X86_64_MAC","title":"X86_64_MAC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>X86_64_MAC = 'x86_64_mac'\n</code></pre> <p>Apple 64-bit x86 architecture.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration","title":"DdrGeneration","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Generation of the DDR SDRAM.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class DdrGeneration(str, Enum):\n    \"\"\"Generation of the DDR SDRAM.\"\"\"\n\n    DDR3 = \"DDR3\"\n    \"\"\"DDR3 SDRAM.\"\"\"\n    DDR4 = \"DDR4\"\n    \"\"\"DDR4 SDRAM.\"\"\"\n    DDR5 = \"DDR5\"\n    \"\"\"DDR5 SDRAM.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration.DDR3","title":"DDR3  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DDR3 = 'DDR3'\n</code></pre> <p>DDR3 SDRAM.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration.DDR4","title":"DDR4  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DDR4 = 'DDR4'\n</code></pre> <p>DDR4 SDRAM.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.DdrGeneration.DDR5","title":"DDR5  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DDR5 = 'DDR5'\n</code></pre> <p>DDR5 SDRAM.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation","title":"Allocation","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Server allocation options.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class Allocation(str, Enum):\n    \"\"\"Server allocation options.\"\"\"\n\n    ONDEMAND = \"ondemand\"\n    \"\"\"On-demand server.\"\"\"\n    RESERVED = \"reserved\"\n    \"\"\"Reserved server.\"\"\"\n    SPOT = \"spot\"\n    \"\"\"Spot/preemptible server.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation.ONDEMAND","title":"ONDEMAND  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ONDEMAND = 'ondemand'\n</code></pre> <p>On-demand server.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation.RESERVED","title":"RESERVED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RESERVED = 'reserved'\n</code></pre> <p>Reserved server.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.Allocation.SPOT","title":"SPOT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SPOT = 'spot'\n</code></pre> <p>Spot/preemptible server.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit","title":"PriceUnit","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Supported units for the price tables.</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class PriceUnit(str, Enum):\n    \"\"\"Supported units for the price tables.\"\"\"\n\n    YEAR = \"year\"\n    \"\"\"Price per year.\"\"\"\n    MONTH = \"month\"\n    \"\"\"Price per month.\"\"\"\n    HOUR = \"hour\"\n    \"\"\"Price per hour.\"\"\"\n    GIB = \"GiB\"\n    \"\"\"Price per gibibyte (GiB).\"\"\"\n    GB = \"GB\"\n    \"\"\"Price per gigabyte (GB).\"\"\"\n    GB_MONTH = \"GB/month\"\n    \"\"\"Price per gigabyte (GB)/month.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.YEAR","title":"YEAR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>YEAR = 'year'\n</code></pre> <p>Price per year.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.MONTH","title":"MONTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MONTH = 'month'\n</code></pre> <p>Price per month.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.HOUR","title":"HOUR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HOUR = 'hour'\n</code></pre> <p>Price per hour.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.GIB","title":"GIB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GIB = 'GiB'\n</code></pre> <p>Price per gibibyte (GiB).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.GB","title":"GB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GB = 'GB'\n</code></pre> <p>Price per gigabyte (GB).</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceUnit.GB_MONTH","title":"GB_MONTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GB_MONTH = 'GB/month'\n</code></pre> <p>Price per gigabyte (GB)/month.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier","title":"PriceTier","text":"<p>               Bases: <code>Json</code></p> <p>Price tier definition.</p> <p>As standard JSON does not support Inf, NaN etc values, those should be passed as string, e.g. for the upper bound.</p> <p>See float_inf_to_str for converting an infinite numeric value into \"Infinity\".</p> Source code in <code>sc_crawler/table_fields.py</code> <pre><code>class PriceTier(Json):\n    \"\"\"Price tier definition.\n\n    As standard JSON does not support Inf, NaN etc values,\n    those should be passed as string, e.g. for the upper bound.\n\n    See [float_inf_to_str][sc_crawler.utils.float_inf_to_str] for\n    converting an infinite numeric value into \"Infinity\".\"\"\"\n\n    lower: Union[float, str]\n    \"\"\"Lower bound of pricing tier, e.g. 100 GB. Unit is defined in the parent object.\"\"\"\n    upper: Union[float, str]\n    \"\"\"Upper bound of pricing tier, e.g. 1 TB. Unit is defined in the parent object.\"\"\"\n    price: float\n    \"\"\"Price in the pricing tier. Currency is defined in the parent object.\"\"\"\n</code></pre>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier.lower","title":"lower  <code>instance-attribute</code>","text":"<pre><code>lower\n</code></pre> <p>Lower bound of pricing tier, e.g. 100 GB. Unit is defined in the parent object.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier.upper","title":"upper  <code>instance-attribute</code>","text":"<pre><code>upper\n</code></pre> <p>Upper bound of pricing tier, e.g. 1 TB. Unit is defined in the parent object.</p>"},{"location":"reference/sc_crawler/table_fields/#sc_crawler.table_fields.PriceTier.price","title":"price  <code>instance-attribute</code>","text":"<pre><code>price\n</code></pre> <p>Price in the pricing tier. Currency is defined in the parent object.</p>"},{"location":"reference/sc_crawler/tables/","title":"tables","text":""},{"location":"reference/sc_crawler/tables/#sc_crawler.tables","title":"sc_crawler.tables","text":"<p>Table definitions for vendors, regions, zones, and other cloud resources.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Country","title":"Country","text":"<p>               Bases: <code>CountryBase</code></p> <p>Country and continent mapping.</p> <p>Attributes:</p> Name Type Description <code>country_id</code> <code>str</code> <p>Country code by ISO 3166 alpha-2.</p> <code>continent</code> <code>str</code> <p>Continent name.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Country(CountryBase, table=True):\n    \"\"\"Country and continent mapping.\"\"\"\n\n    vendors: List[\"Vendor\"] = Relationship(back_populates=\"country\")\n    regions: List[\"Region\"] = Relationship(back_populates=\"country\")\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.ComplianceFramework","title":"ComplianceFramework","text":"<p>               Bases: <code>ComplianceFrameworkBase</code></p> <p>List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1.</p> <p>Attributes:</p> Name Type Description <code>compliance_framework_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>abbreviation</code> <code>Optional[str]</code> <p>Short abbreviation of the Framework name.</p> <code>description</code> <code>Optional[str]</code> <p>Description of the framework in a few paragrahs, outlining key features and characteristics for reference.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Framework's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage with more information on the Framework.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class ComplianceFramework(ComplianceFrameworkBase, table=True):\n    \"\"\"List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1.\"\"\"\n\n    vendor_links: List[\"VendorComplianceLink\"] = Relationship(\n        back_populates=\"compliance_framework\"\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor","title":"Vendor","text":"<p>               Bases: <code>VendorBase</code></p> <p>Compute resource vendors, such as cloud and server providers.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sc_crawler.tables import Vendor\n&gt;&gt;&gt; from sc_crawler.lookup import countries\n&gt;&gt;&gt; aws = Vendor(vendor_id='aws', name='Amazon Web Services', homepage='https://aws.amazon.com', country=countries[\"US\"], founding_year=2002)\n&gt;&gt;&gt; aws\nVendor(vendor_id='aws'...\n&gt;&gt;&gt; from sc_crawler import vendors\n&gt;&gt;&gt; vendors.aws\nVendor(vendor_id='aws'...\n</code></pre> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Vendor's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage of the Vendor.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Vendor's main headquarter is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Vendor's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Vendor's main location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Vendor's main location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Vendor's main location.</p> <code>founding_year</code> <code>int</code> <p>4-digit year when the Vendor was founded.</p> <code>status_page</code> <code>Optional[str]</code> <p>Public status page of the Vendor.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Vendor(VendorBase, table=True):\n    \"\"\"Compute resource vendors, such as cloud and server providers.\n\n    Examples:\n        &gt;&gt;&gt; from sc_crawler.tables import Vendor\n        &gt;&gt;&gt; from sc_crawler.lookup import countries\n        &gt;&gt;&gt; aws = Vendor(vendor_id='aws', name='Amazon Web Services', homepage='https://aws.amazon.com', country=countries[\"US\"], founding_year=2002)\n        &gt;&gt;&gt; aws\n        Vendor(vendor_id='aws'...\n        &gt;&gt;&gt; from sc_crawler import vendors\n        &gt;&gt;&gt; vendors.aws\n        Vendor(vendor_id='aws'...\n    \"\"\"  # noqa: E501\n\n    compliance_framework_links: List[\"VendorComplianceLink\"] = Relationship(\n        back_populates=\"vendor\"\n    )\n    country: Country = Relationship(back_populates=\"vendors\")\n    regions: List[\"Region\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    zones: List[\"Zone\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    storages: List[\"Storage\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    servers: List[\"Server\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    server_prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    traffic_prices: List[\"TrafficPrice\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    ipv4_prices: List[\"Ipv4Price\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    storage_prices: List[\"StoragePrice\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    benchmark_scores: List[\"BenchmarkScore\"] = Relationship(\n        back_populates=\"vendor\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n\n    # private attributes\n    _methods: Optional[ImportString[ModuleType]] = PrivateAttr(default=None)\n    _session: Optional[Session] = PrivateAttr()\n    _progress_tracker: Optional[VendorProgressTracker] = PrivateAttr(\n        default=VoidProgressTracker()\n    )\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # SQLModel does not validates pydantic typing,\n        # only when writing to DB (much later in the process)\n        if not self.vendor_id:\n            raise ValueError(\"No vendor id provided\")\n        if not self.name:\n            raise ValueError(\"No vendor name provided\")\n        if not self.homepage:\n            raise ValueError(\"No vendor homepage provided\")\n        if not self.country:\n            raise ValueError(\"No vendor country provided\")\n        # make sure methods are provided\n        methods = self._get_methods().__dir__()\n        for method in [\n            \"inventory_compliance_frameworks\",\n            \"inventory_regions\",\n            \"inventory_zones\",\n            \"inventory_servers\",\n            \"inventory_server_prices\",\n            \"inventory_server_prices_spot\",\n            \"inventory_storage_prices\",\n            \"inventory_traffic_prices\",\n            \"inventory_ipv4_prices\",\n        ]:\n            if method not in methods:\n                raise NotImplementedError(\n                    f\"Unsupported '{self.vendor_id}' vendor: missing '{method}' method.\"\n                )\n\n    def _get_methods(self):\n        # private attributes are not (always) initialized correctly by SQLmodel\n        # e.g. the attribute is missing alltogether when loaded from DB\n        # https://github.com/tiangolo/sqlmodel/issues/149\n        try:\n            hasattr(self, \"_methods\")\n        except Exception:\n            self._methods = None\n        if not self._methods:\n            try:\n                vendor_module = \".\".join(\n                    [__name__.split(\".\", maxsplit=1)[0], \"vendors\", self.vendor_id]\n                )\n                self._methods = import_module(vendor_module)\n            except Exception as exc:\n                raise NotImplementedError(\n                    f\"Unsupported '{self.vendor_id}' vendor: no methods defined.\"\n                ) from exc\n        return self._methods\n\n    @property\n    def session(self):\n        \"\"\"The Session to use for merging dependent objects into the database.\"\"\"\n        try:\n            return self._session\n        except Exception:\n            return None\n\n    @session.setter\n    def session(self, session: Session):\n        self._session = session\n\n    @session.deleter\n    def session(self):\n        self._session = None\n\n    @property\n    def progress_tracker(self):\n        \"\"\"The [sc_crawler.logger.VendorProgressTracker][] to use for updating progress bars.\"\"\"\n        return self._progress_tracker\n\n    @progress_tracker.setter\n    def progress_tracker(self, progress_tracker: VendorProgressTracker):\n        self._progress_tracker = progress_tracker\n\n    @progress_tracker.deleter\n    def progress_tracker(self):\n        self._progress_tracker = None\n\n    @property\n    def tasks(self):\n        \"\"\"Reexport progress_tracker.tasks for easier access.\"\"\"\n        return self._progress_tracker.tasks\n\n    def log(self, message: str, level: int = logging.INFO):\n        logger.log(level, self.name + \": \" + message, stacklevel=2)\n\n    def set_table_rows_inactive(self, model: str, *args) -&gt; None:\n        \"\"\"Set this vendor's records to [INACTIVE][sc_crawler.table_fields.Status] in a table.\n\n        Positional arguments can be used to pass further filters\n        (besides the default model.vendor_id filter) referencing the\n        model object with SQLModel syntax.\n\n        Examples:\n            &gt;&gt;&gt; aws.set_table_rows_inactive(ServerPrice, ServerPrice.price &lt; 10)  # doctest: +SKIP\n        \"\"\"\n        if self.session:\n            query = update(model).where(model.vendor_id == self.vendor_id)\n            for arg in args:\n                query = query.where(arg)\n            self.session.execute(query.values(status=Status.INACTIVE))\n\n    def _inventory(self, table: ScModel, inventory: Callable):\n        \"\"\"Mark all rows in a table inactive, then insert new/updated items.\"\"\"\n        self.set_table_rows_inactive(table)\n        insert_items(table, inventory(self), self)\n\n    @log_start_end\n    def inventory_compliance_frameworks(self):\n        \"\"\"Get the vendor's all compliance frameworks.\"\"\"\n        self._inventory(\n            VendorComplianceLink, self._get_methods().inventory_compliance_frameworks\n        )\n\n    @log_start_end\n    def inventory_regions(self):\n        \"\"\"Get the vendor's all regions.\"\"\"\n        self._inventory(Region, self._get_methods().inventory_regions)\n\n    @log_start_end\n    def inventory_zones(self):\n        \"\"\"Get all the zones in the vendor's regions.\"\"\"\n        self._inventory(Zone, self._get_methods().inventory_zones)\n\n    @log_start_end\n    def inventory_servers(self):\n        \"\"\"Get the vendor's all server types.\"\"\"\n        self.set_table_rows_inactive(Server)\n        servers = self._get_methods().inventory_servers(self)\n        # show progress bar while downloading\n        self.progress_tracker.start_task(\n            name=\"Downloading sc-inspector-data\", total=None\n        )\n        inspector_data_path()\n        self.progress_tracker.hide_task()\n        # actual HW inspection\n        for server in servers:\n            server = inspect_update_server_dict(server)\n        insert_items(Server, servers, self)\n        benchmarks = []\n        self.progress_tracker.start_task(\n            name=\"Searching for benchmark(s)\", total=len(self.servers)\n        )\n        for server in self.servers:\n            benchmarks += inspect_server_benchmarks(server)\n            self.progress_tracker.advance_task()\n        self.progress_tracker.hide_task()\n        self.set_table_rows_inactive(\n            BenchmarkScore, BenchmarkScore.vendor_id == self.vendor_id\n        )\n        insert_items(BenchmarkScore, benchmarks, self)\n\n    @log_start_end\n    def inventory_server_prices(self):\n        \"\"\"Get the current standard/ondemand/reserved prices of all server types.\"\"\"\n        self.set_table_rows_inactive(\n            ServerPrice, ServerPrice.allocation != Allocation.SPOT\n        )\n        insert_items(\n            ServerPrice,\n            self._get_methods().inventory_server_prices(self),\n            self,\n            prefix=\"ondemand\",\n        )\n\n    @log_start_end\n    def inventory_server_prices_spot(self):\n        \"\"\"Get the current spot prices of all server types.\"\"\"\n        self.set_table_rows_inactive(\n            ServerPrice, ServerPrice.allocation == Allocation.SPOT\n        )\n        insert_items(\n            ServerPrice,\n            self._get_methods().inventory_server_prices_spot(self),\n            self,\n            prefix=\"spot\",\n        )\n\n    @log_start_end\n    def inventory_storages(self):\n        self._inventory(Storage, self._get_methods().inventory_storages)\n\n    @log_start_end\n    def inventory_storage_prices(self):\n        self._inventory(StoragePrice, self._get_methods().inventory_storage_prices)\n\n    @log_start_end\n    def inventory_traffic_prices(self):\n        self._inventory(TrafficPrice, self._get_methods().inventory_traffic_prices)\n\n    @log_start_end\n    def inventory_ipv4_prices(self):\n        self._inventory(Ipv4Price, self._get_methods().inventory_ipv4_prices)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.session","title":"session  <code>deletable</code> <code>property</code> <code>writable</code>","text":"<pre><code>session\n</code></pre> <p>The Session to use for merging dependent objects into the database.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.progress_tracker","title":"progress_tracker  <code>deletable</code> <code>property</code> <code>writable</code>","text":"<pre><code>progress_tracker\n</code></pre> <p>The sc_crawler.logger.VendorProgressTracker to use for updating progress bars.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.tasks","title":"tasks  <code>property</code>","text":"<pre><code>tasks\n</code></pre> <p>Reexport progress_tracker.tasks for easier access.</p>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.set_table_rows_inactive","title":"set_table_rows_inactive","text":"<pre><code>set_table_rows_inactive(model, *args)\n</code></pre> <p>Set this vendor's records to INACTIVE in a table.</p> <p>Positional arguments can be used to pass further filters (besides the default model.vendor_id filter) referencing the model object with SQLModel syntax.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; aws.set_table_rows_inactive(ServerPrice, ServerPrice.price &lt; 10)\n</code></pre> Source code in <code>sc_crawler/tables.py</code> <pre><code>def set_table_rows_inactive(self, model: str, *args) -&gt; None:\n    \"\"\"Set this vendor's records to [INACTIVE][sc_crawler.table_fields.Status] in a table.\n\n    Positional arguments can be used to pass further filters\n    (besides the default model.vendor_id filter) referencing the\n    model object with SQLModel syntax.\n\n    Examples:\n        &gt;&gt;&gt; aws.set_table_rows_inactive(ServerPrice, ServerPrice.price &lt; 10)  # doctest: +SKIP\n    \"\"\"\n    if self.session:\n        query = update(model).where(model.vendor_id == self.vendor_id)\n        for arg in args:\n            query = query.where(arg)\n        self.session.execute(query.values(status=Status.INACTIVE))\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks()\n</code></pre> <p>Get the vendor's all compliance frameworks.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_compliance_frameworks(self):\n    \"\"\"Get the vendor's all compliance frameworks.\"\"\"\n    self._inventory(\n        VendorComplianceLink, self._get_methods().inventory_compliance_frameworks\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions()\n</code></pre> <p>Get the vendor's all regions.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_regions(self):\n    \"\"\"Get the vendor's all regions.\"\"\"\n    self._inventory(Region, self._get_methods().inventory_regions)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones()\n</code></pre> <p>Get all the zones in the vendor's regions.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_zones(self):\n    \"\"\"Get all the zones in the vendor's regions.\"\"\"\n    self._inventory(Zone, self._get_methods().inventory_zones)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers()\n</code></pre> <p>Get the vendor's all server types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_servers(self):\n    \"\"\"Get the vendor's all server types.\"\"\"\n    self.set_table_rows_inactive(Server)\n    servers = self._get_methods().inventory_servers(self)\n    # show progress bar while downloading\n    self.progress_tracker.start_task(\n        name=\"Downloading sc-inspector-data\", total=None\n    )\n    inspector_data_path()\n    self.progress_tracker.hide_task()\n    # actual HW inspection\n    for server in servers:\n        server = inspect_update_server_dict(server)\n    insert_items(Server, servers, self)\n    benchmarks = []\n    self.progress_tracker.start_task(\n        name=\"Searching for benchmark(s)\", total=len(self.servers)\n    )\n    for server in self.servers:\n        benchmarks += inspect_server_benchmarks(server)\n        self.progress_tracker.advance_task()\n    self.progress_tracker.hide_task()\n    self.set_table_rows_inactive(\n        BenchmarkScore, BenchmarkScore.vendor_id == self.vendor_id\n    )\n    insert_items(BenchmarkScore, benchmarks, self)\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices()\n</code></pre> <p>Get the current standard/ondemand/reserved prices of all server types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_server_prices(self):\n    \"\"\"Get the current standard/ondemand/reserved prices of all server types.\"\"\"\n    self.set_table_rows_inactive(\n        ServerPrice, ServerPrice.allocation != Allocation.SPOT\n    )\n    insert_items(\n        ServerPrice,\n        self._get_methods().inventory_server_prices(self),\n        self,\n        prefix=\"ondemand\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Vendor.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot()\n</code></pre> <p>Get the current spot prices of all server types.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>@log_start_end\ndef inventory_server_prices_spot(self):\n    \"\"\"Get the current spot prices of all server types.\"\"\"\n    self.set_table_rows_inactive(\n        ServerPrice, ServerPrice.allocation == Allocation.SPOT\n    )\n    insert_items(\n        ServerPrice,\n        self._get_methods().inventory_server_prices_spot(self),\n        self,\n        prefix=\"spot\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.VendorComplianceLink","title":"VendorComplianceLink","text":"<p>               Bases: <code>VendorComplianceLinkBase</code></p> <p>List of known Compliance Frameworks paired with vendors.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>compliance_framework_id</code> <code>str</code> <p>Reference to the Compliance Framework.</p> <code>comment</code> <code>Optional[str]</code> <p>Optional references, such as dates, URLs, and additional information/evidence.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class VendorComplianceLink(VendorComplianceLinkBase, table=True):\n    \"\"\"List of known Compliance Frameworks paired with vendors.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"compliance_framework_links\")\n    compliance_framework: ComplianceFramework = Relationship(\n        back_populates=\"vendor_links\"\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Region","title":"Region","text":"<p>               Bases: <code>RegionBase</code></p> <p>Regions of Vendors.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depening on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>aliases</code> <code>List[str]</code> <p>List of other commonly used names for the same Region.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Region is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Region's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Region's location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Region's location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Region's location.</p> <code>lon</code> <code>Optional[float]</code> <p>Longitude coordinate of the Region's known or approximate location.</p> <code>lat</code> <code>Optional[float]</code> <p>Latitude coordinate of the Region's known or approximate location.</p> <code>founding_year</code> <code>Optional[int]</code> <p>4-digit year when the Region was founded.</p> <code>green_energy</code> <code>Optional[bool]</code> <p>If the Region is 100% powered by renewable energy.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Region(RegionBase, table=True):\n    \"\"\"Regions of Vendors.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"regions\")\n    country: Country = Relationship(back_populates=\"regions\")\n\n    zones: List[\"Zone\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    server_prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    traffic_prices: List[\"TrafficPrice\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    ipv4_prices: List[\"Ipv4Price\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    storage_prices: List[\"StoragePrice\"] = Relationship(\n        back_populates=\"region\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Zone","title":"Zone","text":"<p>               Bases: <code>ZoneBase</code></p> <p>Availability zones of Regions.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depening on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Zone(ZoneBase, table=True):\n    \"\"\"Availability zones of Regions.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n    )\n\n    region: Region = Relationship(\n        back_populates=\"zones\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(Zone.region_id), \"\n                \"Region.vendor_id == foreign(Zone.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n    vendor: Vendor = Relationship(back_populates=\"zones\")\n\n    server_prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"zone\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Storage","title":"Storage","text":"<p>               Bases: <code>StorageBase</code></p> <p>Flexible storage options that can be attached to a Server.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>storage_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>storage_type</code> <code>StorageType</code> <p>High-level category of the storage, e.g. HDD or SDD.</p> <code>max_iops</code> <code>Optional[int]</code> <p>Maximum Input/Output Operations Per Second.</p> <code>max_throughput</code> <code>Optional[int]</code> <p>Maximum Throughput (MiB/s).</p> <code>min_size</code> <code>Optional[int]</code> <p>Minimum required size (GiB).</p> <code>max_size</code> <code>Optional[int]</code> <p>Maximum possible size (GiB).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Storage(StorageBase, table=True):\n    \"\"\"Flexible storage options that can be attached to a Server.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"storages\")\n\n    prices: List[\"StoragePrice\"] = Relationship(\n        back_populates=\"storage\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Server","title":"Server","text":"<p>               Bases: <code>ServerBase</code></p> <p>Server types.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depening on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>family</code> <code>Optional[str]</code> <p>Server family, e.g. General-purpose machine (GCP), or M5g (AWS).</p> <code>vcpus</code> <code>int</code> <p>Default number of virtual CPUs (vCPU) of the server.</p> <code>hypervisor</code> <code>Optional[str]</code> <p>Hypervisor of the virtual server, e.g. Xen, KVM, Nitro or Dedicated.</p> <code>cpu_allocation</code> <code>CpuAllocation</code> <p>Allocation of CPU(s) to the server, e.g. shared, burstable or dedicated.</p> <code>cpu_cores</code> <code>Optional[int]</code> <p>Default number of CPU cores of the server. Equals to vCPUs when HyperThreading is disabled.</p> <code>cpu_speed</code> <code>Optional[float]</code> <p>Vendor-reported maximum CPU clock speed (GHz).</p> <code>cpu_architecture</code> <code>CpuArchitecture</code> <p>CPU architecture (arm64, arm64_mac, i386, or x86_64).</p> <code>cpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary processor, e.g. Intel or AMD.</p> <code>cpu_family</code> <code>Optional[str]</code> <p>The product line/family of the primary processor, e.g. Xeon, Core i7, Ryzen 9.</p> <code>cpu_model</code> <code>Optional[str]</code> <p>The model number of the primary processor, e.g. 9750H.</p> <code>cpu_l1_cache</code> <code>Optional[int]</code> <p>L1 cache size (byte).</p> <code>cpu_l2_cache</code> <code>Optional[int]</code> <p>L2 cache size (byte).</p> <code>cpu_l3_cache</code> <code>Optional[int]</code> <p>L3 cache size (byte).</p> <code>cpu_flags</code> <code>List[str]</code> <p>CPU features/flags.</p> <code>cpus</code> <code>List[Cpu]</code> <p>JSON array of known CPU details, e.g. the manufacturer, family, model; L1/L2/L3 cache size; microcode version; feature flags; bugs etc.</p> <code>memory_amount</code> <code>int</code> <p>RAM amount (MiB).</p> <code>memory_generation</code> <code>Optional[DdrGeneration]</code> <p>Generation of the DDR SDRAM, e.g. DDR4 or DDR5.</p> <code>memory_speed</code> <code>Optional[int]</code> <p>DDR SDRAM clock rate (Mhz).</p> <code>memory_ecc</code> <code>Optional[bool]</code> <p>If the DDR SDRAM uses error correction code to detect and correct n-bit data corruption.</p> <code>gpu_count</code> <code>int</code> <p>Number of GPU accelerator(s).</p> <code>gpu_memory_min</code> <code>Optional[int]</code> <p>Memory (MiB) allocated to the lowest-end GPU accelerator.</p> <code>gpu_memory_total</code> <code>Optional[int]</code> <p>Overall memory (MiB) allocated to all the GPU accelerator(s).</p> <code>gpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary GPU accelerator, e.g. Nvidia or AMD.</p> <code>gpu_family</code> <code>Optional[str]</code> <p>The product family of the primary GPU accelerator, e.g. Turing.</p> <code>gpu_model</code> <code>Optional[str]</code> <p>The model number of the primary GPU accelerator, e.g. Tesla T4.</p> <code>gpus</code> <code>List[Gpu]</code> <p>JSON array of GPU accelerator details, including the manufacturer, name, and memory (MiB) of each GPU.</p> <code>storage_size</code> <code>int</code> <p>Overall size (GB) of the disk(s).</p> <code>storage_type</code> <code>Optional[StorageType]</code> <p>Primary disk type, e.g. HDD, SSD, NVMe SSD, or network).</p> <code>storages</code> <code>List[Disk]</code> <p>JSON array of disks attached to the server, including the size (MiB) and type of each disk.</p> <code>network_speed</code> <code>Optional[float]</code> <p>The baseline network performance (Gbps) of the network card.</p> <code>inbound_traffic</code> <code>float</code> <p>Amount of complimentary inbound traffic (GB) per month.</p> <code>outbound_traffic</code> <code>float</code> <p>Amount of complimentary outbound traffic (GB) per month.</p> <code>ipv4</code> <code>int</code> <p>Number of complimentary IPv4 address(es).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Server(ServerBase, table=True):\n    \"\"\"Server types.\"\"\"\n\n    vendor: Vendor = Relationship(back_populates=\"servers\")\n    prices: List[\"ServerPrice\"] = Relationship(\n        back_populates=\"server\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n    benchmark_scores: List[\"BenchmarkScore\"] = Relationship(\n        back_populates=\"server\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.ServerPrice","title":"ServerPrice","text":"<p>               Bases: <code>ServerPriceBase</code></p> <p>Server type prices per Region and Allocation method.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Reference to the Zone.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>operating_system</code> <code>str</code> <p>Operating System.</p> <code>allocation</code> <code>Allocation</code> <p>Allocation method, e.g. on-demand or spot.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class ServerPrice(ServerPriceBase, table=True):\n    \"\"\"Server type prices per Region and Allocation method.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\", \"zone_id\"],\n            [\"zone.vendor_id\", \"zone.region_id\", \"zone.zone_id\"],\n        ),\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"server_id\"],\n            [\"server.vendor_id\", \"server.server_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"server_prices\")\n    region: Region = Relationship(\n        back_populates=\"server_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(ServerPrice.region_id), \"\n                \"Region.vendor_id == foreign(ServerPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,zone,server\",\n        },\n    )\n    zone: Zone = Relationship(\n        back_populates=\"server_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Zone.zone_id == foreign(ServerPrice.zone_id), \"\n                \"Zone.region_id == foreign(ServerPrice.region_id),\"\n                \"Zone.vendor_id == foreign(ServerPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,region,server\",\n        },\n    )\n    server: Server = Relationship(\n        back_populates=\"prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Server.server_id == foreign(ServerPrice.server_id), \"\n                \"Server.vendor_id == foreign(ServerPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,region,zone\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.StoragePrice","title":"StoragePrice","text":"<p>               Bases: <code>StoragePriceBase</code></p> <p>Flexible Storage prices in each Region.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>storage_id</code> <code>str</code> <p>Reference to the Storage.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class StoragePrice(StoragePriceBase, table=True):\n    \"\"\"Flexible Storage prices in each Region.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"storage_id\"],\n            [\"storage.vendor_id\", \"storage.storage_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"storage_prices\")\n    region: Region = Relationship(\n        back_populates=\"storage_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(StoragePrice.region_id),\"\n                \"Region.vendor_id == foreign(StoragePrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,storage\",\n        },\n    )\n    storage: Storage = Relationship(\n        back_populates=\"prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Storage.storage_id == foreign(StoragePrice.storage_id), \"\n                \"Storage.vendor_id == foreign(StoragePrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor,region\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.TrafficPrice","title":"TrafficPrice","text":"<p>               Bases: <code>TrafficPriceBase</code></p> <p>Extra Traffic prices in each Region.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>direction</code> <code>TrafficDirection</code> <p>Direction of the traffic: inbound or outbound.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class TrafficPrice(TrafficPriceBase, table=True):\n    \"\"\"Extra Traffic prices in each Region.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"traffic_prices\")\n    region: Region = Relationship(\n        back_populates=\"traffic_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(TrafficPrice.region_id),\"\n                \"Region.vendor_id == foreign(TrafficPrice.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Ipv4Price","title":"Ipv4Price","text":"<p>               Bases: <code>Ipv4PriceBase</code></p> <p>Price of an IPv4 address in each Region.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Ipv4Price(Ipv4PriceBase, table=True):\n    \"\"\"Price of an IPv4 address in each Region.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"region_id\"],\n            [\"region.vendor_id\", \"region.region_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"ipv4_prices\")\n    region: Region = Relationship(\n        back_populates=\"ipv4_prices\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Region.region_id == foreign(Ipv4Price.region_id),\"\n                \"Region.vendor_id == foreign(Ipv4Price.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.Benchmark","title":"Benchmark","text":"<p>               Bases: <code>BenchmarkBase</code></p> <p>Benchmark scenario definitions.</p> <p>Attributes:</p> Name Type Description <code>benchmark_id</code> <code>str</code> <p>Unique identifier of a specific Benchmark.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>framework</code> <code>str</code> <p>The name of the benchmark framework/software/tool used.</p> <code>config_fields</code> <code>dict</code> <p>A dictionary of descriptions on the framework-specific config options, e.g. {\"bandwidth\": \"Memory amount to use for compression in MB.\"}.</p> <code>measurement</code> <code>Optional[str]</code> <p>The name of measurement recoreded in the benchmark.</p> <code>unit</code> <code>Optional[str]</code> <p>Optional unit of measurement for the benchmark score.</p> <code>higher_is_better</code> <code>bool</code> <p>If higher benchmark score means better performance, or vica versa.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class Benchmark(BenchmarkBase, table=True):\n    \"\"\"Benchmark scenario definitions.\"\"\"\n\n    benchmark_scores: List[\"BenchmarkScore\"] = Relationship(\n        back_populates=\"benchmark\", sa_relationship_kwargs={\"viewonly\": True}\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.BenchmarkScore","title":"BenchmarkScore","text":"<p>               Bases: <code>BenchmarkScoreBase</code></p> <p>Results of running Benchmark scenarios on Servers.</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>benchmark_id</code> <code>str</code> <p>Reference to the Benchmark.</p> <code>config</code> <code>HashableDict | dict</code> <p>Dictionary of config parameters of the specific benchmark, e.g. {\"bandwidth\": 4096}</p> <code>score</code> <code>float</code> <p>The resulting score of the benchmark.</p> <code>note</code> <code>Optional[str]</code> <p>Optional note, comment or context on the benchmark score.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables.py</code> <pre><code>class BenchmarkScore(BenchmarkScoreBase, table=True):\n    \"\"\"Results of running Benchmark scenarios on Servers.\"\"\"\n\n    __table_args__ = (\n        ForeignKeyConstraint(\n            [\"vendor_id\", \"server_id\"],\n            [\"server.vendor_id\", \"server.server_id\"],\n        ),\n    )\n    vendor: Vendor = Relationship(back_populates=\"benchmark_scores\")\n    server: Server = Relationship(\n        back_populates=\"benchmark_scores\",\n        sa_relationship_kwargs={\n            \"primaryjoin\": (\n                \"and_(Server.server_id == foreign(BenchmarkScore.server_id), \"\n                \"Server.vendor_id == foreign(BenchmarkScore.vendor_id))\"\n            ),\n            \"overlaps\": \"vendor\",\n        },\n    )\n    benchmark: Benchmark = Relationship(back_populates=\"benchmark_scores\")\n</code></pre>"},{"location":"reference/sc_crawler/tables/#sc_crawler.tables.tables","title":"tables  <code>module-attribute</code>","text":"<pre><code>tables = [o for o in values() if is_table(o)]\n</code></pre> <p>List of all SQLModel (table) models.</p>"},{"location":"reference/sc_crawler/tables_scd/","title":"tables_scd","text":""},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd","title":"sc_crawler.tables_scd","text":"<p>SCD version of the table definitions in sc_crawler.tables.</p>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.Scd","title":"Scd","text":"<p>               Bases: <code>ScModel</code></p> <p>Override the <code>observed_at</code> column to be primary key in SCD tables.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class Scd(ScModel):\n    \"\"\"Override the `observed_at` column to be primary key in SCD tables.\"\"\"\n\n    observed_at: datetime = Field(\n        primary_key=True,\n        default_factory=datetime.utcnow,\n        sa_column_kwargs={\"onupdate\": datetime.utcnow},\n        description=\"Timestamp of the last observation.\",\n    )\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.CountryScd","title":"CountryScd","text":"<p>               Bases: <code>Scd</code>, <code>CountryBase</code></p> <p>Country and continent mapping (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>country_id</code> <code>str</code> <p>Country code by ISO 3166 alpha-2.</p> <code>continent</code> <code>str</code> <p>Continent name.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class CountryScd(Scd, CountryBase, table=True):\n    \"\"\"SCD version of .tables.Country.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.VendorComplianceLinkScd","title":"VendorComplianceLinkScd","text":"<p>               Bases: <code>Scd</code>, <code>VendorComplianceLinkBase</code></p> <p>List of known Compliance Frameworks paired with vendors (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>compliance_framework_id</code> <code>str</code> <p>Reference to the Compliance Framework.</p> <code>comment</code> <code>Optional[str]</code> <p>Optional references, such as dates, URLs, and additional information/evidence.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class VendorComplianceLinkScd(Scd, VendorComplianceLinkBase, table=True):\n    \"\"\"SCD version of .tables.VendorComplianceLink.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ComplianceFrameworkScd","title":"ComplianceFrameworkScd","text":"<p>               Bases: <code>Scd</code>, <code>ComplianceFrameworkBase</code></p> <p>List of Compliance Frameworks, such as HIPAA or SOC 2 Type 1 (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>compliance_framework_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>abbreviation</code> <code>Optional[str]</code> <p>Short abbreviation of the Framework name.</p> <code>description</code> <code>Optional[str]</code> <p>Description of the framework in a few paragrahs, outlining key features and characteristics for reference.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Framework's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage with more information on the Framework.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ComplianceFrameworkScd(Scd, ComplianceFrameworkBase, table=True):\n    \"\"\"SCD version of .tables.ComplianceFramework.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.VendorScd","title":"VendorScd","text":"<p>               Bases: <code>Scd</code>, <code>VendorBase</code></p> <p>Compute resource vendors, such as cloud and server providers (SCD Type 2).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sc_crawler.tables import Vendor\n&gt;&gt;&gt; from sc_crawler.lookup import countries\n&gt;&gt;&gt; aws = Vendor(vendor_id='aws', name='Amazon Web Services', homepage='https://aws.amazon.com', country=countries[\"US\"], founding_year=2002)\n&gt;&gt;&gt; aws\nVendor(vendor_id='aws'...\n&gt;&gt;&gt; from sc_crawler import vendors\n&gt;&gt;&gt; vendors.aws\nVendor(vendor_id='aws'...\n</code></pre> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Unique identifier.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>logo</code> <code>Optional[str]</code> <p>Publicly accessible URL to the image of the Vendor's logo.</p> <code>homepage</code> <code>Optional[str]</code> <p>Public homepage of the Vendor.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Vendor's main headquarter is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Vendor's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Vendor's main location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Vendor's main location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Vendor's main location.</p> <code>founding_year</code> <code>int</code> <p>4-digit year when the Vendor was founded.</p> <code>status_page</code> <code>Optional[str]</code> <p>Public status page of the Vendor.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class VendorScd(Scd, VendorBase, table=True):\n    \"\"\"SCD version of .tables.Vendor.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.RegionScd","title":"RegionScd","text":"<p>               Bases: <code>Scd</code>, <code>RegionBase</code></p> <p>Regions of Vendors (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depening on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>aliases</code> <code>List[str]</code> <p>List of other commonly used names for the same Region.</p> <code>country_id</code> <code>str</code> <p>Reference to the Country, where the Region is located.</p> <code>state</code> <code>Optional[str]</code> <p>Optional state/administrative area of the Region's location within the Country.</p> <code>city</code> <code>Optional[str]</code> <p>Optional city name of the Region's location.</p> <code>address_line</code> <code>Optional[str]</code> <p>Optional address line of the Region's location.</p> <code>zip_code</code> <code>Optional[str]</code> <p>Optional ZIP code of the Region's location.</p> <code>lon</code> <code>Optional[float]</code> <p>Longitude coordinate of the Region's known or approximate location.</p> <code>lat</code> <code>Optional[float]</code> <p>Latitude coordinate of the Region's known or approximate location.</p> <code>founding_year</code> <code>Optional[int]</code> <p>4-digit year when the Region was founded.</p> <code>green_energy</code> <code>Optional[bool]</code> <p>If the Region is 100% powered by renewable energy.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class RegionScd(Scd, RegionBase, table=True):\n    \"\"\"SCD version of .tables.Region.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ZoneScd","title":"ZoneScd","text":"<p>               Bases: <code>Scd</code>, <code>ZoneBase</code></p> <p>Availability zones of Regions (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depening on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ZoneScd(Scd, ZoneBase, table=True):\n    \"\"\"SCD version of .tables.Zone.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.StorageScd","title":"StorageScd","text":"<p>               Bases: <code>Scd</code>, <code>StorageBase</code></p> <p>Flexible storage options that can be attached to a Server (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>storage_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>storage_type</code> <code>StorageType</code> <p>High-level category of the storage, e.g. HDD or SDD.</p> <code>max_iops</code> <code>Optional[int]</code> <p>Maximum Input/Output Operations Per Second.</p> <code>max_throughput</code> <code>Optional[int]</code> <p>Maximum Throughput (MiB/s).</p> <code>min_size</code> <code>Optional[int]</code> <p>Minimum required size (GiB).</p> <code>max_size</code> <code>Optional[int]</code> <p>Maximum possible size (GiB).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class StorageScd(Scd, StorageBase, table=True):\n    \"\"\"SCD version of .tables.Storage.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ServerScd","title":"ServerScd","text":"<p>               Bases: <code>Scd</code>, <code>ServerBase</code></p> <p>Server types (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Unique identifier, as called at the Vendor.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>api_reference</code> <code>str</code> <p>How this resource is referenced in the vendor API calls. This is usually either the id or name of the resource, depening on the vendor and actual API endpoint.</p> <code>display_name</code> <code>str</code> <p>Human-friendly reference (usually the id or name) of the resource.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>family</code> <code>Optional[str]</code> <p>Server family, e.g. General-purpose machine (GCP), or M5g (AWS).</p> <code>vcpus</code> <code>int</code> <p>Default number of virtual CPUs (vCPU) of the server.</p> <code>hypervisor</code> <code>Optional[str]</code> <p>Hypervisor of the virtual server, e.g. Xen, KVM, Nitro or Dedicated.</p> <code>cpu_allocation</code> <code>CpuAllocation</code> <p>Allocation of CPU(s) to the server, e.g. shared, burstable or dedicated.</p> <code>cpu_cores</code> <code>Optional[int]</code> <p>Default number of CPU cores of the server. Equals to vCPUs when HyperThreading is disabled.</p> <code>cpu_speed</code> <code>Optional[float]</code> <p>Vendor-reported maximum CPU clock speed (GHz).</p> <code>cpu_architecture</code> <code>CpuArchitecture</code> <p>CPU architecture (arm64, arm64_mac, i386, or x86_64).</p> <code>cpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary processor, e.g. Intel or AMD.</p> <code>cpu_family</code> <code>Optional[str]</code> <p>The product line/family of the primary processor, e.g. Xeon, Core i7, Ryzen 9.</p> <code>cpu_model</code> <code>Optional[str]</code> <p>The model number of the primary processor, e.g. 9750H.</p> <code>cpu_l1_cache</code> <code>Optional[int]</code> <p>L1 cache size (byte).</p> <code>cpu_l2_cache</code> <code>Optional[int]</code> <p>L2 cache size (byte).</p> <code>cpu_l3_cache</code> <code>Optional[int]</code> <p>L3 cache size (byte).</p> <code>cpu_flags</code> <code>List[str]</code> <p>CPU features/flags.</p> <code>cpus</code> <code>List[Cpu]</code> <p>JSON array of known CPU details, e.g. the manufacturer, family, model; L1/L2/L3 cache size; microcode version; feature flags; bugs etc.</p> <code>memory_amount</code> <code>int</code> <p>RAM amount (MiB).</p> <code>memory_generation</code> <code>Optional[DdrGeneration]</code> <p>Generation of the DDR SDRAM, e.g. DDR4 or DDR5.</p> <code>memory_speed</code> <code>Optional[int]</code> <p>DDR SDRAM clock rate (Mhz).</p> <code>memory_ecc</code> <code>Optional[bool]</code> <p>If the DDR SDRAM uses error correction code to detect and correct n-bit data corruption.</p> <code>gpu_count</code> <code>int</code> <p>Number of GPU accelerator(s).</p> <code>gpu_memory_min</code> <code>Optional[int]</code> <p>Memory (MiB) allocated to the lowest-end GPU accelerator.</p> <code>gpu_memory_total</code> <code>Optional[int]</code> <p>Overall memory (MiB) allocated to all the GPU accelerator(s).</p> <code>gpu_manufacturer</code> <code>Optional[str]</code> <p>The manufacturer of the primary GPU accelerator, e.g. Nvidia or AMD.</p> <code>gpu_family</code> <code>Optional[str]</code> <p>The product family of the primary GPU accelerator, e.g. Turing.</p> <code>gpu_model</code> <code>Optional[str]</code> <p>The model number of the primary GPU accelerator, e.g. Tesla T4.</p> <code>gpus</code> <code>List[Gpu]</code> <p>JSON array of GPU accelerator details, including the manufacturer, name, and memory (MiB) of each GPU.</p> <code>storage_size</code> <code>int</code> <p>Overall size (GB) of the disk(s).</p> <code>storage_type</code> <code>Optional[StorageType]</code> <p>Primary disk type, e.g. HDD, SSD, NVMe SSD, or network).</p> <code>storages</code> <code>List[Disk]</code> <p>JSON array of disks attached to the server, including the size (MiB) and type of each disk.</p> <code>network_speed</code> <code>Optional[float]</code> <p>The baseline network performance (Gbps) of the network card.</p> <code>inbound_traffic</code> <code>float</code> <p>Amount of complimentary inbound traffic (GB) per month.</p> <code>outbound_traffic</code> <code>float</code> <p>Amount of complimentary outbound traffic (GB) per month.</p> <code>ipv4</code> <code>int</code> <p>Number of complimentary IPv4 address(es).</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ServerScd(Scd, ServerBase, table=True):\n    \"\"\"SCD version of .tables.Server.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.ServerPriceScd","title":"ServerPriceScd","text":"<p>               Bases: <code>Scd</code>, <code>ServerPriceBase</code></p> <p>Server type prices per Region and Allocation method (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>zone_id</code> <code>str</code> <p>Reference to the Zone.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>operating_system</code> <code>str</code> <p>Operating System.</p> <code>allocation</code> <code>Allocation</code> <p>Allocation method, e.g. on-demand or spot.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class ServerPriceScd(Scd, ServerPriceBase, table=True):\n    \"\"\"SCD version of .tables.ServerPrice.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.StoragePriceScd","title":"StoragePriceScd","text":"<p>               Bases: <code>Scd</code>, <code>StoragePriceBase</code></p> <p>Flexible Storage prices in each Region (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>storage_id</code> <code>str</code> <p>Reference to the Storage.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class StoragePriceScd(Scd, StoragePriceBase, table=True):\n    \"\"\"SCD version of .tables.StoragePrice.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.TrafficPriceScd","title":"TrafficPriceScd","text":"<p>               Bases: <code>Scd</code>, <code>TrafficPriceBase</code></p> <p>Extra Traffic prices in each Region (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>direction</code> <code>TrafficDirection</code> <p>Direction of the traffic: inbound or outbound.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class TrafficPriceScd(Scd, TrafficPriceBase, table=True):\n    \"\"\"SCD version of .tables.TrafficPrice.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.Ipv4PriceScd","title":"Ipv4PriceScd","text":"<p>               Bases: <code>Scd</code>, <code>Ipv4PriceBase</code></p> <p>Price of an IPv4 address in each Region (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>region_id</code> <code>str</code> <p>Reference to the Region.</p> <code>unit</code> <code>PriceUnit</code> <p>Billing unit of the pricing model.</p> <code>price</code> <code>float</code> <p>Actual price of a billing unit.</p> <code>price_upfront</code> <code>float</code> <p>Price to be paid when setting up the resource.</p> <code>price_tiered</code> <code>List[PriceTier]</code> <p>List of pricing tiers with min/max thresholds and actual prices.</p> <code>currency</code> <code>str</code> <p>Currency of the prices.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class Ipv4PriceScd(Scd, Ipv4PriceBase, table=True):\n    \"\"\"SCD version of .tables.Ipv4Price.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.BenchmarkScd","title":"BenchmarkScd","text":"<p>               Bases: <code>Scd</code>, <code>BenchmarkBase</code></p> <p>Benchmark scenario definitions (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>benchmark_id</code> <code>str</code> <p>Unique identifier of a specific Benchmark.</p> <code>name</code> <code>str</code> <p>Human-friendly name.</p> <code>description</code> <code>Optional[str]</code> <p>Short description.</p> <code>framework</code> <code>str</code> <p>The name of the benchmark framework/software/tool used.</p> <code>config_fields</code> <code>dict</code> <p>A dictionary of descriptions on the framework-specific config options, e.g. {\"bandwidth\": \"Memory amount to use for compression in MB.\"}.</p> <code>measurement</code> <code>Optional[str]</code> <p>The name of measurement recoreded in the benchmark.</p> <code>unit</code> <code>Optional[str]</code> <p>Optional unit of measurement for the benchmark score.</p> <code>higher_is_better</code> <code>bool</code> <p>If higher benchmark score means better performance, or vica versa.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class BenchmarkScd(Scd, BenchmarkBase, table=True):\n    \"\"\"SCD version of .tables.Benchmark.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.BenchmarkScoreScd","title":"BenchmarkScoreScd","text":"<p>               Bases: <code>Scd</code>, <code>BenchmarkScoreBase</code></p> <p>Results of running Benchmark scenarios on Servers (SCD Type 2).</p> <p>Attributes:</p> Name Type Description <code>vendor_id</code> <code>str</code> <p>Reference to the Vendor.</p> <code>server_id</code> <code>str</code> <p>Reference to the Server.</p> <code>benchmark_id</code> <code>str</code> <p>Reference to the Benchmark.</p> <code>config</code> <code>HashableDict | dict</code> <p>Dictionary of config parameters of the specific benchmark, e.g. {\"bandwidth\": 4096}</p> <code>score</code> <code>float</code> <p>The resulting score of the benchmark.</p> <code>note</code> <code>Optional[str]</code> <p>Optional note, comment or context on the benchmark score.</p> <code>status</code> <code>Status</code> <p>Status of the resource (active or inactive).</p> <code>observed_at</code> <code>datetime</code> <p>Timestamp of the last observation.</p> Source code in <code>sc_crawler/tables_scd.py</code> <pre><code>class BenchmarkScoreScd(Scd, BenchmarkScoreBase, table=True):\n    \"\"\"SCD version of .tables.BenchmarkScore.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sc_crawler/tables_scd/#sc_crawler.tables_scd.tables_scd","title":"tables_scd  <code>module-attribute</code>","text":"<pre><code>tables_scd = [o for o in values() if is_table(o)]\n</code></pre> <p>List of all SCD SQLModel (table) models.</p>"},{"location":"reference/sc_crawler/utils/","title":"utils","text":""},{"location":"reference/sc_crawler/utils/#sc_crawler.utils","title":"sc_crawler.utils","text":""},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.jsoned_hash","title":"jsoned_hash","text":"<pre><code>jsoned_hash(*args, **kwargs)\n</code></pre> <p>Hash the JSON-dump of all positional and keyword arguments.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; jsoned_hash(42)\n'0211c62419aece235ba19582d3cf7fd8e25f837c'\n&gt;&gt;&gt; jsoned_hash(everything=42)\n'8f8a7fcade8cb632b856f46fc64c1725ee387617'\n&gt;&gt;&gt; jsoned_hash(42, 42, everything=42)\n'f04a77f000d85929b13de04b436c60a1272dfbf5'\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def jsoned_hash(*args, **kwargs):\n    \"\"\"Hash the JSON-dump of all positional and keyword arguments.\n\n    Examples:\n        &gt;&gt;&gt; jsoned_hash(42)\n        '0211c62419aece235ba19582d3cf7fd8e25f837c'\n        &gt;&gt;&gt; jsoned_hash(everything=42)\n        '8f8a7fcade8cb632b856f46fc64c1725ee387617'\n        &gt;&gt;&gt; jsoned_hash(42, 42, everything=42)\n        'f04a77f000d85929b13de04b436c60a1272dfbf5'\n    \"\"\"\n    return sha1(\n        dumps({\"args\": args, \"kwargs\": kwargs}, sort_keys=True).encode()\n    ).hexdigest()\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.hash_database","title":"hash_database","text":"<pre><code>hash_database(connection_string, level=HashLevels.DATABASE, ignored=['observed_at'], progress=None, exclude_tables=[])\n</code></pre> <p>Hash the content of a database.</p> <p>Parameters:</p> Name Type Description Default <code>connection_string</code> <code>str</code> <p>SQLAlchemy connection string to connect to the database.</p> required <code>level</code> <code>HashLevels</code> <p>The level at which to apply hashing. Possible values are 'DATABASE' (default), 'TABLE', or 'ROW'.</p> <code>DATABASE</code> <code>ignored</code> <code>List[str]</code> <p>List of column names to be ignored during hashing.</p> <code>['observed_at']</code> <code>progress</code> <code>Optional[Progress]</code> <p>Optional progress bar to track the status of the hashing.</p> <code>None</code> <code>exclude_tables</code> <code>List[ScModel]</code> <p>Optional list of tables not to be hashed.</p> <code>[]</code> <p>Returns:</p> Type Description <code>Union[str, dict]</code> <p>A single SHA1 hash or dict of hashes, depending on the level.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def hash_database(\n    connection_string: str,\n    level: HashLevels = HashLevels.DATABASE,\n    ignored: List[str] = [\"observed_at\"],\n    progress: Optional[Progress] = None,\n    exclude_tables: List[ScModel] = [],\n) -&gt; Union[str, dict]:\n    \"\"\"Hash the content of a database.\n\n    Args:\n        connection_string: SQLAlchemy connection string to connect to the database.\n        level: The level at which to apply hashing. Possible values are 'DATABASE' (default), 'TABLE', or 'ROW'.\n        ignored: List of column names to be ignored during hashing.\n        progress: Optional progress bar to track the status of the hashing.\n        exclude_tables: Optional list of tables not to be hashed.\n\n    Returns:\n        A single SHA1 hash or dict of hashes, depending on the level.\n    \"\"\"\n    from .tables import tables as alltables\n\n    tables_to_sync = [t for t in alltables if t not in exclude_tables]\n\n    if progress:\n        tables_task_id = progress.add_task(\"Hashing tables\", total=len(tables_to_sync))\n\n    engine = create_engine(connection_string)\n\n    with Session(engine) as session:\n        hashes = {}\n        for table in tables_to_sync:\n            table_name = table.get_table_name()\n            hashes[table_name] = table.hash(session, ignored=ignored, progress=progress)\n            if progress:\n                progress.update(tables_task_id, advance=1)\n\n    if level == HashLevels.TABLE:\n        hashes = {k: jsoned_hash(v) for k, v in hashes.items()}\n\n    if level == HashLevels.DATABASE:\n        hashes = jsoned_hash(hashes)\n\n    return hashes\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.chunk_list","title":"chunk_list","text":"<pre><code>chunk_list(items, size)\n</code></pre> <p>Split a list into chunks of a specified size.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; [len(x) for x in chunk_list(range(10), 3)]\n[3, 3, 3, 1]\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def chunk_list(items: List[Any], size: int) -&gt; Iterable[List[Any]]:\n    \"\"\"Split a list into chunks of a specified size.\n\n    Examples:\n        &gt;&gt;&gt; [len(x) for x in chunk_list(range(10), 3)]\n        [3, 3, 3, 1]\n    \"\"\"\n    for i in range(0, len(items), size):\n        yield items[i : i + size]\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.scmodels_to_dict","title":"scmodels_to_dict","text":"<pre><code>scmodels_to_dict(scmodels, keys)\n</code></pre> <p>Creates a dict indexed by key(s) of the ScModels of the list.</p> <p>When multiple keys are provided, each ScModel instance will be stored in the dict with all keys. If a key is a list, then each list element is considered (not recursively, only at first level) as a key. Conflict of keys is not checked.</p> <p>Parameters:</p> Name Type Description Default <code>scmodels</code> <code>List[ScModel]</code> <p>list of ScModel instances</p> required <code>keys</code> <code>List[str]</code> <p>a list of strings referring to ScModel fields to be used as keys</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sc_crawler.vendors import aws\n&gt;&gt;&gt; scmodels_to_dict([aws], keys=[\"vendor_id\", \"name\"])\n{'aws': Vendor...\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def scmodels_to_dict(scmodels: List[ScModel], keys: List[str]) -&gt; Dict[str, ScModel]:\n    \"\"\"Creates a dict indexed by key(s) of the ScModels of the list.\n\n    When multiple keys are provided, each ScModel instance will be stored in\n    the dict with all keys. If a key is a list, then each list element is\n    considered (not recursively, only at first level) as a key.\n    Conflict of keys is not checked.\n\n    Args:\n        scmodels: list of ScModel instances\n        keys: a list of strings referring to ScModel fields to be used as keys\n\n    Examples:\n        &gt;&gt;&gt; from sc_crawler.vendors import aws\n        &gt;&gt;&gt; scmodels_to_dict([aws], keys=[\"vendor_id\", \"name\"])\n        {'aws': Vendor...\n    \"\"\"\n    data = {}\n    for key in keys:\n        for scmodel in scmodels:\n            data_keys = getattr(scmodel, key)\n            if not isinstance(data_keys, list):\n                data_keys = [data_keys]\n            for data_key in data_keys:\n                data[data_key] = scmodel\n    return data\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.is_sqlite","title":"is_sqlite","text":"<pre><code>is_sqlite(session)\n</code></pre> <p>Checks if a SQLModel session is binded to a SQLite database.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def is_sqlite(session: Session) -&gt; bool:\n    \"\"\"Checks if a SQLModel session is binded to a SQLite database.\"\"\"\n    return session.bind.dialect.name == \"sqlite\"\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.is_postgresql","title":"is_postgresql","text":"<pre><code>is_postgresql(session)\n</code></pre> <p>Checks if a SQLModel session is binded to a PostgreSQL-like database.</p> <p>Dialect name is checked for PostgreSQL or CockroachDB.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def is_postgresql(session: Session) -&gt; bool:\n    \"\"\"Checks if a SQLModel session is binded to a PostgreSQL-like database.\n\n    Dialect name is checked for PostgreSQL or CockroachDB.\"\"\"\n    return session.bind.dialect.name in [\"postgresql\", \"cockroachdb\"]\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.float_inf_to_str","title":"float_inf_to_str","text":"<pre><code>float_inf_to_str(x)\n</code></pre> <p>Transform to string if a float is inf.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def float_inf_to_str(x: float) -&gt; Union[float, str]:\n    \"\"\"Transform to string if a float is inf.\"\"\"\n    return \"Infinity\" if isinf(x) else x\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.table_name_to_model","title":"table_name_to_model","text":"<pre><code>table_name_to_model(table_name)\n</code></pre> <p>Return the ScModel schema for a table name.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def table_name_to_model(table_name: str) -&gt; ScModel:\n    \"\"\"Return the ScModel schema for a table name.\"\"\"\n    from .tables import tables\n\n    return [t for t in tables if t.get_table_name() == table_name][0]\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.get_row_by_pk","title":"get_row_by_pk","text":"<pre><code>get_row_by_pk(session, model, pks)\n</code></pre> <p>Get a row from a table definition by primary keys.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Connection for database connections.</p> required <code>model</code> <code>ScModel</code> <p>An ScModel schema definition with table reference.</p> required <code>pks</code> <code>dict</code> <p>Dictionary of all the primary keys for the row,.</p> required <p>Returns:</p> Type Description <code>ScModel</code> <p>ScModel object read from the database.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def get_row_by_pk(session: Session, model: ScModel, pks: dict) -&gt; ScModel:\n    \"\"\"Get a row from a table definition by primary keys.\n\n    Args:\n        session: Connection for database connections.\n        model: An ScModel schema definition with table reference.\n        pks: Dictionary of all the primary keys for the row,.\n\n    Returns:\n        ScModel object read from the database.\n    \"\"\"\n    q = select(model)\n    for k, v in pks.items():\n        q = q.where(getattr(model, k) == v)\n    return session.exec(statement=q).one()\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.nesteddefaultdict","title":"nesteddefaultdict","text":"<pre><code>nesteddefaultdict()\n</code></pre> <p>Recursive defaultdict.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; foo = nesteddefaultdict()\n&gt;&gt;&gt; foo[\"bar\"][\"baz\"] = 43\n&gt;&gt;&gt; from json import dumps\n&gt;&gt;&gt; dumps(foo)\n'{\"bar\": {\"baz\": 43}}'\n</code></pre> Source code in <code>sc_crawler/utils.py</code> <pre><code>def nesteddefaultdict():\n    \"\"\"Recursive defaultdict.\n\n    Examples:\n        &gt;&gt;&gt; foo = nesteddefaultdict()\n        &gt;&gt;&gt; foo[\"bar\"][\"baz\"] = 43\n        &gt;&gt;&gt; from json import dumps\n        &gt;&gt;&gt; dumps(foo)\n        '{\"bar\": {\"baz\": 43}}'\n    \"\"\"\n    return defaultdict(nesteddefaultdict)\n</code></pre>"},{"location":"reference/sc_crawler/utils/#sc_crawler.utils.list_search","title":"list_search","text":"<pre><code>list_search(items, key, values)\n</code></pre> <p>Search for a dict in a list with the given key/value pair.</p> <p>When multiple values are provided, it will use the first field with a matching name with either keys.</p> Source code in <code>sc_crawler/utils.py</code> <pre><code>def list_search(items: List[dict], key: str, values: Union[Any, List[Any]]) -&gt; dict:\n    \"\"\"Search for a dict in a list with the given key/value pair.\n\n    When multiple values are provided, it will use the first field with a\n    matching name with either keys.\n    \"\"\"\n    if not isinstance(values, list):\n        values = [values]\n    return next((item for item in items if item[key] in values), None)\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/","title":"vendor_helpers","text":""},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers","title":"sc_crawler.vendor_helpers","text":""},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.fetch_servers","title":"fetch_servers","text":"<pre><code>fetch_servers(fn, where, vendor)\n</code></pre> <p>Fetch servers of a region/zone.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>A function that takes the region or zone id as its first and only argument. The returning list must conform with the Server object, or need to be in a format that preprocess_servers's <code>fn</code> can manage.</p> required <code>where</code> <code>str</code> <p>A Region or Zone <code>api_reference</code> or similar that is passed to <code>fn</code>.</p> required <code>vendor</code> <code>Optional[Vendor]</code> <p>Optional Vendor instance used for logging and progress bar updates.</p> required Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def fetch_servers(fn: Callable, where: str, vendor: Optional[Vendor]) -&gt; List[dict]:\n    \"\"\"Fetch servers of a region/zone.\n\n    Args:\n        fn: A function that takes the region or zone id as its first and only argument.\n            The returning list must conform with the Server object, or need to\n            be in a format that [preprocess_servers][sc_crawler.vendor_helpers.preprocess_servers]'s\n            `fn` can manage.\n        where: A [Region][sc_crawler.tables.Region] or [Zone][sc_crawler.tables.Zone]\n            `api_reference` or similar that is passed to `fn`.\n        vendor: Optional [Vendor][sc_crawler.tables.Vendor] instance used for\n            logging and progress bar updates.\n    \"\"\"\n    servers = fn(where)\n    if vendor:\n        vendor.log(f\"{len(servers)} server(s) found in {where}.\")\n    if vendor:\n        vendor.progress_tracker.advance_task()\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.parallel_fetch_servers","title":"parallel_fetch_servers","text":"<pre><code>parallel_fetch_servers(vendor, fn, id_col, by)\n</code></pre> <p>Fetch servers of all regions/zones in parallel on 8 threads.</p> <p>Parameters:</p> Name Type Description Default <code>vendor</code> <code>Vendor</code> <p>Required Vendor instance used for the regions lookup, logging and progress bar updates.</p> required <code>fn</code> <code>Callable</code> <p>A function to be passed to fetch_servers.</p> required <code>id_cols</code> <p>Field name to be used to deduplicate the list of server dicts.</p> required <code>by</code> <code>Literal['regions', 'zones']</code> <p>What objects of the <code>vendor</code> to iterate on.</p> required Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def parallel_fetch_servers(\n    vendor: Vendor, fn: Callable, id_col: str, by: Literal[\"regions\", \"zones\"]\n) -&gt; List[dict]:\n    \"\"\"Fetch servers of all regions/zones in parallel on 8 threads.\n\n    Args:\n        vendor: Required [Vendor][sc_crawler.tables.Vendor] instance used for\n            the regions lookup, logging and progress bar updates.\n        fn: A function to be passed to [fetch_servers][sc_crawler.vendor_helpers.fetch_servers].\n        id_cols: Field name to be used to deduplicate the list of server dicts.\n        by: What objects of the `vendor` to iterate on.\n    \"\"\"\n\n    locations = [\n        i.api_reference for i in getattr(vendor, by) if i.status == Status.ACTIVE\n    ]\n    vendor.progress_tracker.start_task(\n        name=f\"Scanning {by} for server(s)\", total=len(locations)\n    )\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        servers = executor.map(fetch_servers, repeat(fn), locations, repeat(vendor))\n    servers = list(chain.from_iterable(servers))\n\n    vendor.log(f\"{len(servers)} server(s) found in {len(locations)} {by}.\")\n    servers = list({s[id_col]: s for s in servers}.values())\n    vendor.log(f\"{len(servers)} unique server(s) found.\")\n    active_servers = [\n        s for s in servers if s.get(\"status\", Status.ACTIVE) == Status.ACTIVE\n    ]\n    vendor.log(f\"{len(active_servers)} ACTIVE server(s) found.\")\n    vendor.progress_tracker.hide_task()\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.preprocess_servers","title":"preprocess_servers","text":"<pre><code>preprocess_servers(servers, vendor, fn)\n</code></pre> <p>Preprocess servers before inserting into the database.</p> <p>Takes a list of dicts and tranform to a list of dicts that follows the Server schema.</p> <p>Parameters:</p> Name Type Description Default <code>servers</code> <code>List[dict]</code> <p>To be passed to <code>fn</code>.</p> required <code>vendor</code> <code>Vendor</code> <p>The related Vendor instance used for database connection, logging and progress bar updates.</p> required <code>fn</code> <code>Callable</code> <p>A function that takes a server from <code>servers</code> (one-by-one) and the <code>vendor</code>.</p> required Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def preprocess_servers(servers: List[dict], vendor: Vendor, fn: Callable) -&gt; List[dict]:\n    \"\"\"Preprocess servers before inserting into the database.\n\n    Takes a list of dicts and tranform to a list of dicts that\n    follows the [Server][sc_crawler.tables.Server] schema.\n\n    Args:\n        servers: To be passed to `fn`.\n        vendor: The related [Vendor][sc_crawler.tables.Vendor] instance used\n            for database connection, logging and progress bar updates.\n        fn: A function that takes a server from `servers` (one-by-one) and the `vendor`.\n    \"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Preprocessing server(s)\", total=len(servers)\n    )\n    processed = []\n    for server in servers:\n        processed.append(fn(server, vendor))\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return processed\n</code></pre>"},{"location":"reference/sc_crawler/vendor_helpers/#sc_crawler.vendor_helpers.add_vendor_id","title":"add_vendor_id","text":"<pre><code>add_vendor_id(obj, vendor)\n</code></pre> <p>Adds <code>vendor_id</code> field to a dict.</p> Source code in <code>sc_crawler/vendor_helpers.py</code> <pre><code>def add_vendor_id(obj: dict, vendor: Vendor) -&gt; dict:\n    \"\"\"Adds `vendor_id` field to a dict.\"\"\"\n    obj[\"vendor_id\"] = vendor.vendor_id\n    return obj\n</code></pre>"},{"location":"reference/sc_crawler/vendors/","title":"vendors","text":""},{"location":"reference/sc_crawler/vendors/#sc_crawler.vendors","title":"sc_crawler.vendors","text":"<p>Helper methods for each cloud compute resource provider.</p>"},{"location":"reference/sc_crawler/vendors/aws/","title":"aws","text":""},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws","title":"sc_crawler.vendors.aws","text":""},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of compliance frameworks known for AWS.</p> <p>Resources: https://aws.amazon.com/compliance/programs/</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of compliance frameworks known for AWS.\n\n    Resources: &lt;https://aws.amazon.com/compliance/programs/&gt;\n    \"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id, [\"hipaa\", \"soc2t2\", \"iso27001\"]\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all available AWS regions via <code>boto3</code> calls.</p> <p>Some data sources are not available from APIs, and were collected manually:</p> <ul> <li>launch date: https://aws.amazon.com/about-aws/global-infrastructure/regions_az/,</li> <li>energy source: https://sustainability.aboutamazon.com/products-services/the-cloud?energyType=true#renewable-energy,</li> <li>lon/lat coordinates: https://gist.github.com/martinheidegger/88950cb51ee5bdeafd51bc55287b1092 and approximation based on the city when no more accurate data was available.</li> </ul> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all available AWS regions via `boto3` calls.\n\n    Some data sources are not available from APIs, and were collected manually:\n\n    - launch date: &lt;https://aws.amazon.com/about-aws/global-infrastructure/regions_az/&gt;,\n    - energy source: &lt;https://sustainability.aboutamazon.com/products-services/the-cloud?energyType=true#renewable-energy&gt;,\n    - lon/lat coordinates: &lt;https://gist.github.com/martinheidegger/88950cb51ee5bdeafd51bc55287b1092&gt; and approximation based on the city when no more accurate data was available.\n    \"\"\"  # noqa: E501\n    regions = [\n        {\n            \"region_id\": \"af-south-1\",\n            \"name\": \"Africa (Cape Town)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"ZA\",\n            \"city\": \"Cape Town\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            \"lat\": -33.914651,\n            \"lon\": 18.3758801,\n        },\n        {\n            \"region_id\": \"ap-east-1\",\n            \"name\": \"Asia Pacific (Hong Kong)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"HK\",\n            \"city\": \"Hong Kong\",\n            \"founding_year\": 2019,\n            \"green_energy\": False,\n            \"lat\": 22.2908475,\n            \"lon\": 114.2723379,\n        },\n        {\n            \"region_id\": \"ap-northeast-1\",\n            \"name\": \"Asia Pacific (Tokyo)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"JP\",\n            \"city\": \"Tokyo\",\n            \"founding_year\": 2011,\n            \"green_energy\": False,\n            \"lat\": 35.617436,\n            \"lon\": 139.7459176,\n        },\n        {\n            \"region_id\": \"ap-northeast-2\",\n            \"name\": \"Asia Pacific (Seoul)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"KR\",\n            \"city\": \"Seoul\",\n            \"founding_year\": 2016,\n            \"green_energy\": False,\n            \"lat\": 37.5616592,\n            \"lon\": 126.8736237,\n        },\n        {\n            \"region_id\": \"ap-northeast-3\",\n            \"name\": \"Asia Pacific (Osaka)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"JP\",\n            \"city\": \"Osaka\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            \"lat\": 34.693889,\n            \"lon\": 135.502222,\n        },\n        {\n            \"region_id\": \"ap-south-1\",\n            \"name\": \"Asia Pacific (Mumbai)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IN\",\n            \"city\": \"Mumbai\",\n            \"founding_year\": 2016,\n            \"green_energy\": True,\n            \"lat\": 19.2425503,\n            \"lon\": 72.9667878,\n        },\n        {\n            \"region_id\": \"ap-south-2\",\n            \"name\": \"Asia Pacific (Hyderabad)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IN\",\n            \"city\": \"Hyderabad\",\n            \"founding_year\": 2022,\n            \"green_energy\": True,\n            # approximation based on city location\n            \"lat\": 17.412281,\n            \"lon\": 78.243237,\n        },\n        {\n            \"region_id\": \"ap-southeast-1\",\n            \"name\": \"Asia Pacific (Singapore)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"SG\",\n            \"city\": \"Singapore\",\n            \"founding_year\": 2010,\n            \"green_energy\": False,\n            \"lat\": 1.3218269,\n            \"lon\": 103.6930643,\n        },\n        {\n            \"region_id\": \"ap-southeast-2\",\n            \"name\": \"Asia Pacific (Sydney)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"AU\",\n            \"city\": \"Sydney\",\n            \"founding_year\": 2012,\n            \"green_energy\": False,\n            \"lat\": -33.9117717,\n            \"lon\": 151.1907535,\n        },\n        {\n            \"region_id\": \"ap-southeast-3\",\n            \"name\": \"Asia Pacific (Jakarta)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"ID\",\n            \"city\": \"Jakarta\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            \"lat\": -6.2,\n            \"lon\": 106.816667,\n        },\n        {\n            \"region_id\": \"ap-southeast-4\",\n            \"name\": \"Asia Pacific (Melbourne)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"AU\",\n            \"city\": \"Melbourne\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city location\n            \"lat\": -37.8038607,\n            \"lon\": 144.7119569,\n        },\n        {\n            \"region_id\": \"ca-central-1\",\n            \"name\": \"Canada (Central)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CA\",\n            \"city\": \"Quebec\",  # NOTE needs city name\n            \"founding_year\": 2016,\n            \"green_energy\": True,\n            \"lat\": 45.5,\n            \"lon\": -73.6,\n        },\n        {\n            \"region_id\": \"ca-west-1\",\n            \"name\": \"Canada West (Calgary)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CA\",\n            \"city\": \"Calgary\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city location\n            \"lat\": 51.046574,\n            \"lon\": -114.129024,\n        },\n        {\n            \"region_id\": \"cn-north-1\",\n            \"name\": \"China (Beijing)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CN\",\n            \"city\": \"Beijing\",\n            \"founding_year\": 2016,\n            \"green_energy\": True,\n            \"lat\": 39.8094478,\n            \"lon\": 116.5783234,\n        },\n        {\n            \"region_id\": \"cn-northwest-1\",\n            \"name\": \"China (Ningxia)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CN\",\n            \"city\": \"Ningxia\",  # NOTE needs city name\n            \"founding_year\": 2017,\n            \"green_energy\": True,\n            \"lat\": 37.5024418,\n            \"lon\": 105.1627193,\n        },\n        {\n            \"region_id\": \"eu-central-1\",\n            \"name\": \"Europe (Frankfurt)\",\n            \"aliases\": [\"EU (Frankfurt)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"DE\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2014,\n            \"green_energy\": True,\n            \"lat\": 50.0992094,\n            \"lon\": 8.6303932,\n        },\n        {\n            \"region_id\": \"eu-central-2\",\n            \"name\": \"Europe (Zurich)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"CH\",\n            \"city\": \"Zurich\",\n            \"founding_year\": 2022,\n            \"green_energy\": True,\n            # approximation based on city location\n            \"lat\": 47.3862924,\n            \"lon\": 8.4448814,\n        },\n        {\n            \"region_id\": \"eu-north-1\",\n            \"name\": \"Europe (Stockholm)\",\n            \"aliases\": [\"EU (Stockholm)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"SE\",\n            \"city\": \"Stockholm\",\n            \"founding_year\": 2018,\n            \"green_energy\": True,\n            \"lat\": 59.326242,\n            \"lon\": 17.8419717,\n        },\n        {\n            \"region_id\": \"eu-south-1\",\n            \"name\": \"Europe (Milan)\",\n            \"aliases\": [\"EU (Milan)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IT\",\n            \"city\": \"Milan\",\n            \"founding_year\": 2020,\n            \"green_energy\": True,\n            \"lat\": 45.4628328,\n            \"lon\": 9.1076927,\n        },\n        {\n            \"region_id\": \"eu-south-2\",\n            \"name\": \"Europe (Spain)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"ES\",\n            \"city\": \"Arag\u00f3n\",  # NOTE needs city name\n            \"founding_year\": 2022,\n            \"green_energy\": True,\n            # approximation based on city location\n            \"lat\": 41.7943702,\n            \"lon\": -0.8516735,\n        },\n        {\n            \"region_id\": \"eu-west-1\",\n            \"name\": \"Europe (Ireland)\",\n            \"aliases\": [\"EU (Ireland)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IE\",\n            \"city\": \"Dublin\",\n            \"founding_year\": 2007,\n            \"green_energy\": True,\n            \"lat\": 53.4056545,\n            \"lon\": -6.224503,\n        },\n        {\n            \"region_id\": \"eu-west-2\",\n            \"name\": \"Europe (London)\",\n            \"aliases\": [\"EU (London)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"GB\",\n            \"city\": \"London\",\n            \"founding_year\": 2016,\n            \"green_energy\": True,\n            \"lat\": 51.5085036,\n            \"lon\": -0.0609266,\n        },\n        {\n            \"region_id\": \"eu-west-3\",\n            \"name\": \"Europe (Paris)\",\n            \"aliases\": [\"EU (Paris)\"],\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"FR\",\n            \"city\": \"Paris\",\n            \"founding_year\": 2017,\n            \"green_energy\": True,\n            \"lat\": 48.6009709,\n            \"lon\": 2.2976644,\n        },\n        {\n            \"region_id\": \"il-central-1\",\n            \"name\": \"Israel (Tel Aviv)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"IL\",\n            \"city\": \"Tel Aviv\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city location\n            \"lat\": 32.0491183,\n            \"lon\": 34.7891105,\n        },\n        {\n            \"region_id\": \"me-central-1\",\n            \"name\": \"Middle East (UAE)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"AE\",\n            # NOTE city and state unknown\n            \"display_name\": \"United Arab Emirates\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on country\n            \"lat\": 25.0647937,\n            \"lon\": 55.1363688,\n        },\n        {\n            \"region_id\": \"me-south-1\",\n            \"name\": \"Middle East (Bahrain)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"BH\",\n            # NOTE city and stateunknown\n            \"display_name\": \"Bahrain\",\n            \"founding_year\": 2019,\n            \"green_energy\": False,\n            \"lat\": 25.941298,\n            \"lon\": 50.3073907,\n        },\n        {\n            \"region_id\": \"sa-east-1\",\n            \"name\": \"South America (Sao Paulo)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"BR\",\n            \"city\": \"Sao Paulo\",\n            \"founding_year\": 2011,\n            \"green_energy\": False,\n            \"lat\": -23.4925798,\n            \"lon\": -46.8105593,\n        },\n        {\n            \"region_id\": \"us-east-1\",\n            \"name\": \"US East (N. Virginia)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"Northern Virgina\",\n            # NOTE city unknown\n            \"founding_year\": 2006,\n            \"green_energy\": True,\n            \"lat\": 38.9940541,\n            \"lon\": -77.4524237,\n        },\n        {\n            \"region_id\": \"us-east-2\",\n            \"name\": \"US East (Ohio)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"Ohio\",\n            # NOTE city unknown\n            \"founding_year\": 2016,\n            \"green_energy\": True,\n            \"lat\": 40.0946354,\n            \"lon\": -82.7541337,\n        },\n        {\n            \"region_id\": \"us-west-1\",\n            \"name\": \"US West (N. California)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"California\",\n            # NOTE city unknown\n            \"founding_year\": 2009,\n            \"green_energy\": True,\n            \"lat\": 37.443680,\n            \"lon\": -122.153664,\n        },\n        {\n            \"region_id\": \"us-west-2\",\n            \"name\": \"US West (Oregon)\",\n            \"vendor_id\": vendor.vendor_id,\n            \"country_id\": \"US\",\n            \"state\": \"Oregon\",\n            # NOTE city unknown\n            \"founding_year\": 2011,\n            \"green_energy\": True,\n            \"lat\": 45.9174667,\n            \"lon\": -119.2684488,\n        },\n    ]\n\n    # add API reference and display names\n    for region in regions:\n        region[\"api_reference\"] = region[\"region_id\"]\n        if region.get(\"display_name\") is None:\n            display_name_prefix = region.get(\"city\", region.get(\"state\", \"\"))\n            region[\"display_name\"] = f\"{display_name_prefix} ({region['country_id']})\"\n\n    # look for undocumented (new) regions in AWS\n    supported_regions = [d[\"region_id\"] for d in regions]\n    available_regions = _boto_describe_regions()\n    for available_region in available_regions:\n        region_name = available_region[\"RegionName\"]\n        if \"gov\" in region_name:\n            next()\n        if region_name not in supported_regions:\n            raise NotImplementedError(f\"Unsupported AWS region: {region_name}\")\n\n    # mark inactive regions\n    active_regions = [region[\"RegionName\"] for region in available_regions]\n    for region in regions:\n        if region[\"region_id\"] in active_regions:\n            region[\"status\"] = \"active\"\n        else:\n            region[\"status\"] = \"inactive\"\n\n    return regions\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all available AWS availability zones via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all available AWS availability zones via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Scanning region(s) for zone(s)\", total=len(vendor.regions)\n    )\n\n    def get_zones(region: Region, vendor: Vendor) -&gt; List[dict]:\n        new = []\n        if region.status == \"active\":\n            for zone in _boto_describe_availability_zones(region.region_id):\n                new.append(\n                    {\n                        \"zone_id\": zone[\"ZoneId\"],\n                        \"name\": zone[\"ZoneName\"],\n                        \"api_reference\": zone[\"ZoneName\"],\n                        \"display_name\": zone[\"ZoneName\"],\n                        \"region_id\": region.region_id,\n                        \"vendor_id\": vendor.vendor_id,\n                    }\n                )\n        vendor.progress_tracker.advance_task()\n        return new\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        zones = executor.map(get_zones, vendor.regions, repeat(vendor))\n    zones = list(chain.from_iterable(zones))\n    vendor.progress_tracker.hide_task()\n    return zones\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all available AWS instance types in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all available AWS instance types in all regions via `boto3` calls.\"\"\"\n    # TODO consider dropping this in favor of pricing.get_products, as\n    #      it has info e.g. on instanceFamily although other fields\n    #      are messier (e.g. extract memory from string)\n    servers = parallel_fetch_servers(\n        vendor, _boto_describe_instance_types, \"InstanceType\", \"regions\"\n    )\n    servers = preprocess_servers(servers, vendor, _make_server_from_instance_type)\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>List all on-demand instance prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_server_prices(vendor):\n    \"\"\"List all on-demand instance prices in all regions via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Searching for ondemand server_price(s)\", total=None\n    )\n    products = _boto_get_products(\n        service_code=\"AmazonEC2\",\n        filters={\n            # TODO ingest win, mac etc others\n            \"operatingSystem\": \"Linux\",\n            \"preInstalledSw\": \"NA\",\n            \"licenseModel\": \"No License required\",\n            \"locationType\": \"AWS Region\",\n            \"capacitystatus\": \"Used\",\n            # TODO reserved pricing options - might decide not to, as not in scope?\n            \"marketoption\": \"OnDemand\",\n            # TODO dedicated options?\n            \"tenancy\": \"Shared\",\n        },\n    )\n    vendor.progress_tracker.hide_task()\n\n    # lookup tables\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n    servers = scmodels_to_dict(vendor.servers, keys=[\"server_id\"])\n\n    # check all regions for instance types per zone\n    active_region_ids = [\n        r.api_reference for r in regions.values() if r.status == Status.ACTIVE\n    ]\n    vendor.progress_tracker.start_task(\n        name=\"Look up supported server types in all ACTIVE regions/zones\",\n        total=len(active_region_ids),\n    )\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        regions_servers = executor.map(\n            _describe_instance_type_offerings_per_zone_with_progress,\n            active_region_ids,\n            repeat(vendor),\n        )\n    regions_servers = dict(zip(active_region_ids, regions_servers))\n    vendor.progress_tracker.hide_task()\n\n    server_prices = []\n    vendor.progress_tracker.start_task(\n        name=\"Preprocess ondemand server_price(s)\", total=len(products)\n    )\n    for product in products:\n        try:\n            attributes = product[\"product\"][\"attributes\"]\n            # early drop Gov regions\n            if \"GovCloud\" in attributes[\"location\"]:\n                continue\n            server = servers[attributes[\"instanceType\"]]\n            region = regions[attributes[\"location\"]]\n            zones = regions_servers.get(region.api_reference, {}).get(\n                server.server_id, []\n            )\n            price = _extract_ondemand_price(product[\"terms\"])\n            for zone in zones:\n                server_prices.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"zone_id\": zone,\n                        \"server_id\": server.server_id,\n                        # TODO ingest other OSs\n                        \"operating_system\": \"Linux\",\n                        \"allocation\": Allocation.ONDEMAND,\n                        \"price\": price[0],\n                        \"currency\": price[1],\n                        \"unit\": PriceUnit.HOUR,\n                    }\n                )\n        except KeyError as e:\n            vendor.log(\n                f\"Cannot make ondemand server_price due to unknown {str(e)}: {str(attributes)}\",\n                DEBUG,\n            )\n        finally:\n            vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return server_prices\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>List all spot instance prices in all availability zones via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"List all spot instance prices in all availability zones via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Scanning regions for spot server_price(s)\",\n        total=len(vendor.regions),\n    )\n\n    def get_spot_prices(region: Region, vendor: Vendor) -&gt; List[dict]:\n        new = []\n        if region.status == \"active\":\n            try:\n                new = _describe_spot_price_history(region.region_id)\n                vendor.log(\n                    f\"{len(new)} spot server_price(s) found in {region.region_id}.\"\n                )\n            except ClientError as e:\n                vendor.log(\n                    f\"Cannot get spot server_price in {region.region_id}: {str(e)}\"\n                )\n        vendor.progress_tracker.advance_task()\n        return new\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        products = executor.map(get_spot_prices, vendor.regions, repeat(vendor))\n    products = list(chain.from_iterable(products))\n    vendor.log(f\"{len(products)} spot server_price(s) found.\")\n    vendor.progress_tracker.hide_task()\n\n    # lookup tables\n    zones = scmodels_to_dict(vendor.zones, keys=[\"name\"])\n    servers = scmodels_to_dict(vendor.servers, keys=[\"server_id\"])\n\n    server_prices = []\n    vendor.progress_tracker.start_task(\n        name=\"Preprocess spot server_price(s)\", total=len(products)\n    )\n    for product in products:\n        try:\n            zone = zones[product[\"AvailabilityZone\"]]\n            server = servers[product[\"InstanceType\"]]\n        except KeyError as e:\n            vendor.log(\n                f\"Cannot make ondemand server_price due to unknown {str(e)}: {str(product)}\",\n                DEBUG,\n            )\n            continue\n        server_prices.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": zone.region.region_id,\n                \"zone_id\": zone.zone_id,\n                \"server_id\": server.server_id,\n                # TODO ingest other OSs\n                \"operating_system\": \"Linux\",\n                \"allocation\": Allocation.SPOT,\n                \"price\": float(product[\"SpotPrice\"]),\n                \"currency\": \"USD\",\n                \"unit\": PriceUnit.HOUR,\n                # use reported time instead of current timestamp\n                \"observed_at\": product[\"Timestamp\"],\n            }\n        )\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return server_prices\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all storage types via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"List all storage types via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Searching for storages\", total=len(storage_manual_data)\n    )\n\n    # look up all volume types in us-east-1\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        products = executor.map(\n            _search_storage,\n            storage_types,\n            repeat(vendor),\n            repeat(\"US East (N. Virginia)\"),\n        )\n    products = list(chain.from_iterable(products))\n    vendor.progress_tracker.hide_task()\n\n    storages = []\n    for product in products:\n        attributes = product[\"product\"][\"attributes\"]\n        product_id = attributes[\"volumeApiName\"]\n\n        def get_attr(key: str) -&gt; float:\n            return extract_last_number(\n                str(\n                    attributes.get(\n                        key,\n                        storage_manual_data[product_id][key],\n                    )\n                )\n            )\n\n        storage_type = (\n            StorageType.HDD if \"HDD\" in attributes[\"storageMedia\"] else StorageType.SSD\n        )\n        storages.append(\n            {\n                \"storage_id\": product_id,\n                \"vendor_id\": vendor.vendor_id,\n                \"name\": attributes[\"volumeType\"],\n                \"description\": attributes[\"storageMedia\"],\n                \"storage_type\": storage_type,\n                \"max_iops\": get_attr(\"maxIopsvolume\"),\n                \"max_throughput\": get_attr(\"maxThroughputvolume\"),\n                \"min_size\": get_attr(\"minVolumeSize\") * 1024,\n                \"max_size\": get_attr(\"maxVolumeSize\") * 1024,\n            }\n        )\n\n    return storages\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>List all storage prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"List all storage prices in all regions via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Searching for storage_price(s)\", total=len(storage_manual_data)\n    )\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        products = executor.map(\n            _search_storage,\n            storage_types,\n            repeat(vendor),\n        )\n    products = list(chain.from_iterable(products))\n    vendor.progress_tracker.hide_task()\n    vendor.log(f\"Found {len(products)} storage_price(s).\")\n\n    # lookup tables\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n\n    vendor.progress_tracker.start_task(\n        name=\"Preprocessing storage_price(s)\", total=len(products)\n    )\n    prices = []\n    for product in products:\n        try:\n            attributes = product[\"product\"][\"attributes\"]\n            region = regions[attributes[\"location\"]]\n            price = _extract_ondemand_price(product[\"terms\"])\n            prices.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"storage_id\": attributes[\"volumeApiName\"],\n                    \"unit\": PriceUnit.GB_MONTH,\n                    \"price\": price[0],\n                    \"currency\": price[1],\n                }\n            )\n        except KeyError:\n            continue\n        finally:\n            vendor.progress_tracker.advance_task()\n\n    vendor.progress_tracker.hide_task()\n    return prices\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>List all inbound and outbound traffic prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"List all inbound and outbound traffic prices in all regions via `boto3` calls.\"\"\"\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n    items = []\n    for direction in list(TrafficDirection):\n        loc_dir = \"toLocation\" if direction == TrafficDirection.IN else \"fromLocation\"\n        vendor.progress_tracker.start_task(\n            name=f\"Searching for {direction.value} traffic_price(s)\", total=None\n        )\n        products = _boto_get_products(\n            service_code=\"AWSDataTransfer\",\n            filters={\n                \"transferType\": \"AWS \" + direction.value.title(),\n            },\n        )\n        vendor.log(f\"Found {len(products)} {direction.value} traffic_price(s).\")\n        vendor.progress_tracker.update_task(\n            description=f\"Syncing {direction.value} traffic_price(s)\",\n            total=len(products),\n        )\n        for product in products:\n            try:\n                region = regions[product[\"product\"][\"attributes\"][loc_dir]]\n                prices = _extract_ondemand_prices(product[\"terms\"], fix_1024=True)\n                price = [PriceTier.model_validate(p).model_dump() for p in prices[0]]\n                items.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"price\": max([t[\"price\"] for t in prices[0]]),\n                        \"price_tiered\": price,\n                        \"currency\": prices[1],\n                        \"unit\": PriceUnit.GB_MONTH,\n                        \"direction\": direction,\n                    }\n                )\n            except KeyError:\n                continue\n            finally:\n                vendor.progress_tracker.advance_task()\n        vendor.progress_tracker.hide_task()\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/aws/#sc_crawler.vendors.aws.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>List IPV4 prices in all regions via <code>boto3</code> calls.</p> Source code in <code>sc_crawler/vendors/aws.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"List IPV4 prices in all regions via `boto3` calls.\"\"\"\n    vendor.progress_tracker.start_task(name=\"Searching for ipv4_price(s)\", total=None)\n    products = _boto_get_products(\n        service_code=\"AmazonVPC\",\n        filters={\n            \"group\": \"VPCPublicIPv4Address\",\n            \"groupDescription\": \"Hourly charge for In-use Public IPv4 Addresses\",\n        },\n    )\n    vendor.log(f\"Found {len(products)} ipv4_price(s).\")\n    vendor.progress_tracker.update_task(\n        description=\"Syncing ipv4_price(s)\", total=len(products)\n    )\n    # lookup tables\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\", \"aliases\"])\n    items = []\n    for product in products:\n        try:\n            region = regions[product[\"product\"][\"attributes\"][\"location\"]]\n        except KeyError as e:\n            vendor.log(\"region not found: %s\" % str(e), DEBUG)\n            continue\n        price = _extract_ondemand_price(product[\"terms\"])\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": price[0],\n                \"currency\": price[1],\n                \"unit\": PriceUnit.HOUR,\n            }\n        )\n        vendor.progress_tracker.advance_task()\n    vendor.progress_tracker.hide_task()\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/","title":"azure","text":""},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure","title":"sc_crawler.vendors.azure","text":""},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.SERVER_FEATURES","title":"SERVER_FEATURES  <code>module-attribute</code>","text":"<pre><code>SERVER_FEATURES = {'a': 'AMD processor', 'p': 'ARM processor', 'b': 'Block Storage performance', 'd': 'Local Disk', 'i': 'Isolated', 'l': 'Low Memory', 'm': 'Memory Intensive', 't': 'Tiny Memory', 's': 'Premium Storage capable', 'r': 'RDMA capable', 'e': 'Memory Optimized', 'x': 'Unmatched Memory Capacity', 'o': 'o'}\n</code></pre> <p>Map lowercase chars from the server name to features.</p>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.STORAGE_METER_MAPPING","title":"STORAGE_METER_MAPPING  <code>module-attribute</code>","text":"<pre><code>STORAGE_METER_MAPPING = {'P2 LRS Disk Mount': ('PremiumV2_LRS', 1), 'P1 LRS Disk': ('Premium_LRS', 4), 'P1 ZRS Disk': ('Premium_ZRS', 4), 'E1 LRS Disk': ('StandardSSD_LRS', 4), 'E1 ZRS Disk': ('StandardSSD_ZRS', 4), 'S4 LRS Disk': ('Standard_LRS', 32), 'Ultra LRS Provisioned Capacity': ('UltraSSD_LRS', 1)}\n</code></pre> <p>Map Storage price meter names to the Storage name and the related disk's size.</p>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of known compliance frameworks at Azure.</p> <p>Data collected from https://learn.microsoft.com/en-us/azure/compliance/.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of known compliance frameworks at Azure.\n\n    Data collected from &lt;https://learn.microsoft.com/en-us/azure/compliance/&gt;.\n    \"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id, [\"hipaa\", \"soc2t2\", \"iso27001\"]\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all regions via API call.</p> <p>Location (country and state) and founding year were collected manually from https://datacenters.microsoft.com/globe/explore/ and its underlying JSON at https://datacenters.microsoft.com/globe/data/geo/regions.json.</p> <p>City and the energy source information was collected from the sustainability fact sheets referenced in the above page and JSON.</p> <p>Coordinates were provided by the Microsoft API, which doesn't seem to be very reliable.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all regions via API call.\n\n    Location (country and state) and founding year\n    were collected manually from\n    &lt;https://datacenters.microsoft.com/globe/explore/&gt;\n    and its underlying JSON at\n    &lt;https://datacenters.microsoft.com/globe/data/geo/regions.json&gt;.\n\n    City and the energy source information was collected from\n    the sustainability fact sheets referenced in the above page and JSON.\n\n    Coordinates were provided by the Microsoft API, which doesn't seem\n    to be very reliable.\n    \"\"\"\n\n    manual_datas = {\n        # Canada\n        \"canadaeast\": {\n            \"country_id\": \"CA\",\n            \"state\": \"Quebec\",\n            \"city\": \"Quebec City\",\n            \"founding_year\": 2016,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"canadacentral\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Toronto\",\n            \"founding_year\": 2016,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # United States\n        \"centralus\": {\n            \"country_id\": \"US\",\n            \"state\": \"Iowa\",\n            \"founding_year\": 2014,\n            \"green_energy\": True,\n        },\n        \"centraluseuap\": {\n            \"country_id\": \"US\",\n            \"state\": \"Iowa\",\n            \"green_energy\": True,\n        },\n        \"eastus\": {\n            \"country_id\": \"US\",\n            \"city\": \"Boydton\",\n            \"state\": \"Virginia\",\n            # official site says 2014 with a dead link, but it was 2012 as per\n            # https://web.archive.org/web/20120530115120/http:/blogs.msdn.com/b/windowsazure/archive/2012/04/05/announcing-new-datacenter-options-for-windows-azure.aspx\n            \"founding_year\": 2012,\n            \"green_energy\": False,\n        },\n        \"eastusstg\": {\n            \"country_id\": \"US\",\n            \"state\": \"Virginia\",\n            \"green_energy\": False,\n        },\n        \"eastus2\": {\n            \"country_id\": \"US\",\n            \"city\": \"Boydton\",\n            \"state\": \"Virginia\",\n            # official site says 2012 with a dead link, but it was 2014 as per\n            # https://azure.microsoft.com/en-us/updates/general-availability-microsoft-azure-us-central-and-us-east-2-regions/\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"eastus2euap\": {\n            \"country_id\": \"US\",\n            \"state\": \"Virginia\",\n            \"green_energy\": False,\n        },\n        \"northcentralus\": {\n            \"country_id\": \"US\",\n            \"city\": \"Chicago\",\n            \"state\": \"Illinois\",\n            \"founding_year\": 2009,\n            \"green_energy\": False,\n        },\n        \"southcentralus\": {\n            \"country_id\": \"US\",\n            \"state\": \"Texas\",\n            \"city\": \"San Antonio\",\n            \"founding_year\": 2008,\n            \"green_energy\": True,\n        },\n        \"southcentralusstg\": {\n            \"country_id\": \"US\",\n            \"state\": \"Texas\",\n            \"city\": \"San Antonio\",\n        },\n        \"westcentralus\": {\n            \"country_id\": \"US\",\n            \"state\": \"Wyoming\",\n            \"city\": \"Cheyenne\",\n            \"founding_year\": 2016,\n            \"green_energy\": False,\n        },\n        \"westus\": {\n            \"country_id\": \"US\",\n            \"state\": \"California\",\n            \"founding_year\": 2012,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"westus2\": {\n            \"country_id\": \"US\",\n            \"state\": \"Washington\",\n            \"founding_year\": 2007,\n            \"green_energy\": False,\n        },\n        \"westus3\": {\n            \"country_id\": \"US\",\n            \"state\": \"Arizona\",\n            \"city\": \"Phoenix\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n        },\n        # Mexico\n        \"mexicocentral\": {\n            \"country_id\": \"ZA\",\n            \"state\": \"Quer\u00e9taro\",\n            \"founding_year\": 2024,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # South America\n        \"brazilsouth\": {\n            \"country_id\": \"BR\",\n            \"state\": \"Campinas\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"brazilsoutheast\": {\n            \"country_id\": \"US\",\n            \"city\": \"Rio de Janeiro\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"chilecentral\": {\n            \"country_id\": \"CL\",\n            \"city\": \"Santiago\",\n            # coming soon\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # not production region?\n        # https://github.com/Azure/azure-dev/issues/2165#issuecomment-1542948509\n        \"brazilus\": {\n            \"country_id\": \"BR\",\n        },\n        # Asia Pacific\n        \"australiacentral\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Canberra\",\n            \"founding_year\": 2018,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"australiacentral2\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Canberra\",\n            \"founding_year\": 2018,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"australiaeast\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Sydney\",\n            \"state\": \"New South Wales\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"australiasoutheast\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Melbourne\",\n            \"state\": \"Victoria\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n        },\n        \"eastasia\": {\n            \"country_id\": \"HK\",\n            \"founding_year\": 2010,\n            \"green_energy\": False,\n        },\n        \"southeastasia\": {\n            \"country_id\": \"SG\",\n            \"city\": \"Singapore\",\n            \"founding_year\": 2010,\n            \"green_energy\": False,\n        },\n        \"japaneast\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Tokyo\",\n            \"founding_year\": 2014,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"japanwest\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Osaka\",\n            \"founding_year\": 2014,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"jioindiacentral\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Nagpur\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"jioindiawest\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Jamnagar\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"centralindia\": {\n            \"country_id\": \"IN\",\n            \"state\": \"Pune\",\n            \"founding_year\": 2015,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"southindia\": {\n            \"country_id\": \"IN\",\n            \"state\": \"Chennai\",\n            \"founding_year\": 2015,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"westindia\": {\n            \"country_id\": \"IN\",\n            \"state\": \"Mumbai\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"koreacentral\": {\n            \"country_id\": \"KR\",\n            \"city\": \"Seoul\",\n            \"founding_year\": 2017,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"koreasouth\": {\n            \"country_id\": \"KR\",\n            \"city\": \"Busan\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"newzealandnorth\": {\n            \"country_id\": \"NZ\",\n            \"city\": \"Auckland\",\n            \"founding_year\": 2024,\n            \"green_energy\": False,\n        },\n        \"indonesiacentral\": {\n            \"country_id\": \"ID\",\n            \"city\": \"Jakarta\",\n            # coming soon\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"malaysiawest\": {\n            \"country_id\": \"MY\",\n            \"city\": \"Kuala Lumpur\",\n            # coming soon\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # Europe\n        \"francecentral\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Paris\",\n            \"founding_year\": 2018,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"francesouth\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Marseille\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"germanynorth\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Berlin\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"germanywestcentral\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"italynorth\": {\n            \"country_id\": \"IT\",\n            \"city\": \"Milan\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n        },\n        \"northeurope\": {\n            \"country_id\": \"IE\",\n            \"city\": \"Dublin\",\n            \"founding_year\": 2009,\n            \"green_energy\": False,\n        },\n        \"norwayeast\": {\n            \"country_id\": \"NO\",\n            \"city\": \"Oslo\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"norwaywest\": {\n            \"country_id\": \"NO\",\n        },\n        \"polandcentral\": {\n            \"country_id\": \"PL\",\n            \"city\": \"Warsaw\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n        },\n        \"spaincentral\": {\n            \"country_id\": \"ES\",\n            \"city\": \"Madrid\",\n            \"founding_year\": 2024,\n            \"green_energy\": False,\n        },\n        \"swedencentral\": {\n            \"country_id\": \"SE\",\n            \"city\": \"G\u00e4vle and Sandviken\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n        },\n        \"switzerlandnorth\": {\n            \"country_id\": \"CH\",\n            \"city\": \"Z\u00fcrich\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"switzerlandwest\": {\n            \"country_id\": \"CH\",\n            \"city\": \"Geneva\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"uksouth\": {\n            \"country_id\": \"GB\",\n            \"city\": \"London\",\n            \"founding_year\": 2016,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"ukwest\": {\n            \"country_id\": \"GB\",\n            \"city\": \"Cardiff\",\n            \"founding_year\": 2017,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"westeurope\": {\n            \"country_id\": \"NL\",\n            \"founding_year\": 2010,\n            \"green_energy\": False,\n        },\n        \"belgiumcentral\": {\n            \"country_id\": \"BE\",\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # Middle East\n        \"israelcentral\": {\n            \"country_id\": \"IL\",\n            \"founding_year\": 2023,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"qatarcentral\": {\n            \"country_id\": \"QA\",\n            \"city\": \"Doha\",\n            \"founding_year\": 2022,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"uaecentral\": {\n            \"country_id\": \"AE\",\n            \"city\": \"Abu Dhabi\",\n        },\n        \"uaenorth\": {\n            \"country_id\": \"AE\",\n            \"city\": \"Dubai\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"austriaeast\": {\n            \"country_id\": \"AT\",\n            \"city\": \"Vienna\",\n            \"founding_year\": 2025,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # Africa\n        \"southafricanorth\": {\n            \"country_id\": \"ZA\",\n            \"city\": \"Johannesburg\",\n            \"founding_year\": 2019,\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        \"southafricawest\": {\n            \"country_id\": \"ZA\",\n            \"city\": \"Cape Town\",\n            # unknown as no sustainability fact sheet found\n            \"green_energy\": False,\n        },\n        # China TODO enable\n    }\n\n    items = []\n    for region in _regions():\n        if region[\"metadata\"][\"region_type\"] != \"Physical\":\n            continue\n        # no idea what are these\n        if region[\"name\"].endswith(\"stg\"):\n            continue\n        # not production region?\n        # https://github.com/Azure/azure-dev/issues/2165#issuecomment-1542948509\n        if region[\"name\"] == \"brazilus\":\n            continue\n        # exclude for now as this new region is popping up and being removed\n        # from their API response randomly, so messing with git history\n        if region[\"name\"] == \"newzealandnorth\":\n            continue\n        manual_data = manual_datas.get(region[\"name\"])\n        if not manual_data:\n            raise KeyError(f\"No manual data found for {region['name']}.\")\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region[\"name\"],\n                \"name\": region[\"display_name\"],\n                \"api_reference\": region[\"name\"],\n                \"display_name\": (\n                    region[\"display_name\"] + \" (\" + manual_data[\"country_id\"] + \")\"\n                ),\n                \"country_id\": manual_data[\"country_id\"],\n                \"state\": manual_data.get(\"state\"),\n                \"city\": manual_data.get(\"city\"),\n                \"address_line\": None,\n                \"zip_code\": None,\n                \"lat\": region[\"metadata\"][\"latitude\"],\n                \"lon\": region[\"metadata\"][\"longitude\"],\n                \"founding_year\": manual_data.get(\"founding_year\"),\n                \"green_energy\": manual_data.get(\"green_energy\"),\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all availability zones.</p> <p>API call to list existing availability zones (\"1\", \"2\", and \"3\") for each region, and creating a dummy \"0\" zone for the regions without availability zones.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all availability zones.\n\n    API call to list existing availability zones (\"1\", \"2\", and \"3\")\n    for each region, and creating a dummy \"0\" zone for the regions\n    without availability zones.\n    \"\"\"\n    items = []\n    resources = _resources(\"Microsoft.Compute\")\n    locations = [i for i in resources if i[\"resource_type\"] == \"virtualMachines\"][0]\n    locations = {item[\"location\"]: item[\"zones\"] for item in locations[\"zone_mappings\"]}\n    for region in vendor.regions:\n        # default to zone with 0 ID if there are no real availability zones\n        region_zones = locations.get(region.name, [\"0\"])\n        for zone in region_zones:\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"zone_id\": zone,\n                    \"name\": zone,\n                    \"api_reference\": zone,\n                    \"display_name\": region.region_id + \"-\" + zone,\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all available instance types in all regions.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all available instance types in all regions.\"\"\"\n    servers = _servers()\n    for i in range(len(servers) - 1, -1, -1):\n        name = servers[i].get(\"name\")\n        # drop Basic servers as to be deprecated by Aug 2024\n        if name.startswith(\"Basic\"):\n            vendor.log(f\"Excluding deprecated: {name}\")\n            servers.pop(i)\n        # servers that are likely to be not available, with zero pricing\n        if name.endswith(\"Promo\"):\n            vendor.log(f\"Excluding nonsense pricing: {name}\")\n            servers.pop(i)\n        # servers probably not intended for our eyes\n        if \"Internal\" in name:\n            vendor.log(f\"Excluding internal server: {name}\")\n            servers.pop(i)\n        # servers randomly switching between active/inactive status\n        # TODO review from time to time\n        if name in [\"Standard_M896ixds_32_v3\", \"Standard_M64-32bds_1_v3\"]:\n            vendor.log(f\"Excluding server with questionable availability: {name}\")\n            servers.pop(i)\n    servers = preprocess_servers(servers, vendor, _standardize_server)\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>List all known server ondemand prices in all regions using the Azure Retail Pricing API.</p> <p>More information: https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_server_prices(vendor):\n    \"\"\"List all known server ondemand prices in all regions using the Azure Retail Pricing API.\n\n    More information: &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n    return _inventory_server_prices(vendor, Allocation.ONDEMAND)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>List all known server spot prices in all regions using the Azure Retail Pricing API.</p> <p>See details at inventory_server_prices.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"List all known server spot prices in all regions using the Azure Retail Pricing API.\n\n    See details at [inventory_server_prices][sc_crawler.vendors.azure.inventory_server_prices].\n    \"\"\"\n    return _inventory_server_prices(vendor, Allocation.SPOT)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all storage options via the Compute resource manager client.</p> <p>For more information, see https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"List all storage options via the Compute resource manager client.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types&gt;.\n    \"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of compute resources\", total=None\n    )\n\n    disks = []\n    for resource in _compute_resources():\n        if resource[\"resource_type\"] == \"disks\":\n            disks.append(resource)\n\n    disks = list({d[\"name\"]: d for d in disks}.values())\n    vendor.progress_tracker.hide_task()\n\n    items = []\n    for disk in disks:\n\n        def _search(values):\n            return list_search(disk[\"capabilities\"], \"name\", values)[\"value\"]\n\n        storage_type = (\n            StorageType.HDD\n            if \"Standard\" in disk[\"name\"] and \"SSD\" not in disk[\"name\"]\n            else StorageType.SSD\n        )\n        redundancy_type = (\n            \"Locally Redundant Storage\"\n            if \"LRS\" in disk[\"name\"]\n            else \"Zone-Redundant Storage\"\n        )\n        description = f\"{disk['tier']} tier {storage_type.name} ({redundancy_type})\"\n\n        items.append(\n            {\n                \"storage_id\": disk[\"name\"],\n                \"vendor_id\": vendor.vendor_id,\n                \"name\": disk[\"name\"],\n                \"description\": description,\n                \"storage_type\": storage_type,\n                \"max_iops\": _search([\"MaxIOpsReadWrite\", \"MaxIOps\"]),\n                \"max_throughput\": _search(\n                    [\"MaxBandwidthMBpsReadWrite\", \"MaxBandwidthMBps\"]\n                ),\n                # NOTE this is 16TB for most drives?!\n                \"min_size\": _search(\"MinSizeGiB\"),\n                \"max_size\": _search(\"MaxSizeGiB\"),\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>Look up Storage prices via the Azure Retail Prices API.</p> <p>For more information, see https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"Look up Storage prices via the Azure Retail Prices API.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of storage resources\", total=None\n    )\n    retail_prices = _prices(\"$filter=serviceName eq 'Storage'\")\n    vendor.progress_tracker.hide_task()\n\n    regions = scmodels_to_dict(vendor.regions, keys=[\"region_id\"])\n    storages = scmodels_to_dict(vendor.storages, keys=[\"storage_id\"])\n\n    items = []\n    for p in retail_prices:\n        mapping = STORAGE_METER_MAPPING.get(p[\"meterName\"])\n        if (\n            mapping\n            and mapping[0] in storages.keys()\n            and p[\"armRegionName\"] in regions.keys()\n        ):\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": p[\"armRegionName\"],\n                    \"storage_id\": mapping[0],\n                    \"unit\": PriceUnit.GB_MONTH,\n                    \"price\": p[\"retailPrice\"] / mapping[1],\n                    \"currency\": p[\"currencyCode\"],\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>Look up Internet Egress/Ingress prices via the Azure Retail Prices API.</p> <p>For more information, see https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"Look up Internet Egress/Ingress prices via the Azure Retail Prices API.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n\n    def get_tiers(prices: List[dict]) -&gt; List[dict]:\n        def prep_tiers(d: dict) -&gt; dict:\n            return {\n                \"lower\": d.get(\"tierMinimumUnits\", 0),\n                \"price\": d[\"retailPrice\"],\n            }\n\n        tiers = [prep_tiers(p) for p in prices]\n        tiers.sort(key=lambda x: x.get(\"lower\"))\n        for i in range(len(tiers)):\n            if i == len(tiers) - 1:\n                tiers[i][\"upper\"] = \"Infinity\"\n            else:\n                tiers[i][\"upper\"] = tiers[i + 1][\"lower\"]\n        return tiers\n\n    def by_region(prices: List[dict], region: str) -&gt; List[dict]:\n        return [p for p in prices if p[\"armRegionName\"] == region]\n\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of traffic prices\", total=None\n    )\n    inbound_prices = _prices(\n        \"$filter=serviceFamily eq 'Networking' and meterName eq 'Standard Data Transfer In'\"\n    )\n    outbound_prices = _prices(\n        \"$filter=serviceFamily eq 'Networking' and \"\n        \"meterName eq 'Standard Data Transfer Out' and \"\n        \"productName eq 'Bandwidth - Routing Preference: Internet'\"\n    )\n    vendor.progress_tracker.hide_task()\n\n    items = []\n    regions = scmodels_to_dict(vendor.regions, keys=[\"api_reference\"])\n    for region in regions.values():\n        for direction in [\"inbound\", \"outbound\"]:\n            prices = inbound_prices if direction == \"inbound\" else outbound_prices\n            tiers = get_tiers(by_region(prices, region.api_reference))\n            if tiers:\n                items.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"price\": max([t[\"price\"] for t in tiers]),\n                        \"price_tiered\": tiers,\n                        \"currency\": prices[0].get(\"currencyCode\", \"USD\"),\n                        \"unit\": PriceUnit.GB_MONTH,\n                        \"direction\": (\n                            TrafficDirection.IN\n                            if direction == \"inbound\"\n                            else TrafficDirection.OUT\n                        ),\n                    }\n                )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/azure/#sc_crawler.vendors.azure.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>Look up Internet Egress/Ingress prices via the Azure Retail Prices API.</p> <p>For more information, see https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices.</p> Source code in <code>sc_crawler/vendors/azure.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"Look up Internet Egress/Ingress prices via the Azure Retail Prices API.\n\n    For more information, see &lt;https://learn.microsoft.com/en-us/rest/api/cost-management/retail-prices/azure-retail-prices&gt;.\n    \"\"\"\n\n    vendor.progress_tracker.start_task(\n        name=\"Fetching list of traffic prices\", total=None\n    )\n    prices = _prices(\n        \"$filter=serviceFamily eq 'Networking' and \"\n        \"meterName eq 'Basic IPv4 Dynamic Public IP' and \"\n        \"type eq 'Consumption'\"\n    )\n    vendor.progress_tracker.hide_task()\n\n    items = []\n    regions = scmodels_to_dict(vendor.regions, keys=[\"api_reference\"])\n    for region in regions.values():\n        price = list_search(prices, \"armRegionName\", region.api_reference)\n        if price:\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"price\": price[\"retailPrice\"],\n                    \"currency\": price.get(\"currencyCode\", \"USD\"),\n                    \"unit\": PriceUnit.HOUR,\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/","title":"gcp","text":""},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp","title":"sc_crawler.vendors.gcp","text":""},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of compliance frameworks known for GCP.</p> <p>Resources: https://cloud.google.com/compliance?hl=en</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of compliance frameworks known for GCP.\n\n    Resources: &lt;https://cloud.google.com/compliance?hl=en&gt;\"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id, [\"hipaa\", \"soc2t2\", \"iso27001\"]\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all available GCP regions via API calls.</p> <p>Some data sources are not available from APIs, and were collected manually:</p> <ul> <li>location: https://cloud.google.com/compute/docs/regions-zones#available and https://en.wikipedia.org/wiki/Google_data_centers,</li> <li>lon/lat coordinates: https://en.wikipedia.org/wiki/Google_data_centers#Locations and approximation based on the city when no more accurate data was available.</li> <li>energy carbon data: https://cloud.google.com/sustainability/region-carbon#data and https://github.com/GoogleCloudPlatform/region-carbon-info,</li> <li>launch dates were collected from Wikipedia and GCP blog posts, such as https://medium.com/@retomeier/an-annotated-history-of-googles-cloud-platform-90b90f948920 and https://cloud.google.com/blog/products/infrastructure/introducing-new-google-cloud-regions.</li> </ul> <p>Note that many GCP regions use more than 90% green energy, but the related flag in our database is set to <code>False</code> as not being 100%.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all available GCP regions via API calls.\n\n    Some data sources are not available from APIs, and were collected manually:\n\n    - location: &lt;https://cloud.google.com/compute/docs/regions-zones#available&gt; and &lt;https://en.wikipedia.org/wiki/Google_data_centers&gt;,\n    - lon/lat coordinates: &lt;https://en.wikipedia.org/wiki/Google_data_centers#Locations&gt; and approximation based on the city when no more accurate data was available.\n    - energy carbon data: &lt;https://cloud.google.com/sustainability/region-carbon#data&gt; and &lt;https://github.com/GoogleCloudPlatform/region-carbon-info&gt;,\n    - launch dates were collected from [Wikipedia](https://en.wikipedia.org/wiki/Google_Cloud_Platform#Regions_and_zones) and GCP blog posts, such as &lt;https://medium.com/@retomeier/an-annotated-history-of-googles-cloud-platform-90b90f948920&gt; and &lt;https://cloud.google.com/blog/products/infrastructure/introducing-new-google-cloud-regions&gt;.\n\n    Note that many GCP regions use more than 90% green energy,\n    but the related flag in our database is set to `False` as not being 100%.\n    \"\"\"\n\n    manual_data = {\n        \"africa-south1\": {\n            \"country_id\": \"ZA\",\n            \"city\": \"Johannesburg\",\n            # https://cloud.google.com/blog/products/infrastructure/heita-south-africa-new-cloud-region\n            \"founding_year\": 2024,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -26.0420631,\n            \"lon\": 28.0589808,\n        },\n        \"asia-east1\": {\n            \"country_id\": \"TW\",\n            \"state\": \"Changhua County\",\n            \"founding_year\": 2013,\n            \"green_energy\": False,\n            \"lat\": 24.1385,\n            \"lon\": 120.425722,\n        },\n        \"asia-east2\": {\n            \"country_id\": \"HK\",\n            # https://cloud.google.com/blog/products/gcp/gcps-region-in-hong-kong-is-now-open\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            # approximation based on country\n            \"lat\": 22.2772377,\n            \"lon\": 114.1703066,\n            \"display_name\": \"Hong Kong\",\n        },\n        \"asia-northeast1\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Tokyo\",\n            \"state\": \"Japan\",\n            \"founding_year\": 2016,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 35.6433846,\n            \"lon\": 139.7684933,\n        },\n        \"asia-northeast2\": {\n            \"country_id\": \"JP\",\n            \"city\": \"Osaka\",\n            \"founding_year\": 2019,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 34.6696646,\n            \"lon\": 135.4846612,\n        },\n        \"asia-northeast3\": {\n            \"country_id\": \"KR\",\n            \"city\": \"Seoul\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 37.5514982,\n            \"lon\": 126.97784,\n        },\n        \"asia-south1\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Mumbai\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 19.0709441,\n            \"lon\": 72.8726468,\n        },\n        \"asia-south2\": {\n            \"country_id\": \"IN\",\n            \"city\": \"Delhi\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 28.6439839,\n            \"lon\": 76.9284239,\n        },\n        \"asia-southeast1\": {\n            \"country_id\": \"SG\",\n            \"city\": \"Jurong West\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            \"lat\": 1.351333,\n            \"lon\": 103.709778,\n        },\n        \"asia-southeast2\": {\n            \"country_id\": \"ID\",\n            \"city\": \"Jakarta\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -6.2297401,\n            \"lon\": 106.747117,\n        },\n        \"australia-southeast1\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Sydney\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -33.8375583,\n            \"lon\": 150.9488095,\n        },\n        \"australia-southeast2\": {\n            \"country_id\": \"AU\",\n            \"city\": \"Melbourne\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -37.8038607,\n            \"lon\": 144.7119569,\n        },\n        \"europe-central2\": {\n            \"country_id\": \"PL\",\n            \"city\": \"Warsaw\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 52.2328871,\n            \"lon\": 20.8966164,\n        },\n        \"europe-north1\": {\n            \"country_id\": \"FI\",\n            \"city\": \"Hamina\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            \"lat\": 60.536578,\n            \"lon\": 27.117003,\n        },\n        \"europe-north2\": {\n            \"country_id\": \"SE\",\n            \"city\": \"Stockholm\",\n            \"founding_year\": 2025,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 59.334591,\n            \"lon\": 18.06324,\n        },\n        \"europe-southwest1\": {\n            \"country_id\": \"ES\",\n            \"city\": \"Madrid\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            \"lat\": 40.519533,\n            \"lon\": -3.340937,\n        },\n        \"europe-west1\": {\n            \"country_id\": \"BE\",\n            \"city\": \"St. Ghislain\",\n            # https://medium.com/@retomeier/an-annotated-history-of-googles-cloud-platform-90b90f948920\n            \"founding_year\": 2015,\n            \"green_energy\": False,\n            \"lat\": 50.469333,\n            \"lon\": 3.865472,\n        },\n        \"europe-west10\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Berlin\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 52.5105672,\n            \"lon\": 13.3806972,\n        },\n        \"europe-west12\": {\n            \"country_id\": \"IT\",\n            \"city\": \"Turin\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            \"lat\": 45.146729,\n            \"lon\": 7.742147,\n        },\n        \"europe-west2\": {\n            \"country_id\": \"GB\",\n            \"city\": \"London\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 51.5090133,\n            \"lon\": -0.2118157,\n        },\n        \"europe-west3\": {\n            \"country_id\": \"DE\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            \"lat\": 50.12263,\n            \"lon\": 8.974168,\n        },\n        \"europe-west4\": {\n            \"country_id\": \"NL\",\n            \"city\": \"Eemshaven\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            \"lat\": 52.790105,\n            \"lon\": 5.029219,\n        },\n        \"europe-west6\": {\n            \"country_id\": \"CH\",\n            \"city\": \"Zurich\",\n            \"founding_year\": 2019,\n            \"green_energy\": False,\n            \"lat\": 47.445926,\n            \"lon\": 8.210909,\n        },\n        \"europe-west8\": {\n            \"country_id\": \"IT\",\n            \"city\": \"Milan\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 45.4615551,\n            \"lon\": 9.1389572,\n        },\n        \"europe-west9\": {\n            \"country_id\": \"FR\",\n            \"city\": \"Paris\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 48.8641797,\n            \"lon\": 2.3109137,\n        },\n        \"me-central1\": {\n            \"country_id\": \"QA\",\n            \"city\": \"Doha\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 25.272868,\n            \"lon\": 51.4717522,\n        },\n        \"me-central2\": {\n            \"country_id\": \"SA\",\n            \"city\": \"Dammam\",\n            \"founding_year\": 2023,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 26.3826288,\n            \"lon\": 49.9675732,\n        },\n        \"me-west1\": {\n            \"country_id\": \"IL\",\n            \"city\": \"Tel Aviv\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 32.0491183,\n            \"lon\": 34.7891105,\n        },\n        \"northamerica-northeast1\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Montr\u00e9al\",\n            \"founding_year\": 2018,\n            \"green_energy\": True,\n            # approximation based on city\n            \"lat\": 45.4933996,\n            \"lon\": -73.728239,\n        },\n        \"northamerica-northeast2\": {\n            \"country_id\": \"CA\",\n            \"city\": \"Toronto\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 43.72666,\n            \"lon\": -79.5355309,\n        },\n        \"southamerica-east1\": {\n            \"country_id\": \"BR\",\n            \"city\": \"Osasco\",\n            \"state\": \"S\u00e3o Paulo\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": -23.5267431,\n            \"lon\": -46.8096539,\n        },\n        \"southamerica-west1\": {\n            \"country_id\": \"CL\",\n            \"city\": \"Santiago\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            \"lat\": -33.520515,\n            \"lon\": -70.721695,\n        },\n        # NOTE this is not announced yet, but showing up in API from time to time\n        \"northamerica-south1\": {\n            # https://mexicobusiness.news/cloudanddata/news/google-cloud-announces-first-mexican-data-region-queretaro\n            \"country_id\": \"MX\",\n            \"city\": \"Queretaro\",\n            \"founding_year\": 2025,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 20.5896,\n            \"lon\": -100.3897,\n        },\n        \"us-central1\": {\n            \"country_id\": \"US\",\n            \"city\": \"Council Bluffs\",\n            \"state\": \"Iowa\",\n            \"founding_year\": 2009,\n            \"green_energy\": False,\n            \"lat\": 41.168253,\n            \"lon\": -95.796125,\n        },\n        \"us-east1\": {\n            \"country_id\": \"US\",\n            \"city\": \"Moncks Corner\",\n            \"state\": \"South Carolina\",\n            \"founding_year\": 2015,\n            \"green_energy\": False,\n            \"lat\": 33.064111,\n            \"lon\": -80.043361,\n        },\n        \"us-east4\": {\n            \"country_id\": \"US\",\n            \"city\": \"Ashburn\",\n            \"state\": \"Virginia\",\n            \"founding_year\": 2017,\n            \"green_energy\": False,\n            \"lat\": 38.943331,\n            \"lon\": -77.524336,\n        },\n        \"us-east5\": {\n            \"country_id\": \"US\",\n            \"city\": \"Columbus\",\n            \"state\": \"Ohio\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 39.9773124,\n            \"lon\": -83.0423282,\n        },\n        \"us-south1\": {\n            \"country_id\": \"US\",\n            \"city\": \"Dallas\",\n            \"state\": \"Texas\",\n            \"founding_year\": 2022,\n            \"green_energy\": False,\n            \"lat\": 32.44317,\n            \"lon\": -97.062324,\n        },\n        \"us-west1\": {\n            \"country_id\": \"US\",\n            \"city\": \"The Dalles\",\n            \"state\": \"Oregon\",\n            \"founding_year\": 2016,\n            \"green_energy\": False,\n            \"lat\": 45.632511,\n            \"lon\": -121.202267,\n        },\n        \"us-west2\": {\n            \"country_id\": \"US\",\n            \"city\": \"Los Angeles\",\n            \"state\": \"California\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 34.0549694,\n            \"lon\": -118.3753618,\n        },\n        \"us-west3\": {\n            \"country_id\": \"US\",\n            \"city\": \"Salt Lake City\",\n            \"state\": \"Utah\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            # approximation based on city\n            \"lat\": 40.7386099,\n            \"lon\": -111.9609998,\n        },\n        \"us-west4\": {\n            \"country_id\": \"US\",\n            \"city\": \"Las Vegas\",\n            \"state\": \"Nevada\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            \"lat\": 36.055625,\n            \"lon\": -115.010226,\n        },\n    }\n\n    # add API reference and display names\n    for k, v in manual_data.items():\n        v[\"api_reference\"] = k\n        if v.get(\"display_name\") is None:\n            v[\"display_name\"] = v.get(\"city\", v.get(\"state\", \"\"))\n            if v.get(\"display_name\"):\n                v[\"display_name\"] = v[\"display_name\"] + \" (\" + v[\"country_id\"] + \")\"\n            else:\n                v[\"display_name\"] = v[\"country_id\"]\n\n    regions = _regions()\n    items = []\n    for region in regions:\n        if region.name not in manual_data:\n            raise KeyError(f\"Unknown region metadata for {region.name}\")\n        item = {\n            \"vendor_id\": vendor.vendor_id,\n            \"region_id\": str(region.id),\n            \"name\": region.name,\n        }\n        for k, v in manual_data[region.name].items():\n            item[k] = v\n        items.append(item)\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all available GCP zones via API calls.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all available GCP zones via API calls.\"\"\"\n    items = []\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\"])\n    for zone in _zones():\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                # example `zone.region`:\n                # https://www.googleapis.com/compute/v1/projects/algebraic-pier-412621/regions/us-east4\n                \"region_id\": regions[zone.region.split(\"/\")[-1]].region_id,\n                \"zone_id\": str(zone.id),\n                \"name\": zone.name,\n                \"api_reference\": zone.name,\n                \"display_name\": zone.name,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all available GCP servers available in all zones.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all available GCP servers available in all zones.\"\"\"\n    servers = parallel_fetch_servers(vendor, _search_servers, \"name\", \"zones\")\n    servers = preprocess_servers(servers, vendor, add_vendor_id)\n    return servers\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_server_prices","title":"inventory_server_prices","text":"<pre><code>inventory_server_prices(vendor)\n</code></pre> <p>List all available GCP server ondemand prices in all regions.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_server_prices(vendor):\n    \"\"\"List all available GCP server ondemand prices in all regions.\"\"\"\n    return _inventory_server_prices(vendor, Allocation.ONDEMAND)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>List all available GCP server spot prices in all regions.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"List all available GCP server spot prices in all regions.\"\"\"\n    return _inventory_server_prices(vendor, Allocation.SPOT)\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>List all available GCP disk storage options available in all zones.</p> <p>For more details on the disk types, check https://cloud.google.com/compute/docs/disks#disk-types.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"List all available GCP disk storage options available in all zones.\n\n    For more details on the disk types, check &lt;https://cloud.google.com/compute/docs/disks#disk-types&gt;.\"\"\"\n    vendor.progress_tracker.start_task(\n        name=\"Scanning zone(s) for storage(s)\", total=len(vendor.zones)\n    )\n\n    def search_storages(zone: Zone, vendor: Vendor) -&gt; List[dict]:\n        zone_storages = []\n        for storage in _storages(zone.name):\n            valid_sizes = storage.valid_disk_size.replace(\"GB\", \"\").split(\"-\")\n            zone_storages.append(\n                {\n                    \"storage_id\": str(storage.id),\n                    \"vendor_id\": vendor.vendor_id,\n                    \"name\": storage.name,\n                    \"description\": storage.description,\n                    \"storage_type\": (\n                        StorageType.SSD\n                        if storage.name != \"pd-standard\"\n                        else StorageType.HDD\n                    ),\n                    \"max_iops\": None,\n                    \"max_throughput\": None,\n                    \"min_size\": int(valid_sizes[0]),\n                    \"max_size\": int(valid_sizes[1]),\n                }\n            )\n        vendor.log(f\"{len(zone_storages)} storage(s) found in {zone.name}.\")\n        vendor.progress_tracker.advance_task()\n        return zone_storages\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        storages = executor.map(search_storages, vendor.zones, repeat(vendor))\n    storages = list(chain.from_iterable(storages))\n\n    vendor.log(f\"{len(storages)} storage(s) found in {len(vendor.zones)} zones.\")\n    storages = list({p[\"name\"]: p for p in storages}.values())\n    vendor.log(f\"{len(storages)} unique storage(s) found.\")\n    storages = [s for s in storages if s[\"name\"] in STORAGE_ALLOWLIST]\n    vendor.log(f\"{len(storages)} storage(s) after dropping items with complex pricing.\")\n    vendor.progress_tracker.hide_task()\n    return storages\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>List all available GCP disk storage prices in all regions.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"List all available GCP disk storage prices in all regions.\"\"\"\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\"])\n    skus = _skus_dict()\n    items = []\n    for storage in vendor.storages:\n        storage_regions = skus[\"storage\"][storage.name].keys()\n        for storage_region in storage_regions:\n            # skip edge regions\n            region = regions.get(storage_region)\n            if region is None:\n                vendor.log(\n                    f\"Skip unknown '{storage_region}' region for {storage.name}\",\n                    DEBUG,\n                )\n                continue\n\n            price, currency = skus[\"storage\"][storage.name][storage_region][\"ondemand\"]\n            for zone in region.zones:\n                items.append(\n                    {\n                        \"vendor_id\": vendor.vendor_id,\n                        \"region_id\": region.region_id,\n                        \"storage_id\": storage.storage_id,\n                        \"unit\": PriceUnit.GB_MONTH,\n                        \"price\": price,\n                        \"currency\": currency,\n                    }\n                )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>List inbound and outbound network traffic prices in all GCP regions.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"List inbound and outbound network traffic prices in all GCP regions.\"\"\"\n    regions = scmodels_to_dict(vendor.regions, keys=[\"name\"])\n    skus = _skus(\"Compute Engine\")\n    items = []\n    for sku in skus:\n        # skip not processed items early\n        if sku.category.resource_family != \"Network\":\n            continue\n        if sku.category.resource_group not in [\n            \"StandardInternetEgress\",\n            \"StandardInternetIngress\",\n        ]:\n            continue\n\n        # helper variables\n        traffic_regions = sku.service_regions\n        tiered_rates = sku.pricing_info[0].pricing_expression.tiered_rates\n        price_tiers = []\n        for i in range(len(tiered_rates)):\n            price_tiers.append(\n                {\n                    \"lower\": tiered_rates[i].start_usage_amount,\n                    \"upper\": \"Infinity\"\n                    if i == len(tiered_rates) - 1\n                    else tiered_rates[i + 1].start_usage_amount,\n                    \"price\": tiered_rates[i].unit_price.nanos / 1e9,\n                }\n            )\n\n        for traffic_region in traffic_regions:\n            region = regions.get(traffic_region)\n            if region is None:\n                vendor.log(\n                    f\"Skip unknown '{traffic_region}' region for {sku.description}\",\n                    DEBUG,\n                )\n                continue\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region.region_id,\n                    \"price\": max([t[\"price\"] for t in price_tiers]),\n                    \"price_tiered\": price_tiers,\n                    \"currency\": tiered_rates[0].unit_price.currency_code,\n                    \"unit\": PriceUnit.GB_MONTH,\n                    \"direction\": (\n                        TrafficDirection.OUT\n                        if sku.category.resource_group == \"StandardInternetEgress\"\n                        else TrafficDirection.IN\n                    ),\n                }\n            )\n\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/gcp/#sc_crawler.vendors.gcp.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>List the price of an attached IPv4 address in all GCP regions.</p> <p>Note that this data was not found using the APIs (only unattached static IPs), so the values are recorded manually from https://cloud.google.com/vpc/network-pricing#ipaddress.</p> Source code in <code>sc_crawler/vendors/gcp.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"List the price of an attached IPv4 address in all GCP regions.\n\n    Note that this data was not found using the APIs (only unattached static IPs),\n    so the values are recorded manually from &lt;https://cloud.google.com/vpc/network-pricing#ipaddress&gt;.\n    \"\"\"\n    # skus = _skus(\"Compute Engine\")\n    # for sku in skus:\n    #     if sku.category.resource_family != \"Network\":\n    #         continue\n    #     if sku.description == \"Static Ip Charge\":\n    #         pass\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0.005,\n                \"currency\": \"USD\",\n                \"unit\": PriceUnit.HOUR,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/","title":"hcloud","text":""},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud","title":"sc_crawler.vendors.hcloud","text":""},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of known compliance frameworks at Hetzner.</p> <p>Data collected from https://www.hetzner.com/unternehmen/zertifizierung.</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of known compliance frameworks at Hetzner.\n\n    Data collected from &lt;https://www.hetzner.com/unternehmen/zertifizierung&gt;.\"\"\"\n    return map_compliance_frameworks_to_vendor(vendor.vendor_id, [\"iso27001\"])\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all regions via API call.</p> <p>Hetzner Cloud uses integers for the region (virtual datacenter) id that we convert into string. Best to use the unique <code>name</code>, which can be also passed instead of the <code>id</code> in most <code>hcloud</code> API endpoints via the <code>id_or_name</code> method.</p> <p>Not taking the Hetzner unique <code>name</code> as id, as it's not stated to be unique for other resources, and uniqueness for servers might also change in the future.</p> <p>All regions are powered by green energy as per https://www.hetzner.com/unternehmen/umweltschutz/.</p> <p>Lon/lat coordinates were collected by searching for Hetzner locations in the Region's city.</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all regions via API call.\n\n    Hetzner Cloud uses integers for the region (virtual datacenter) id\n    that we convert into string. Best to use the unique `name`, which\n    can be also passed instead of the `id` in most `hcloud` API\n    endpoints via the `id_or_name` method.\n\n    Not taking the Hetzner unique `name` as id, as it's not\n    stated to be unique for other resources, and uniqueness\n    for servers might also change in the future.\n\n    All regions are powered by green energy as per\n    &lt;https://www.hetzner.com/unternehmen/umweltschutz/&gt;.\n\n    Lon/lat coordinates were collected by searching for Hetzner\n    locations in the Region's city.\n\n    \"\"\"\n    regions = {\n        \"2\": {  # Nuremberg\n            \"lat\": 49.4498349,\n            \"lon\": 11.0128772,\n        },\n        \"3\": {  # Helsinki\n            \"lat\": 60.3433291,\n            \"lon\": 25.02683,\n        },\n        \"4\": {  # Falkenstein\n            \"lat\": 50.4793313,\n            \"lon\": 12.3331105,\n        },\n        \"5\": {  # Ashburn, VA\n            \"lat\": 39.0176685,\n            \"lon\": -77.468102,\n        },\n        \"6\": {  # Hillsboro, OR\n            \"lat\": 45.558319,\n            \"lon\": -122.9306602,\n        },\n        \"7\": {  # Singapore\n            \"lat\": 1.290270,\n            \"lon\": 103.851959,\n        },\n    }\n\n    items = []\n    for region in _client().datacenters.get_all():\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": str(region.id),\n                \"name\": region.name,\n                \"api_reference\": region.name,\n                \"display_name\": (\n                    region.location.city + f\" ({region.location.country})\"\n                ),\n                # TODO add region.description\n                \"aliases\": [region.location.name],\n                \"country_id\": region.location.country,\n                \"state\": None,\n                \"city\": region.location.city,\n                \"address_line\": None,\n                \"zip_code\": None,\n                \"lat\": regions[str(region.id)][\"lat\"],\n                \"lon\": regions[str(region.id)][\"lon\"],\n                \"founding_year\": None,\n                \"green_energy\": True,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all regions as availability zones.</p> <p>There is no concept of having multiple availability zones withing a region (virtual datacenter) at Hetzner Cloud, so creating 1-1 dummy Zones reusing the Region id and name.</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all regions as availability zones.\n\n    There is no concept of having multiple availability zones withing\n    a region (virtual datacenter) at Hetzner Cloud, so creating 1-1\n    dummy Zones reusing the Region id and name.\n\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"zone_id\": region.region_id,\n                \"name\": region.name,\n                \"api_reference\": region.name,\n                \"display_name\": region.name,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_servers","title":"inventory_servers","text":"<pre><code>inventory_servers(vendor)\n</code></pre> <p>List all server types from API and manual data entry from the Hetzner Cloud homepage.</p> <p>CPU information is recorded from https://www.hetzner.com/cloud/ as not exposed via API.</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_servers(vendor):\n    \"\"\"List all server types from API and manual data entry from the Hetzner Cloud homepage.\n\n    CPU information is recorded from &lt;https://www.hetzner.com/cloud/&gt; as not exposed via API.\"\"\"\n    items = []\n    for server in _client().server_types.get_all():\n        # CPU info not available via the API,\n        # collected from https://www.hetzner.com/cloud/\n        cpu = _server_cpu(server.name)\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"server_id\": str(server.id),\n                \"name\": server.name,\n                \"api_reference\": server.name,\n                \"display_name\": server.name,\n                \"description\": server.description,\n                \"family\": server.name.rstrip(\"0123456789\"),\n                \"vcpus\": server.cores,\n                \"hypervisor\": \"QEMU\",\n                \"cpu_allocation\": (\n                    CpuAllocation.SHARED\n                    if server.cpu_type == \"shared\"\n                    else CpuAllocation.DEDICATED\n                ),\n                \"cpu_cores\": None,\n                \"cpu_speed\": None,\n                \"cpu_architecture\": (\n                    CpuArchitecture.ARM64\n                    if server.architecture == \"arm\"\n                    else CpuArchitecture.X86_64\n                ),\n                \"cpu_manufacturer\": cpu[0],\n                \"cpu_family\": cpu[1],\n                \"cpu_model\": cpu[2],\n                \"cpus\": [],\n                \"memory_amount\": server.memory * 1024,\n                \"gpu_count\": 0,\n                \"gpu_memory_min\": None,\n                \"gpu_memory_total\": None,\n                \"gpu_manufacturer\": None,\n                \"gpu_model\": None,\n                \"gpus\": [],\n                \"storage_size\": server.disk,\n                \"storage_type\": (\n                    StorageType.SSD\n                    if server.storage_type == \"local\"\n                    else StorageType.NETWORK\n                ),\n                \"storages\": [],\n                \"network_speed\": None,\n                # https://docs.hetzner.com/cloud/billing/faq/#how-do-you-bill-for-traffic\n                \"inbound_traffic\": 0,  # free\n                \"outbound_traffic\": (\n                    max([region.get(\"included_traffic\") for region in server.prices])\n                    / (1024**3)\n                ),\n                \"ipv4\": 0,\n                \"status\": Status.ACTIVE if not server.deprecation else Status.INACTIVE,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_server_prices_spot","title":"inventory_server_prices_spot","text":"<pre><code>inventory_server_prices_spot(vendor)\n</code></pre> <p>There are no spot instaces at Hetzner.</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_server_prices_spot(vendor):\n    \"\"\"There are no spot instaces at Hetzner.\"\"\"\n    return []\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_storages","title":"inventory_storages","text":"<pre><code>inventory_storages(vendor)\n</code></pre> <p>Block storage volume information collected manually.</p> <p>There is not information shared vie the API, so information was collected manually from:</p> <ul> <li>https://www.hetzner.com/cloud/</li> <li>https://docs.hetzner.cloud/#volumes-create-a-volume</li> </ul> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_storages(vendor):\n    \"\"\"Block storage volume information collected manually.\n\n    There is not information shared vie the API, so information\n    was collected manually from:\n\n    - &lt;https://www.hetzner.com/cloud/&gt;\n    - &lt;https://docs.hetzner.cloud/#volumes-create-a-volume&gt;\n    \"\"\"\n    items = [\n        {\n            \"storage_id\": \"block\",\n            \"vendor_id\": vendor.vendor_id,\n            \"name\": \"Block storage volume\",\n            \"description\": None,\n            \"storage_type\": StorageType.NETWORK,\n            \"max_iops\": None,\n            \"max_throughput\": None,\n            \"min_size\": 10,\n            \"max_size\": 10240,\n        }\n    ]\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_storage_prices","title":"inventory_storage_prices","text":"<pre><code>inventory_storage_prices(vendor)\n</code></pre> <p>Block storage volume pricing information collected manually.</p> <p>Source: https://www.hetzner.com/cloud/</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_storage_prices(vendor):\n    \"\"\"Block storage volume pricing information collected manually.\n\n    Source: &lt;https://www.hetzner.com/cloud/&gt;\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"storage_id\": \"block\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"price\": 0.0440,\n                \"currency\": \"EUR\",\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_traffic_prices","title":"inventory_traffic_prices","text":"<pre><code>inventory_traffic_prices(vendor)\n</code></pre> <p>Traffic price collected manually.</p> <p>Source: https://docs.hetzner.com/robot/general/traffic/</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_traffic_prices(vendor):\n    \"\"\"Traffic price collected manually.\n\n    Source: &lt;https://docs.hetzner.com/robot/general/traffic/&gt;\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0,\n                \"price_tiered\": [],\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.IN,\n            }\n        )\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": round(1 / 1024, 8),\n                \"price_tiered\": [],\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.GB_MONTH,\n                \"direction\": TrafficDirection.OUT,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/hcloud/#sc_crawler.vendors.hcloud.inventory_ipv4_prices","title":"inventory_ipv4_prices","text":"<pre><code>inventory_ipv4_prices(vendor)\n</code></pre> <p>IPv4 price collected manually.</p> <p>Source: https://docs.hetzner.com/general/others/ipv4-pricing/#cloud</p> Source code in <code>sc_crawler/vendors/hcloud.py</code> <pre><code>def inventory_ipv4_prices(vendor):\n    \"\"\"IPv4 price collected manually.\n\n    Source: &lt;https://docs.hetzner.com/general/others/ipv4-pricing/#cloud&gt;\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"price\": 0.50,\n                \"currency\": \"EUR\",\n                \"unit\": PriceUnit.MONTH,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/upcloud/","title":"upcloud","text":""},{"location":"reference/sc_crawler/vendors/upcloud/#sc_crawler.vendors.upcloud","title":"sc_crawler.vendors.upcloud","text":""},{"location":"reference/sc_crawler/vendors/upcloud/#sc_crawler.vendors.upcloud.inventory_compliance_frameworks","title":"inventory_compliance_frameworks","text":"<pre><code>inventory_compliance_frameworks(vendor)\n</code></pre> <p>Manual list of known compliance frameworks at UpCloud.</p> <p>Data collected from their Security and Standards docs at https://upcloud.com/security-privacy.</p> Source code in <code>sc_crawler/vendors/upcloud.py</code> <pre><code>def inventory_compliance_frameworks(vendor):\n    \"\"\"Manual list of known compliance frameworks at UpCloud.\n\n    Data collected from their Security and Standards docs at\n    &lt;https://upcloud.com/security-privacy&gt;.\"\"\"\n    return map_compliance_frameworks_to_vendor(\n        vendor.vendor_id,\n        [\"iso27001\"],\n    )\n</code></pre>"},{"location":"reference/sc_crawler/vendors/upcloud/#sc_crawler.vendors.upcloud.inventory_regions","title":"inventory_regions","text":"<pre><code>inventory_regions(vendor)\n</code></pre> <p>List all regions via API call.</p> <p>Data manually enriched from https://upcloud.com/data-centres.</p> Source code in <code>sc_crawler/vendors/upcloud.py</code> <pre><code>def inventory_regions(vendor):\n    \"\"\"List all regions via API call.\n\n    Data manually enriched from https://upcloud.com/data-centres.\"\"\"\n    manual_data = {\n        \"au-syd1\": {\n            \"country_id\": \"AU\",\n            \"state\": \"New South Wales\",\n            \"city\": \"Sydney\",\n            \"founding_year\": 2021,\n            \"green_energy\": False,\n            \"lon\": 151.189377,\n            \"lat\": -33.918251,\n        },\n        \"de-fra1\": {\n            \"country_id\": \"DE\",\n            \"state\": \"Hesse\",\n            \"city\": \"Frankfurt\",\n            \"founding_year\": 2015,\n            \"green_energy\": True,\n            \"lon\": 8.735120,\n            \"lat\": 50.119190,\n        },\n        \"fi-hel1\": {\n            \"country_id\": \"FI\",\n            \"state\": \"Uusimaa\",\n            \"city\": \"Helsinki\",\n            \"founding_year\": 2011,\n            \"green_energy\": True,\n            \"lon\": 24.778570,\n            \"lat\": 60.20323,\n        },\n        \"fi-hel2\": {\n            \"country_id\": \"FI\",\n            \"state\": \"Uusimaa\",\n            \"city\": \"Helsinki\",\n            \"founding_year\": 2018,\n            \"green_energy\": True,\n            \"lon\": 24.876350,\n            \"lat\": 60.216209,\n        },\n        \"es-mad1\": {\n            \"country_id\": \"ES\",\n            \"state\": \"Madrid\",\n            \"city\": \"Madrid\",\n            \"founding_year\": 2020,\n            \"green_energy\": True,\n            \"lon\": -3.6239873,\n            \"lat\": 40.4395019,\n        },\n        \"nl-ams1\": {\n            \"country_id\": \"NL\",\n            \"state\": \"Noord Holland\",\n            \"city\": \"Amsterdam\",\n            \"founding_year\": 2017,\n            \"green_energy\": True,\n            \"lon\": 4.8400019,\n            \"lat\": 52.3998291,\n        },\n        \"pl-waw1\": {\n            \"country_id\": \"PL\",\n            \"state\": \"Mazowieckie\",\n            \"city\": \"Warsaw\",\n            \"founding_year\": 2020,\n            \"green_energy\": True,\n            \"lon\": 20.9192823,\n            \"lat\": 52.1905901,\n        },\n        \"se-sto1\": {\n            \"country_id\": \"SE\",\n            \"state\": \"Stockholm\",\n            \"city\": \"Stockholm\",\n            \"founding_year\": 2015,\n            \"green_energy\": True,\n            \"lon\": 18.102788,\n            \"lat\": 59.2636708,\n        },\n        \"sg-sin1\": {\n            \"country_id\": \"SG\",\n            \"state\": \"Singapore\",\n            \"city\": \"Singapore\",\n            \"founding_year\": 2017,\n            \"green_energy\": True,\n            \"lon\": 103.7022636,\n            \"lat\": 1.3172304,\n        },\n        \"uk-lon1\": {\n            \"country_id\": \"GB\",\n            \"state\": \"London\",\n            \"city\": \"London\",\n            \"founding_year\": 2012,\n            \"green_energy\": True,\n            # approximate .. probably business address\n            \"lon\": -0.1037341,\n            \"lat\": 51.5232232,\n        },\n        \"us-chi1\": {\n            \"country_id\": \"US\",\n            \"state\": \"Illinois\",\n            \"city\": \"Chicago\",\n            \"founding_year\": 2014,\n            \"green_energy\": False,\n            \"lon\": -87.6342056,\n            \"lat\": 41.8761287,\n        },\n        \"us-nyc1\": {\n            \"country_id\": \"US\",\n            \"state\": \"New York\",\n            \"city\": \"New York\",\n            \"founding_year\": 2020,\n            \"green_energy\": False,\n            \"lon\": -74.0645536,\n            \"lat\": 40.7834325,\n        },\n        \"us-sjo1\": {\n            \"country_id\": \"US\",\n            \"state\": \"California\",\n            \"city\": \"San Jose\",\n            \"founding_year\": 2018,\n            \"green_energy\": False,\n            \"lon\": -121.9754458,\n            \"lat\": 37.3764769,\n        },\n    }\n    items = []\n    regions = _client().get_zones()[\"zones\"][\"zone\"]\n    for region in regions:\n        if region[\"public\"] == \"yes\":\n            if region[\"id\"] not in manual_data:\n                raise ValueError(f\"Missing manual data for {region['id']}\")\n            region_data = manual_data[region[\"id\"]]\n            items.append(\n                {\n                    \"vendor_id\": vendor.vendor_id,\n                    \"region_id\": region[\"id\"],\n                    \"name\": region[\"description\"],\n                    \"api_reference\": region[\"id\"],\n                    \"display_name\": (\n                        region[\"description\"] + f\" ({region_data['country_id']})\"\n                    ),\n                    \"aliases\": [],\n                    \"country_id\": region_data[\"country_id\"],\n                    \"state\": region_data[\"state\"],\n                    \"city\": region_data[\"city\"],\n                    \"address_line\": None,\n                    \"zip_code\": None,\n                    \"lon\": region_data[\"lon\"],\n                    \"lat\": region_data[\"lat\"],\n                    \"founding_year\": region_data[\"founding_year\"],\n                    \"green_energy\": region_data[\"green_energy\"],\n                }\n            )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/upcloud/#sc_crawler.vendors.upcloud.inventory_zones","title":"inventory_zones","text":"<pre><code>inventory_zones(vendor)\n</code></pre> <p>List all regions as availability zones.</p> <p>There is no concept of having multiple availability zones withing a region (virtual datacenter) at UpCloud, so creating 1-1 dummy Zones reusing the Region id and name.</p> Source code in <code>sc_crawler/vendors/upcloud.py</code> <pre><code>def inventory_zones(vendor):\n    \"\"\"List all regions as availability zones.\n\n    There is no concept of having multiple availability zones withing\n    a region (virtual datacenter) at UpCloud, so creating 1-1\n    dummy Zones reusing the Region id and name.\n    \"\"\"\n    items = []\n    for region in vendor.regions:\n        items.append(\n            {\n                \"vendor_id\": vendor.vendor_id,\n                \"region_id\": region.region_id,\n                \"zone_id\": region.region_id,\n                \"name\": region.name,\n                \"api_reference\": region.region_id,\n                \"display_name\": region.name,\n            }\n        )\n    return items\n</code></pre>"},{"location":"reference/sc_crawler/vendors/vendors/","title":"vendors","text":""},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors","title":"sc_crawler.vendors.vendors","text":"<p>Supported cloud and VPS provider vendors.</p> <p>For logos, see e.g. https://iconduck.com/sets/svg-logos, and edit to square e.g. via https://boxy-svg.com.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.aws","title":"aws  <code>module-attribute</code>","text":"<pre><code>aws = Vendor(vendor_id='aws', name='Amazon Web Services', logo='https://sparecores.com/assets/images/vendors/aws.svg', homepage='https://aws.amazon.com', country=countries['US'], state='Washington', city='Seattle', address_line='410 Terry Ave N', zip_code='98109', founding_year=2002, status_page='https://health.aws.amazon.com/health/status')\n</code></pre> <p>Amazon Web Services.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.gcp","title":"gcp  <code>module-attribute</code>","text":"<pre><code>gcp = Vendor(vendor_id='gcp', name='Google Cloud Platform', logo='https://sparecores.com/assets/images/vendors/gcp.svg', homepage='https://cloud.google.com', country=countries['US'], state='California', city='Mountain View', address_line='1600 Amphitheatre Pkwy', zip_code='94043', founding_year=2008, status_page='https://status.cloud.google.com/')\n</code></pre> <p>Google Cloud Platform.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.hcloud","title":"hcloud  <code>module-attribute</code>","text":"<pre><code>hcloud = Vendor(vendor_id='hcloud', name='Hetzner Cloud', logo='https://sparecores.com/assets/images/vendors/hcloud.svg', homepage='https://www.hetzner.com/cloud/', country=countries['DE'], state='Bavaria', city='Gunzenhausen', address_line='Industriestr. 25', zip_code='91710', founding_year=1997, status_page='https://status.hetzner.com/')\n</code></pre> <p>Hetzner Cloud.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.azure","title":"azure  <code>module-attribute</code>","text":"<pre><code>azure = Vendor(vendor_id='azure', name='Microsoft Azure', logo='https://sparecores.com/assets/images/vendors/azure.svg', homepage='https://azure.microsoft.com', country=countries['US'], state='Washington', city='Redmond', address_line='One Microsoft Way', zip_code='98052', founding_year=2008, status_page='https://azure.status.microsoft.com')\n</code></pre> <p>Microsoft Azure.</p>"},{"location":"reference/sc_crawler/vendors/vendors/#sc_crawler.vendors.vendors.upcloud","title":"upcloud  <code>module-attribute</code>","text":"<pre><code>upcloud = Vendor(vendor_id='upcloud', name='UpCloud', logo='https://sparecores.com/assets/images/vendors/upcloud.svg', homepage='https://upcloud.com', country=countries['FI'], state='Uusimaa', city='Helsinki', address_line='Aleksanterinkatu 15 B, 7th floor', zip_code='00100', founding_year=2012, status_page='https://status.upcloud.com')\n</code></pre> <p>UpCloud.</p>"}]}